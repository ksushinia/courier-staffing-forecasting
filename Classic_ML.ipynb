{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lQv0U65qUlmc",
    "outputId": "63e32c40-8f2d-417d-c17f-6f449ee17e8d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from catboost) (1.16.3)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly->catboost) (9.1.2)\n",
      "Downloading catboost-1.2.8-cp312-cp312-manylinux2014_x86_64.whl (99.2 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m99.2/99.2 MB\u001B[0m \u001B[31m10.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: catboost\n",
      "Successfully installed catboost-1.2.8\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost pandas numpy scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "!mkdir -p ~/.kaggle\n",
    "\n",
    "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
    "\n",
    "# даем права доступа\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# скачиваем данные\n",
    "!kaggle competitions download -c intern-regression-courier-deficit-challenge\n",
    "\n",
    "# распаковываем\n",
    "!unzip -o intern-regression-courier-deficit-challenge.zip -d data\n",
    "\n",
    "print(\"Файлы находятся в папке data:\")\n",
    "print(os.listdir('data'))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lKIYpxvUW2HD",
    "outputId": "7f9f13fd-ddab-4112-a294-1e8f91cba9a8"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "Downloading intern-regression-courier-deficit-challenge.zip to /content\n",
      "  0% 0.00/1.82M [00:00<?, ?B/s]\n",
      "100% 1.82M/1.82M [00:00<00:00, 768MB/s]\n",
      "Archive:  intern-regression-courier-deficit-challenge.zip\n",
      "  inflating: data/facts.csv          \n",
      "  inflating: data/sample_submission.csv  \n",
      "  inflating: data/shifts_prediction.csv  \n",
      "  inflating: data/test.csv           \n",
      "  inflating: data/train.csv          \n",
      "Файлы находятся в папке data:\n",
      "['test.csv', 'shifts_prediction.csv', 'sample_submission.csv', 'train.csv', 'facts.csv']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# удобное отображение\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# читаем данные\n",
    "# parse_dates переводит текст в дату\n",
    "train = pd.read_csv('data/train.csv', parse_dates=['calendar_dt'])\n",
    "test = pd.read_csv('data/test.csv') # здесь даты нет\n",
    "facts = pd.read_csv('data/facts.csv', parse_dates=['calendar_dt'])\n",
    "shifts = pd.read_csv('data/shifts_prediction.csv', parse_dates=['calendar_dt'])\n",
    "submission_example = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "print(\"Размеры таблиц:\")\n",
    "print(f\"train: {train.shape}\")\n",
    "print(f\"test: {test.shape}\")\n",
    "print(f\"facts: {facts.shape}\")\n",
    "print(f\"shifts: {shifts.shape}\")\n",
    "\n",
    "# смотрим на первые строки трейна\n",
    "train.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "S4DPcOeNY4-g",
    "outputId": "92d30e15-6ea8-42d5-ed90-e5d78a135c02"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Размеры таблиц:\n",
      "train: (8220, 3)\n",
      "test: (2438, 1)\n",
      "facts: (10660, 13)\n",
      "shifts: (223470, 5)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "  calendar_dt                              store_id  target\n",
       "0  2025-11-03  000fade4-e8dc-11ed-b10a-08c0eb31fffb     1.0\n",
       "1  2025-11-10  000fade4-e8dc-11ed-b10a-08c0eb31fffb     1.0\n",
       "2  2025-11-17  000fade4-e8dc-11ed-b10a-08c0eb31fffb     4.0\n",
       "3  2025-11-03  0022f1b0-b8f8-11ee-b10b-08c0eb31fffb     1.0\n",
       "4  2025-11-10  0022f1b0-b8f8-11ee-b10b-08c0eb31fffb     1.0"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-baf4210b-9b77-4db2-be3c-7dc0140f9444\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calendar_dt</th>\n",
       "      <th>store_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>000fade4-e8dc-11ed-b10a-08c0eb31fffb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>000fade4-e8dc-11ed-b10a-08c0eb31fffb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>000fade4-e8dc-11ed-b10a-08c0eb31fffb</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-03</td>\n",
       "      <td>0022f1b0-b8f8-11ee-b10b-08c0eb31fffb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-10</td>\n",
       "      <td>0022f1b0-b8f8-11ee-b10b-08c0eb31fffb</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baf4210b-9b77-4db2-be3c-7dc0140f9444')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-baf4210b-9b77-4db2-be3c-7dc0140f9444 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-baf4210b-9b77-4db2-be3c-7dc0140f9444');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "train",
       "summary": "{\n  \"name\": \"train\",\n  \"rows\": 8220,\n  \"fields\": [\n    {\n      \"column\": \"calendar_dt\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-01-01 00:00:00\",\n        \"max\": \"2025-11-17 00:00:00\",\n        \"num_unique_values\": 98,\n        \"samples\": [\n          \"2025-06-02 00:00:00\",\n          \"2024-12-30 00:00:00\",\n          \"2024-03-25 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"store_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2453,\n        \"samples\": [\n          \"db87b953-f9ab-11ea-8599-1c34dae33151\",\n          \"4377c415-3554-11eb-859a-1c34dae33151\",\n          \"72e787b6-a0d6-11ef-ae7a-08c0eb320147\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.738420224415233,\n        \"min\": 0.0,\n        \"max\": 31.0,\n        \"num_unique_values\": 24,\n        \"samples\": [\n          10.0,\n          14.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
      }
     },
     "metadata": {},
     "execution_count": 3
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# добавляем дату в тест\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "# помечаем отдельно трейн и тест, чтобы потом разделить\n",
    "train['is_train'] = 1\n",
    "test['is_train'] = 0\n",
    "test['target'] = np.nan # это мы будем предсказывать\n",
    "\n",
    "# склеиваем в один длинный dataframe\n",
    "df = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "# добавляем в каждую строку информацию о прошлом (фактах) и будущем (прогнозах)\n",
    "df = df.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df = df.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "print(\"размер общего датасета:\", df.shape)\n",
    "print(\"пропуски (только 5):\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(5))\n",
    "\n",
    "# заполним пропуски нулями (для начала)\n",
    "# не заполняем target, он должен остаться NaN в тесте\n",
    "features_to_fill = [c for c in df.columns if c != 'target']\n",
    "df[features_to_fill] = df[features_to_fill].fillna(0)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xofkN7EEcwfg",
    "outputId": "11d09aa9-e99d-4b90-c559-2f35063b2564"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "размер общего датасета: (10658, 18)\n",
      "пропуски (только 5):\n",
      "marketing_costs_lag_1              3203\n",
      "fact_percent_lateness_lag_1        2457\n",
      "target                             2438\n",
      "fact_load_factor_lag_1              115\n",
      "fact_couriers_with_shifts_lag_1     115\n",
      "dtype: int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# фичи из даты\n",
    "df['month'] = df['calendar_dt'].dt.month\n",
    "df['day'] = df['calendar_dt'].dt.day\n",
    "# номер недели в году\n",
    "df['week_of_year'] = df['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# разница между прогнозом заказов и фактом прошлой недели\n",
    "df['orders_diff'] = df['predicted_num_orders'] - df['fact_num_orders_lag_1']\n",
    "\n",
    "# нагрузка\n",
    "df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "\n",
    "# определяем списки колонок\n",
    "categorical_features = ['store_id', 'city_nm'] # текстовые поля\n",
    "drop_cols = ['calendar_dt', 'target', 'is_train'] # это не идет в обучение\n",
    "feature_cols = [c for c in df.columns if c not in drop_cols]\n",
    "\n",
    "print(f\"всего признаков: {len(feature_cols)}\")\n",
    "print(feature_cols)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWDN6oC4eebo",
    "outputId": "63407528-ee1f-4042-e54f-7e0c668c391f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "всего признаков: 20\n",
      "['store_id', 'fact_staff_value_lag_1', 'fact_load_factor_lag_1', 'num_available_couriers_lag_1', 'fact_num_orders_lag_1', 'fact_percent_lateness_lag_1', 'city_nm', 'store_lifetime_in_days', 'fact_staff_churn', 'flag_high_load_lag_1', 'marketing_costs_lag_1', 'fact_couriers_with_shifts_lag_1', 'predicted_staff_value', 'predicted_num_orders', 'predicted_load_factor', 'month', 'day', 'week_of_year', 'orders_diff', 'load_diff']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# разделяем обратно\n",
    "X_train = df[df['is_train'] == 1][feature_cols]\n",
    "y_train = df[df['is_train'] == 1]['target']\n",
    "X_test = df[df['is_train'] == 0][feature_cols]\n",
    "\n",
    "# инициализируем CatBoost\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1500,          # количество деревьев (эпох)\n",
    "    learning_rate=0.03,       # шаг обучения\n",
    "    depth=6,                  # глубина дерева\n",
    "    loss_function='MAE',      # оптимизируем среднюю абсолютную ошибку\n",
    "    eval_metric='MAE',\n",
    "    cat_features=categorical_features, # категориальные фичи\n",
    "    random_seed=42,\n",
    "    verbose=100               # вывод каждые 100 итераций\n",
    ")\n",
    "\n",
    "print(\"начинаем обучение...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Готово!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7mWIYJpHe5EP",
    "outputId": "be8effc3-8c58-4333-8b5f-902ec92e192c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "начинаем обучение...\n",
      "0:\tlearn: 1.9121974\ttotal: 55.3ms\tremaining: 1m 22s\n",
      "100:\tlearn: 0.4897663\ttotal: 1.83s\tremaining: 25.4s\n",
      "200:\tlearn: 0.4348211\ttotal: 4.74s\tremaining: 30.6s\n",
      "300:\tlearn: 0.4235268\ttotal: 6.41s\tremaining: 25.5s\n",
      "400:\tlearn: 0.4120154\ttotal: 8.94s\tremaining: 24.5s\n",
      "500:\tlearn: 0.4030597\ttotal: 12.1s\tremaining: 24.2s\n",
      "600:\tlearn: 0.3927104\ttotal: 14.2s\tremaining: 21.2s\n",
      "700:\tlearn: 0.3881858\ttotal: 16.4s\tremaining: 18.6s\n",
      "800:\tlearn: 0.3828637\ttotal: 18.4s\tremaining: 16.1s\n",
      "900:\tlearn: 0.3789922\ttotal: 20.4s\tremaining: 13.5s\n",
      "1000:\tlearn: 0.3756024\ttotal: 22.6s\tremaining: 11.3s\n",
      "1100:\tlearn: 0.3707492\ttotal: 25.4s\tremaining: 9.2s\n",
      "1200:\tlearn: 0.3678933\ttotal: 26.8s\tremaining: 6.66s\n",
      "1300:\tlearn: 0.3644926\ttotal: 27.6s\tremaining: 4.22s\n",
      "1400:\tlearn: 0.3616904\ttotal: 28.4s\tremaining: 2.01s\n",
      "1499:\tlearn: 0.3594796\ttotal: 29.2s\tremaining: 0us\n",
      "Готово!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# смотрим важность фич\n",
    "feature_importance = model.get_feature_importance(prettified=True)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Importances\", y=\"Feature Id\", data=feature_importance.head(15))\n",
    "plt.title('топ 15 важных признаков')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "qItIYZPqf_qV",
    "outputId": "a3cea2c9-dcd7-425d-d493-06d601331348"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# дефицит не может быть отрицательным.\n",
    "predictions = np.maximum(predictions, 0)\n",
    "\n",
    "# собираем DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'store_id': test['store_id'],\n",
    "    'target': predictions\n",
    "})\n",
    "\n",
    "# сортируем по store_id\n",
    "submission = submission.sort_values(by='store_id')\n",
    "\n",
    "submission.to_csv('submission_v1_catboost.csv', index=False)\n",
    "\n",
    "print(\"Файл сохранён!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00E9LrW9hK0E",
    "outputId": "1f872846-6fb7-495d-cf85-e626cc9a8fa9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Файл сохранён!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# соберем датасет заново, чтобы убрать заполнение нулями\n",
    "# снова склеиваем\n",
    "df_v2 = pd.concat([train, test], ignore_index=True)\n",
    "df_v2 = df_v2.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_v2 = df_v2.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "# заполним нулями только то, где это логично\n",
    "df_v2['marketing_costs_lag_1'] = df_v2['marketing_costs_lag_1'].fillna(0)\n",
    "df_v2['flag_high_load_lag_1'] = df_v2['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# остальные колонки пока оставим как NaN\n",
    "\n",
    "# новые фичи\n",
    "# базовые даты\n",
    "df_v2['month'] = df_v2['calendar_dt'].dt.month\n",
    "df_v2['week_of_year'] = df_v2['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# отношение прогноза к факту\n",
    "# 1e-5 чтобы не делить на ноль\n",
    "df_v2['orders_growth'] = df_v2['predicted_num_orders'] / (df_v2['fact_num_orders_lag_1'] + 1e-5)\n",
    "\n",
    "# сколько уволилось относительно общего штата\n",
    "df_v2['churn_rate'] = df_v2['fact_staff_churn'] / (df_v2['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "# разница между тем, сколько надо было и сколько было\n",
    "df_v2['staff_shortage_lag'] = df_v2['fact_staff_value_lag_1'] - df_v2['fact_couriers_with_shifts_lag_1']\n",
    "\n",
    "# старые полезные фичи\n",
    "df_v2['orders_diff'] = df_v2['predicted_num_orders'] - df_v2['fact_num_orders_lag_1']\n",
    "df_v2['load_diff'] = df_v2['predicted_load_factor'] - df_v2['fact_load_factor_lag_1']\n",
    "\n",
    "\n",
    "categorical_features = ['store_id', 'city_nm']\n",
    "drop_cols = ['calendar_dt', 'target', 'is_train']\n",
    "feature_cols = [c for c in df_v2.columns if c not in drop_cols]\n",
    "\n",
    "print(f\"новые фичи добавлены, всего: {len(feature_cols)}\")\n",
    "\n",
    "X_train_v2 = df_v2[df_v2['is_train'] == 1][feature_cols]\n",
    "y_train_v2 = df_v2[df_v2['is_train'] == 1]['target']\n",
    "X_test_v2 = df_v2[df_v2['is_train'] == 0][feature_cols]\n",
    "\n",
    "model_v2 = CatBoostRegressor(\n",
    "    iterations=2000,          # больше деревьев\n",
    "    learning_rate=0.02,       # меньше шаг\n",
    "    depth=7,                  # чуть-чуть углубили дерево\n",
    "    l2_leaf_reg=3,            # чтобы не переобучиться на churn\n",
    "    loss_function='MAE',\n",
    "    eval_metric='MAE',\n",
    "    cat_features=categorical_features,\n",
    "    nan_mode='Min',           # NaN считать меньше минимума\n",
    "    random_seed=42,\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "print(\"Обучаем модель v2...\")\n",
    "model_v2.fit(X_train_v2, y_train_v2)\n",
    "\n",
    "preds_v2 = model_v2.predict(X_test_v2)\n",
    "preds_v2 = np.maximum(preds_v2, 0) # чтобы убрать отрицательные\n",
    "\n",
    "submission_v2 = pd.DataFrame({\n",
    "    'store_id': test['store_id'], # id берем из исходного теста\n",
    "    'target': preds_v2\n",
    "})\n",
    "submission_v2 = submission_v2.sort_values(by='store_id')\n",
    "submission_v2.to_csv('submission_v2_smart_nan.csv', index=False)\n",
    "\n",
    "print(\"Готово! Файл создан\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lp4nfRMKiqQn",
    "outputId": "6044887b-e6a9-47f1-979e-19bb91c6cd7a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "новые фичи добавлены, всего: 22\n",
      "Обучаем модель v2...\n",
      "0:\tlearn: 1.9295076\ttotal: 26.7ms\tremaining: 53.3s\n",
      "200:\tlearn: 0.4499014\ttotal: 2.81s\tremaining: 25.2s\n",
      "400:\tlearn: 0.4157704\ttotal: 5.36s\tremaining: 21.4s\n",
      "600:\tlearn: 0.3967554\ttotal: 9.73s\tremaining: 22.7s\n",
      "800:\tlearn: 0.3793959\ttotal: 12.5s\tremaining: 18.7s\n",
      "1000:\tlearn: 0.3721424\ttotal: 15.6s\tremaining: 15.6s\n",
      "1200:\tlearn: 0.3631828\ttotal: 18.5s\tremaining: 12.3s\n",
      "1400:\tlearn: 0.3555950\ttotal: 23.5s\tremaining: 10s\n",
      "1600:\tlearn: 0.3494877\ttotal: 26.5s\tremaining: 6.6s\n",
      "1800:\tlearn: 0.3439905\ttotal: 29.4s\tremaining: 3.25s\n",
      "1999:\tlearn: 0.3389969\ttotal: 32.2s\tremaining: 0us\n",
      "Готово! Файл создан\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# обновленная сборка\n",
    "df_v3 = pd.concat([train, test], ignore_index=True)\n",
    "df_v3 = df_v3.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_v3 = df_v3.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "# работа с NaN как в прошлой версии\n",
    "df_v3['marketing_costs_lag_1'] = df_v3['marketing_costs_lag_1'].fillna(0)\n",
    "df_v3['flag_high_load_lag_1'] = df_v3['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# прогноз дефицита: сколько надо по прогнозу - сколько выходило на прошлой неделе\n",
    "df_v3['heuristic_diff'] = df_v3['predicted_staff_value'] - df_v3['fact_couriers_with_shifts_lag_1']\n",
    "\n",
    "# насколько вырос план по заказам относительно факта\n",
    "df_v3['orders_increase_ratio'] = df_v3['predicted_num_orders'] / (df_v3['fact_num_orders_lag_1'] + 1)\n",
    "\n",
    "# остальные полезные фичи\n",
    "df_v3['month'] = df_v3['calendar_dt'].dt.month\n",
    "df_v3['week_of_year'] = df_v3['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "df_v3['churn_ratio'] = df_v3['fact_staff_churn'] / (df_v3['fact_staff_value_lag_1'] + 1)\n",
    "\n",
    "# проверяем  перед отправкой\n",
    "print(\"запуск локальной валидации\")\n",
    "\n",
    "# определяем фичи\n",
    "drop_cols = ['calendar_dt', 'target', 'is_train']\n",
    "features = [c for c in df_v3.columns if c not in drop_cols]\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "\n",
    "# берем только тренировочные данные\n",
    "train_full = df_v3[df_v3['is_train'] == 1].copy()\n",
    "\n",
    "# отрезаем последнюю доступную дату в train для проверки\n",
    "last_date = train_full['calendar_dt'].max()\n",
    "print(f\"дата для проверки: {last_date}\")\n",
    "\n",
    "X_train_local = train_full[train_full['calendar_dt'] < last_date][features]\n",
    "y_train_local = train_full[train_full['calendar_dt'] < last_date]['target']\n",
    "\n",
    "X_val_local = train_full[train_full['calendar_dt'] == last_date][features]\n",
    "y_val_local = train_full[train_full['calendar_dt'] == last_date]['target']\n",
    "\n",
    "# обучаем проверочную модель\n",
    "val_model = CatBoostRegressor(\n",
    "    iterations=1500,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    cat_features=cat_features,\n",
    "    loss_function='MAE',\n",
    "    verbose=200,\n",
    "    random_seed=42\n",
    ")\n",
    "val_model.fit(X_train_local, y_train_local)\n",
    "\n",
    "# проверяем качество\n",
    "preds_val = val_model.predict(X_val_local)\n",
    "preds_val = np.maximum(preds_val, 0) # убираем отрицательные\n",
    "\n",
    "# считаем WAPE по формуле\n",
    "wape = np.sum(np.abs(y_val_local - preds_val)) / np.sum(np.abs(y_val_local))\n",
    "print(f\"ЛОКАЛЬНЫЙ WAPE: {wape:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2PWSwlyk_fP",
    "outputId": "01fd623a-5290-4515-c1ab-0feb059e9494"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "запуск локальной валидации\n",
      "дата для проверки: 2025-11-17 00:00:00\n",
      "0:\tlearn: 1.9036886\ttotal: 13.1ms\tremaining: 19.7s\n",
      "200:\tlearn: 0.4241836\ttotal: 1.54s\tremaining: 9.93s\n",
      "400:\tlearn: 0.3956460\ttotal: 4.31s\tremaining: 11.8s\n",
      "600:\tlearn: 0.3713680\ttotal: 6.85s\tremaining: 10.3s\n",
      "800:\tlearn: 0.3571895\ttotal: 8.54s\tremaining: 7.45s\n",
      "1000:\tlearn: 0.3465110\ttotal: 10.1s\tremaining: 5.05s\n",
      "1200:\tlearn: 0.3391874\ttotal: 11.8s\tremaining: 2.92s\n",
      "1400:\tlearn: 0.3325068\ttotal: 13.3s\tremaining: 939ms\n",
      "1499:\tlearn: 0.3297866\ttotal: 14.1s\tremaining: 0us\n",
      "ЛОКАЛЬНЫЙ WAPE: 0.18200\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# копируем датасет из прошлой версии\n",
    "df_v4 = df_v3.copy()\n",
    "\n",
    "# считаем средний дефицит для каждого магазина по трейну\n",
    "store_history = train.groupby('store_id')['target'].mean().reset_index()\n",
    "store_history.columns = ['store_id', 'store_mean_deficit']\n",
    "\n",
    "# приклеиваем это знание ко всему датасету\n",
    "df_v4 = df_v4.merge(store_history, on='store_id', how='left')\n",
    "\n",
    "# если магазин новый и нет его истории заполняем общим средним по всем магазинам\n",
    "global_mean = train['target'].mean()\n",
    "df_v4['store_mean_deficit'] = df_v4['store_mean_deficit'].fillna(global_mean)\n",
    "\n",
    "# считаем средний процент опозданий в каждом городе\n",
    "city_stats = df_v4.groupby('city_nm')['fact_percent_lateness_lag_1'].transform('mean')\n",
    "df_v4['city_mean_lateness'] = city_stats\n",
    "\n",
    "# сколько заказов приходится на одного курьера, который предложил услуги\n",
    "# +1 чтобы не делить на ноль\n",
    "df_v4['orders_per_available_courier'] = df_v4['predicted_num_orders'] / (df_v4['num_available_couriers_lag_1'] + 1)\n",
    "\n",
    "print(\"проверка версии v4\")\n",
    "\n",
    "features_v4 = features + ['store_mean_deficit', 'city_mean_lateness', 'orders_per_available_courier']\n",
    "print(f\"количество фич: {len(features_v4)}\")\n",
    "\n",
    "# делим на трейн и валидацию по времени\n",
    "train_full = df_v4[df_v4['is_train'] == 1].copy()\n",
    "last_date = train_full['calendar_dt'].max()\n",
    "\n",
    "X_train_local = train_full[train_full['calendar_dt'] < last_date][features_v4]\n",
    "y_train_local = train_full[train_full['calendar_dt'] < last_date]['target']\n",
    "\n",
    "X_val_local = train_full[train_full['calendar_dt'] == last_date][features_v4]\n",
    "y_val_local = train_full[train_full['calendar_dt'] == last_date]['target']\n",
    "\n",
    "# обучаем\n",
    "model_v4_test = CatBoostRegressor(\n",
    "    iterations=2000,          # чуть больше итераций\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    cat_features=cat_features,\n",
    "    loss_function='MAE',\n",
    "    verbose=200,\n",
    "    random_seed=42\n",
    ")\n",
    "model_v4_test.fit(X_train_local, y_train_local)\n",
    "\n",
    "# проверяем WAPE\n",
    "preds_val_v4 = model_v4_test.predict(X_val_local)\n",
    "preds_val_v4 = np.maximum(preds_val_v4, 0)\n",
    "wape_v4 = np.sum(np.abs(y_val_local - preds_val_v4)) / np.sum(np.abs(y_val_local))\n",
    "\n",
    "print(f\"ЛОКАЛЬНЫЙ WAPE V4: {wape_v4:.5f}\")\n",
    "print(f\"(прошлый результат 0.18200)\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6-ADPUWNmQ9H",
    "outputId": "98e30147-20ad-4928-80f2-b8da56cce813"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "проверка версии v4\n",
      "количество фич: 23\n",
      "0:\tlearn: 1.8973576\ttotal: 35.7ms\tremaining: 1m 11s\n",
      "200:\tlearn: 0.3999850\ttotal: 2.7s\tremaining: 24.2s\n",
      "400:\tlearn: 0.3523955\ttotal: 4.41s\tremaining: 17.6s\n",
      "600:\tlearn: 0.3261400\ttotal: 6.06s\tremaining: 14.1s\n",
      "800:\tlearn: 0.3167267\ttotal: 7.73s\tremaining: 11.6s\n",
      "1000:\tlearn: 0.3074254\ttotal: 9.47s\tremaining: 9.45s\n",
      "1200:\tlearn: 0.3007418\ttotal: 11.2s\tremaining: 7.43s\n",
      "1400:\tlearn: 0.2946388\ttotal: 14.5s\tremaining: 6.18s\n",
      "1600:\tlearn: 0.2890979\ttotal: 16.8s\tremaining: 4.19s\n",
      "1800:\tlearn: 0.2846418\ttotal: 18.5s\tremaining: 2.04s\n",
      "1999:\tlearn: 0.2802278\ttotal: 20.2s\tremaining: 0us\n",
      "ЛОКАЛЬНЫЙ WAPE V4: 0.16966\n",
      "(прошлый результат 0.18200)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# обучение на всех данных\n",
    "\n",
    "# берем фичи которые дали 0.169\n",
    "features_v4 = features + ['store_mean_deficit', 'city_mean_lateness', 'orders_per_available_courier']\n",
    "print(f\"обучим модель на {len(features_v4)} признаках\")\n",
    "\n",
    "# берем весь трейн\n",
    "X_train_full_v4 = df_v4[df_v4['is_train'] == 1][features_v4]\n",
    "y_train_full_v4 = df_v4[df_v4['is_train'] == 1]['target']\n",
    "X_test_final_v4 = df_v4[df_v4['is_train'] == 0][features_v4]\n",
    "\n",
    "# инициализируем модель\n",
    "model_v4 = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    cat_features=cat_features,\n",
    "    loss_function='MAE',\n",
    "    verbose=200,\n",
    "    random_seed=42\n",
    ")\n",
    "\n",
    "# обучаем\n",
    "model_v4.fit(X_train_full_v4, y_train_full_v4)\n",
    "\n",
    "# предсказываем\n",
    "final_preds_v4 = model_v4.predict(X_test_final_v4)\n",
    "final_preds_v4 = np.maximum(final_preds_v4, 0) # уберем отрицательные\n",
    "\n",
    "# сохраняем\n",
    "submission_v4 = pd.DataFrame({\n",
    "    'store_id': test['store_id'],\n",
    "    'target': final_preds_v4\n",
    "})\n",
    "submission_v4 =submission_v4.sort_values(by='store_id')\n",
    "submission_v4.to_csv('submission_v4_history.csv', index=False)\n",
    "\n",
    "print(\"Файл готов!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8qyRoeuhnarP",
    "outputId": "cca5383e-8962-4592-b1bc-53987ff918ff"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "обучим модель на 23 признаках\n",
      "0:\tlearn: 1.9153434\ttotal: 28.9ms\tremaining: 57.8s\n",
      "200:\tlearn: 0.4009222\ttotal: 2.02s\tremaining: 18.1s\n",
      "400:\tlearn: 0.3668331\ttotal: 5.13s\tremaining: 20.5s\n",
      "600:\tlearn: 0.3473226\ttotal: 8.18s\tremaining: 19s\n",
      "800:\tlearn: 0.3378854\ttotal: 10.4s\tremaining: 15.5s\n",
      "1000:\tlearn: 0.3300461\ttotal: 12.4s\tremaining: 12.4s\n",
      "1200:\tlearn: 0.3238339\ttotal: 14.5s\tremaining: 9.63s\n",
      "1400:\tlearn: 0.3179766\ttotal: 16.6s\tremaining: 7.1s\n",
      "1600:\tlearn: 0.3131660\ttotal: 20.9s\tremaining: 5.22s\n",
      "1800:\tlearn: 0.3086650\ttotal: 23s\tremaining: 2.54s\n",
      "1999:\tlearn: 0.3041562\ttotal: 25.1s\tremaining: 0us\n",
      "Файл готов!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# берем чистый датасет как в V3\n",
    "df_v5 = pd.concat([train, test], ignore_index=True)\n",
    "df_v5 = df_v5.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_v5 = df_v5.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "# обработка пропусков\n",
    "df_v5['marketing_costs_lag_1'] = df_v5['marketing_costs_lag_1'].fillna(0)\n",
    "df_v5['flag_high_load_lag_1'] = df_v5['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# те фичи, что сработали в V3 + одна новая\n",
    "\n",
    "# V3\n",
    "df_v5['heuristic_diff'] = df_v5['predicted_staff_value'] - df_v5['fact_couriers_with_shifts_lag_1']\n",
    "df_v5['orders_increase_ratio'] = df_v5['predicted_num_orders'] / (df_v5['fact_num_orders_lag_1'] + 1)\n",
    "df_v5['churn_ratio'] = df_v5['fact_staff_churn'] / (df_v5['fact_staff_value_lag_1'] + 1)\n",
    "\n",
    "# считаем среднее опоздание в городе зная facts\n",
    "df_v5['city_lateness_lag'] = df_v5.groupby('city_nm')['fact_percent_lateness_lag_1'].transform('median')\n",
    "\n",
    "# дата\n",
    "df_v5['month'] = df_v5['calendar_dt'].dt.month\n",
    "df_v5['week_of_year'] = df_v5['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "print(\"запуск валидации V5\")\n",
    "\n",
    "drop_cols = ['calendar_dt', 'target', 'is_train']\n",
    "features_v5 = [c for c in df_v5.columns if c not in drop_cols]\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "\n",
    "# делим\n",
    "train_full = df_v5[df_v5['is_train'] == 1].copy()\n",
    "last_date = train_full['calendar_dt'].max()\n",
    "\n",
    "X_train_local = train_full[train_full['calendar_dt'] < last_date][features_v5]\n",
    "y_train_local = train_full[train_full['calendar_dt'] < last_date]['target']\n",
    "\n",
    "X_val_local = train_full[train_full['calendar_dt'] == last_date][features_v5]\n",
    "y_val_local = train_full[train_full['calendar_dt'] == last_date]['target']\n",
    "\n",
    "# параметры берем от V3\n",
    "model_v5_val = CatBoostRegressor(\n",
    "    iterations=1600,        # чуть добавили, тк фич больше\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    cat_features=cat_features,\n",
    "    loss_function='MAE',\n",
    "    verbose=200,\n",
    "    random_seed=42\n",
    ")\n",
    "model_v5_val.fit(X_train_local, y_train_local)\n",
    "\n",
    "# проверка\n",
    "preds_val = model_v5_val.predict(X_val_local)\n",
    "preds_val = np.maximum(preds_val, 0)\n",
    "wape_v5 = np.sum(np.abs(y_val_local - preds_val)) / np.sum(np.abs(y_val_local))\n",
    "\n",
    "print(f\"WAPE V5: {wape_v5:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aYoC2QUUo8jN",
    "outputId": "a0ad8f8c-de5f-4ff0-df09-608e90ef86b0"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "запуск валидации V5\n",
      "0:\tlearn: 1.8931542\ttotal: 13.3ms\tremaining: 21.3s\n",
      "200:\tlearn: 0.4277359\ttotal: 1.46s\tremaining: 10.1s\n",
      "400:\tlearn: 0.3942181\ttotal: 2.97s\tremaining: 8.89s\n",
      "600:\tlearn: 0.3682781\ttotal: 4.64s\tremaining: 7.71s\n",
      "800:\tlearn: 0.3558293\ttotal: 6.24s\tremaining: 6.22s\n",
      "1000:\tlearn: 0.3454144\ttotal: 9.74s\tremaining: 5.83s\n",
      "1200:\tlearn: 0.3367901\ttotal: 12.6s\tremaining: 4.18s\n",
      "1400:\tlearn: 0.3297198\ttotal: 14.2s\tremaining: 2.01s\n",
      "1599:\tlearn: 0.3231709\ttotal: 16.3s\tremaining: 0us\n",
      "WAPE V5: 0.18348\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# V3 пока что лучшая версия\n",
    "\n",
    "# собираем данные\n",
    "df_final = pd.concat([train, test], ignore_index=True)\n",
    "df_final = df_final.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_final = df_final.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "# заполняем NaN\n",
    "df_final['marketing_costs_lag_1'] = df_final['marketing_costs_lag_1'].fillna(0)\n",
    "df_final['flag_high_load_lag_1'] = df_final['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# только те фичи, что были в V3\n",
    "df_final['heuristic_diff'] = df_final['predicted_staff_value'] - df_final['fact_couriers_with_shifts_lag_1']\n",
    "# рост заказов\n",
    "df_final['orders_increase_ratio'] = df_final['predicted_num_orders'] / (df_final['fact_num_orders_lag_1'] + 1)\n",
    "# текучка кадров\n",
    "df_final['churn_ratio'] = df_final['fact_staff_churn'] / (df_final['fact_staff_value_lag_1'] + 1)\n",
    "# даты\n",
    "df_final['month'] = df_final['calendar_dt'].dt.month\n",
    "df_final['week_of_year'] = df_final['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# список фичей\n",
    "features_final = ['store_id', 'fact_staff_value_lag_1', 'fact_load_factor_lag_1',\n",
    "                  'num_available_couriers_lag_1', 'fact_num_orders_lag_1',\n",
    "                  'fact_percent_lateness_lag_1', 'city_nm', 'store_lifetime_in_days',\n",
    "                  'fact_staff_churn', 'flag_high_load_lag_1', 'marketing_costs_lag_1',\n",
    "                  'fact_couriers_with_shifts_lag_1', 'predicted_staff_value',\n",
    "                  'predicted_num_orders', 'predicted_load_factor', 'month',\n",
    "                  'week_of_year', 'heuristic_diff', 'orders_increase_ratio', 'churn_ratio']\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "\n",
    "# обучение на всем трейне\n",
    "print(\"обучаем модель V3\")\n",
    "X_train = df_final[df_final['is_train'] == 1][features_final]\n",
    "y_train = df_final[df_final['is_train'] == 1]['target']\n",
    "X_test = df_final[df_final['is_train'] == 0][features_final]\n",
    "\n",
    "model_v3_final = CatBoostRegressor(\n",
    "    iterations=1600,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    cat_features=cat_features,\n",
    "    loss_function='MAE',\n",
    "    verbose=200,\n",
    "    random_seed=42\n",
    ")\n",
    "model_v3_final.fit(X_train, y_train)\n",
    "\n",
    "# прогноз\n",
    "preds = model_v3_final.predict(X_test)\n",
    "preds = np.maximum(preds, 0)\n",
    "\n",
    "# сохранение\n",
    "sub = pd.DataFrame({'store_id': test['store_id'], 'target': preds})\n",
    "sub = sub.sort_values(by='store_id')\n",
    "sub.to_csv('submission_v3_final.csv', index=False)\n",
    "print(\"Файл готов!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HuyXSu5sppTS",
    "outputId": "26c617aa-ee98-47f7-8b71-daa75ec35901"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "обучаем модель V3\n",
      "0:\tlearn: 1.9121974\ttotal: 19.7ms\tremaining: 31.4s\n",
      "200:\tlearn: 0.4341427\ttotal: 4.8s\tremaining: 33.4s\n",
      "400:\tlearn: 0.4111961\ttotal: 6.64s\tremaining: 19.9s\n",
      "600:\tlearn: 0.3912670\ttotal: 8.56s\tremaining: 14.2s\n",
      "800:\tlearn: 0.3797837\ttotal: 10.6s\tremaining: 10.5s\n",
      "1000:\tlearn: 0.3712788\ttotal: 12.7s\tremaining: 7.61s\n",
      "1200:\tlearn: 0.3649965\ttotal: 16.4s\tremaining: 5.46s\n",
      "1400:\tlearn: 0.3594438\ttotal: 19.2s\tremaining: 2.72s\n",
      "1599:\tlearn: 0.3543560\ttotal: 21.3s\tremaining: 0us\n",
      "Файл готов!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# собираем данные\n",
    "df_check = pd.concat([train, test], ignore_index=True)\n",
    "df_check = df_check.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_check = df_check.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "# NaN\n",
    "df_check['marketing_costs_lag_1'] = df_check['marketing_costs_lag_1'].fillna(0)\n",
    "df_check['flag_high_load_lag_1'] = df_check['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# фичи\n",
    "df_check['heuristic_diff'] = df_check['predicted_staff_value'] - df_check['fact_couriers_with_shifts_lag_1']\n",
    "df_check['orders_increase_ratio'] = df_check['predicted_num_orders'] / (df_check['fact_num_orders_lag_1'] + 1)\n",
    "df_check['churn_ratio'] = df_check['fact_staff_churn'] / (df_check['fact_staff_value_lag_1'] + 1)\n",
    "df_check['month'] = df_check['calendar_dt'].dt.month\n",
    "df_check['week_of_year'] = df_check['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "features_check = ['store_id', 'fact_staff_value_lag_1', 'fact_load_factor_lag_1',\n",
    "                  'num_available_couriers_lag_1', 'fact_num_orders_lag_1',\n",
    "                  'fact_percent_lateness_lag_1', 'city_nm', 'store_lifetime_in_days',\n",
    "                  'fact_staff_churn', 'flag_high_load_lag_1', 'marketing_costs_lag_1',\n",
    "                  'fact_couriers_with_shifts_lag_1', 'predicted_staff_value',\n",
    "                  'predicted_num_orders', 'predicted_load_factor', 'month',\n",
    "                  'week_of_year', 'heuristic_diff', 'orders_increase_ratio', 'churn_ratio']\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "\n",
    "# делим на трейн и валидацию (последняя неделя)\n",
    "train_full = df_check[df_check['is_train'] == 1].copy()\n",
    "last_date = train_full['calendar_dt'].max()\n",
    "\n",
    "X_train_local = train_full[train_full['calendar_dt'] < last_date][features_check]\n",
    "y_train_local = train_full[train_full['calendar_dt'] < last_date]['target']\n",
    "\n",
    "X_val_local = train_full[train_full['calendar_dt'] == last_date][features_check]\n",
    "y_val_local = train_full[train_full['calendar_dt'] == last_date]['target']\n",
    "\n",
    "# запускаем цикл\n",
    "SEEDS = [42, 2023, 777, 1, 555]\n",
    "val_preds_sum = np.zeros(len(X_val_local))\n",
    "single_model_score = 0\n",
    "\n",
    "print(f\" сравним одиночную модель и ансамбль ({len(SEEDS)})\")\n",
    "\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    # обучаем\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1600, learning_rate=0.03, depth=6,\n",
    "        cat_features=cat_features, loss_function='MAE',\n",
    "        random_seed=seed, verbose=0, allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_local, y_train_local)\n",
    "\n",
    "    # предсказываем\n",
    "    p = model.predict(X_val_local)\n",
    "    p = np.maximum(p, 0)\n",
    "\n",
    "    # результат первого сида запомним отдельно\n",
    "    if seed == 42:\n",
    "        wape_single = np.sum(np.abs(y_val_local - p)) / np.sum(np.abs(y_val_local))\n",
    "        print(f\"Seed 42 (Single Model) WAPE: {wape_single:.5f}\")\n",
    "        single_model_score = wape_single\n",
    "\n",
    "    val_preds_sum += p\n",
    "\n",
    "# результат ансамбля\n",
    "ensemble_preds = val_preds_sum / len(SEEDS)\n",
    "wape_ensemble = np.sum(np.abs(y_val_local - ensemble_preds)) / np.sum(np.abs(y_val_local))\n",
    "\n",
    "print(f\"\\nИТОГ:\")\n",
    "print(f\"одиночная модель: {single_model_score:.5f}\")\n",
    "print(f\"ансамбль (average): {wape_ensemble:.5f}\")\n",
    "\n",
    "diff = single_model_score - wape_ensemble\n",
    "if diff > 0:\n",
    "    print(f\"ансамбль снизил ошибку на {diff:.5f}\")\n",
    "else:\n",
    "    print(f\"нет улучшения, ансамбль не помог\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kDMiXzd1ryA4",
    "outputId": "b1b86dbc-2272-475f-bee7-446609b8c977"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " сравним одиночную модель и ансамбль (5\n",
      "Seed 42 (Single Model) WAPE: 0.18148\n",
      "\n",
      "ИТОГ:\n",
      "одиночная модель: 0.18148\n",
      "ансамбль (average): 0.18092\n",
      "ансамбль снизил ошибку на 0.00056\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# собираем базу\n",
    "df_v7 = pd.concat([train, test], ignore_index=True)\n",
    "df_v7 = df_v7.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_v7 = df_v7.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "# NaN\n",
    "df_v7['marketing_costs_lag_1'] = df_v7['marketing_costs_lag_1'].fillna(0)\n",
    "df_v7['flag_high_load_lag_1'] = df_v7['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# создаем колонку с NaN\n",
    "df_v7['store_mean_deficit_kfold'] = np.nan\n",
    "\n",
    "# работаем с трейном для обучения кодировщика\n",
    "train_indices = df_v7[df_v7['is_train'] == 1].index\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ЦИКЛ ПО ФОЛДАМ\n",
    "for train_idx, val_idx in kf.split(train_indices):\n",
    "    # получаем индексы из общего датафрейма\n",
    "    global_train_idx = train_indices[train_idx]\n",
    "    global_val_idx = train_indices[val_idx]\n",
    "\n",
    "    # считаем среднее на обучающей части фолда\n",
    "    means = df_v7.loc[global_train_idx].groupby('store_id')['target'].mean()\n",
    "\n",
    "    # применяем на валидационную часть\n",
    "    df_v7.loc[global_val_idx, 'store_mean_deficit_kfold'] = df_v7.loc[global_val_idx, 'store_id'].map(means)\n",
    "\n",
    "# Для теста берем среднее по всему трейну\n",
    "global_means = df_v7[df_v7['is_train'] == 1].groupby('store_id')['target'].mean()\n",
    "test_indices = df_v7[df_v7['is_train'] == 0].index\n",
    "df_v7.loc[test_indices, 'store_mean_deficit_kfold'] = df_v7.loc[test_indices, 'store_id'].map(global_means)\n",
    "\n",
    "# заполняем пропуски общим средним\n",
    "df_v7['store_mean_deficit_kfold'] = df_v7['store_mean_deficit_kfold'].fillna(df_v7[df_v7['is_train']==1]['target'].mean())\n",
    "\n",
    "# остальные фичи V3\n",
    "df_v7['heuristic_diff'] = df_v7['predicted_staff_value'] - df_v7['fact_couriers_with_shifts_lag_1']\n",
    "df_v7['orders_increase_ratio'] = df_v7['predicted_num_orders'] / (df_v7['fact_num_orders_lag_1'] + 1)\n",
    "df_v7['churn_ratio'] = df_v7['fact_staff_churn'] / (df_v7['fact_staff_value_lag_1'] + 1)\n",
    "df_v7['month'] = df_v7['calendar_dt'].dt.month\n",
    "df_v7['week_of_year'] = df_v7['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# список фичей с новой крутой\n",
    "features_v7 = ['store_id', 'fact_staff_value_lag_1', 'fact_load_factor_lag_1',\n",
    "               'num_available_couriers_lag_1', 'fact_num_orders_lag_1',\n",
    "               'fact_percent_lateness_lag_1', 'city_nm', 'store_lifetime_in_days',\n",
    "               'fact_staff_churn', 'flag_high_load_lag_1', 'marketing_costs_lag_1',\n",
    "               'fact_couriers_with_shifts_lag_1', 'predicted_staff_value',\n",
    "               'predicted_num_orders', 'predicted_load_factor', 'month',\n",
    "               'week_of_year', 'heuristic_diff', 'orders_increase_ratio', 'churn_ratio',\n",
    "               'store_mean_deficit_kfold']\n",
    "\n",
    "# локальная валидация V7\n",
    "print(\"проверка V7\")\n",
    "train_full = df_v7[df_v7['is_train'] == 1].copy()\n",
    "last_date = train_full['calendar_dt'].max()\n",
    "\n",
    "X_train_local = train_full[train_full['calendar_dt'] < last_date][features_v7]\n",
    "y_train_local = train_full[train_full['calendar_dt'] < last_date]['target']\n",
    "\n",
    "X_val_local = train_full[train_full['calendar_dt'] == last_date][features_v7]\n",
    "y_val_local = train_full[train_full['calendar_dt'] == last_date]['target']\n",
    "\n",
    "# обучаем\n",
    "model_v7 = CatBoostRegressor(\n",
    "    iterations=2000, learning_rate=0.03, depth=6,\n",
    "    cat_features=['store_id', 'city_nm'], loss_function='MAE',\n",
    "    verbose=200, random_seed=42\n",
    ")\n",
    "model_v7.fit(X_train_local, y_train_local)\n",
    "\n",
    "preds_v7 = model_v7.predict(X_val_local)\n",
    "preds_v7 = np.maximum(preds_v7, 0)\n",
    "wape_v7 = np.sum(np.abs(y_val_local - preds_v7)) / np.sum(np.abs(y_val_local))\n",
    "\n",
    "print(f\"WAPE V7: {wape_v7:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EaDnqhJ_tWpw",
    "outputId": "e6fe430f-1714-4eb6-da0c-d55b029d6d9c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "проверка V7\n",
      "0:\tlearn: 1.8919918\ttotal: 12ms\tremaining: 24.1s\n",
      "200:\tlearn: 0.4166800\ttotal: 1.55s\tremaining: 13.9s\n",
      "400:\tlearn: 0.3810636\ttotal: 3.14s\tremaining: 12.5s\n",
      "600:\tlearn: 0.3530652\ttotal: 7.18s\tremaining: 16.7s\n",
      "800:\tlearn: 0.3405362\ttotal: 10.6s\tremaining: 15.9s\n",
      "1000:\tlearn: 0.3311268\ttotal: 12.4s\tremaining: 12.3s\n",
      "1200:\tlearn: 0.3234823\ttotal: 14s\tremaining: 9.34s\n",
      "1400:\tlearn: 0.3172832\ttotal: 15.8s\tremaining: 6.74s\n",
      "1600:\tlearn: 0.3111965\ttotal: 17.5s\tremaining: 4.35s\n",
      "1800:\tlearn: 0.3066405\ttotal: 19.2s\tremaining: 2.12s\n",
      "1999:\tlearn: 0.3026059\ttotal: 21.8s\tremaining: 0us\n",
      "WAPE V7: 0.18769\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# V8 подбор параметров\n",
    "\n",
    "# собираем данные (как в V3)\n",
    "df_tune = pd.concat([train, test], ignore_index=True)\n",
    "df_tune = df_tune.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_tune = df_tune.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "df_tune['marketing_costs_lag_1'] = df_tune['marketing_costs_lag_1'].fillna(0)\n",
    "df_tune['flag_high_load_lag_1'] = df_tune['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# фичи V3\n",
    "df_tune['heuristic_diff'] = df_tune['predicted_staff_value'] - df_tune['fact_couriers_with_shifts_lag_1']\n",
    "df_tune['orders_increase_ratio'] = df_tune['predicted_num_orders'] / (df_tune['fact_num_orders_lag_1'] + 1)\n",
    "df_tune['churn_ratio'] = df_tune['fact_staff_churn'] / (df_tune['fact_staff_value_lag_1'] + 1)\n",
    "df_tune['month'] = df_tune['calendar_dt'].dt.month\n",
    "df_tune['week_of_year'] = df_tune['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "# список фич\n",
    "features_tune = ['store_id', 'fact_staff_value_lag_1', 'fact_load_factor_lag_1',\n",
    "                 'num_available_couriers_lag_1', 'fact_num_orders_lag_1',\n",
    "                 'fact_percent_lateness_lag_1', 'city_nm', 'store_lifetime_in_days',\n",
    "                 'fact_staff_churn', 'flag_high_load_lag_1', 'marketing_costs_lag_1',\n",
    "                 'fact_couriers_with_shifts_lag_1', 'predicted_staff_value',\n",
    "                 'predicted_num_orders', 'predicted_load_factor', 'month',\n",
    "                 'week_of_year', 'heuristic_diff', 'orders_increase_ratio', 'churn_ratio']\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "\n",
    "# подготовка валидации (последняя неделя)\n",
    "train_full = df_tune[df_tune['is_train'] == 1].copy()\n",
    "last_date = train_full['calendar_dt'].max()\n",
    "\n",
    "X_train_local = train_full[train_full['calendar_dt'] < last_date][features_tune]\n",
    "y_train_local = train_full[train_full['calendar_dt'] < last_date]['target']\n",
    "\n",
    "X_val_local = train_full[train_full['calendar_dt'] == last_date][features_tune]\n",
    "y_val_local = train_full[train_full['calendar_dt'] == last_date]['target']\n",
    "\n",
    "# ПЕРЕБОР ПАРАМЕТРОВ\n",
    "depths = [4, 6, 8, 10]\n",
    "lrs = [0.03, 0.05]\n",
    "\n",
    "best_wape = 999\n",
    "best_params = {}\n",
    "\n",
    "print(f\"поиск идеальных параметров\")\n",
    "print(f\"базовый результат V3 был примерно 0.18148\")\n",
    "\n",
    "for d in depths:\n",
    "    for lr in lrs:\n",
    "        print(f\"\\nпроверяем: Depth = {d}, LR = {lr}\")\n",
    "\n",
    "        model = CatBoostRegressor(\n",
    "            iterations=1500,\n",
    "            learning_rate=lr,\n",
    "            depth=d,\n",
    "            cat_features=cat_features,\n",
    "            loss_function='MAE',\n",
    "            verbose=0, # Молчун\n",
    "            random_seed=42,\n",
    "            allow_writing_files=False\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_local, y_train_local)\n",
    "\n",
    "        preds = model.predict(X_val_local)\n",
    "        preds = np.maximum(preds, 0)\n",
    "\n",
    "        current_wape = np.sum(np.abs(y_val_local - preds)) / np.sum(np.abs(y_val_local))\n",
    "        print(f\"результат: {current_wape:.5f}\")\n",
    "\n",
    "        if current_wape < best_wape:\n",
    "            best_wape = current_wape\n",
    "            best_params = {'depth': d, 'learning_rate': lr}\n",
    "\n",
    "print(f\"\\nЛУЧШИЙ РЕЗУЛЬТАТ: {best_wape:.5f}\")\n",
    "print(f\"с параметрами: {best_params}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXLXXV6rvMcr",
    "outputId": "b8045d39-eeaf-49dc-ecb4-8d4bd8795a74"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "поиск идеальных параметров\n",
      "базовый результат V3 был примерно 0.18148\n",
      "\n",
      "проверяем: Depth = 4, LR = 0.03\n",
      "результат: 0.17582\n",
      "\n",
      "проверяем: Depth = 4, LR = 0.05\n",
      "результат: 0.18070\n",
      "\n",
      "проверяем: Depth = 6, LR = 0.03\n",
      "результат: 0.18033\n",
      "\n",
      "проверяем: Depth = 6, LR = 0.05\n",
      "результат: 0.18355\n",
      "\n",
      "проверяем: Depth = 8, LR = 0.03\n",
      "результат: 0.20174\n",
      "\n",
      "проверяем: Depth = 8, LR = 0.05\n",
      "результат: 0.19218\n",
      "\n",
      "проверяем: Depth = 10, LR = 0.03\n",
      "результат: 0.20051\n",
      "\n",
      "проверяем: Depth = 10, LR = 0.05\n",
      "результат: 0.20694\n",
      "\n",
      "ЛУЧШИЙ РЕЗУЛЬТАТ: 0.17582\n",
      "с параметрами: {'depth': 4, 'learning_rate': 0.03}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# V9 с подходящими параметрами\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# сборка данных\n",
    "df_final = pd.concat([train, test], ignore_index=True)\n",
    "df_final = df_final.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_final = df_final.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "df_final['marketing_costs_lag_1'] = df_final['marketing_costs_lag_1'].fillna(0)\n",
    "df_final['flag_high_load_lag_1'] = df_final['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# фичи как в V3\n",
    "df_final['heuristic_diff'] = df_final['predicted_staff_value'] - df_final['fact_couriers_with_shifts_lag_1']\n",
    "df_final['orders_increase_ratio'] = df_final['predicted_num_orders'] / (df_final['fact_num_orders_lag_1'] + 1)\n",
    "df_final['churn_ratio'] = df_final['fact_staff_churn'] / (df_final['fact_staff_value_lag_1'] + 1)\n",
    "df_final['month'] = df_final['calendar_dt'].dt.month\n",
    "df_final['week_of_year'] = df_final['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "features_final = ['store_id', 'fact_staff_value_lag_1', 'fact_load_factor_lag_1',\n",
    "                  'num_available_couriers_lag_1', 'fact_num_orders_lag_1',\n",
    "                  'fact_percent_lateness_lag_1', 'city_nm', 'store_lifetime_in_days',\n",
    "                  'fact_staff_churn', 'flag_high_load_lag_1', 'marketing_costs_lag_1',\n",
    "                  'fact_couriers_with_shifts_lag_1', 'predicted_staff_value',\n",
    "                  'predicted_num_orders', 'predicted_load_factor', 'month',\n",
    "                  'week_of_year', 'heuristic_diff', 'orders_increase_ratio', 'churn_ratio']\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "\n",
    "# подготовка\n",
    "X_train = df_final[df_final['is_train'] == 1][features_final]\n",
    "y_train = df_final[df_final['is_train'] == 1]['target']\n",
    "X_test = df_final[df_final['is_train'] == 0][features_final]\n",
    "\n",
    "# с новыми параметрами\n",
    "SEEDS = [42, 2025, 777, 100, 999] # 5 разных стартов\n",
    "final_preds_sum = np.zeros(len(X_test))\n",
    "\n",
    "print(f\"старт\")\n",
    "\n",
    "for i, seed in enumerate(SEEDS):\n",
    "    print(f\"обучение {i+1}/5 (seed={seed})\")\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=2000,        # чуть больше итераций, тк дерево неглубокое\n",
    "        learning_rate=0.03,     # подходящая скорость\n",
    "        depth=4,\n",
    "        cat_features=cat_features,\n",
    "        loss_function='MAE',\n",
    "        random_seed=seed,\n",
    "        verbose=0,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    p = model.predict(X_test)\n",
    "    p = np.maximum(p, 0)\n",
    "    final_preds_sum += p\n",
    "\n",
    "# усредняем\n",
    "final_blend_preds = final_preds_sum / len(SEEDS)\n",
    "\n",
    "# сохраняем\n",
    "submission_v9 = pd.DataFrame({'store_id': test['store_id'], 'target': final_blend_preds})\n",
    "submission_v9 = submission_v9.sort_values(by='store_id')\n",
    "submission_v9.to_csv('submission_v9_best_params.csv', index=False)\n",
    "\n",
    "print(\"\\nФайл готов!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QdzgeEb7x0zM",
    "outputId": "2d981a7e-7b98-4ec0-fdd0-a37925735e00"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "старт\n",
      "обучение 1/5 (seed=42)\n",
      "обучение 2/5 (seed=2025)\n",
      "обучение 3/5 (seed=777)\n",
      "обучение 4/5 (seed=100)\n",
      "обучение 5/5 (seed=999)\n",
      "\n",
      "Файл готов!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# проверка пост обработки\n",
    "\n",
    "# подготовка данных (как в V9 и V3)\n",
    "df_check = pd.concat([train, test], ignore_index=True)\n",
    "df_check = df_check.merge(facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "df_check = df_check.merge(shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "# NaN\n",
    "df_check['marketing_costs_lag_1'] = df_check['marketing_costs_lag_1'].fillna(0)\n",
    "df_check['flag_high_load_lag_1'] = df_check['flag_high_load_lag_1'].fillna(0)\n",
    "\n",
    "# фичи\n",
    "df_check['heuristic_diff'] = df_check['predicted_staff_value'] - df_check['fact_couriers_with_shifts_lag_1']\n",
    "df_check['orders_increase_ratio'] = df_check['predicted_num_orders'] / (df_check['fact_num_orders_lag_1'] + 1)\n",
    "df_check['churn_ratio'] = df_check['fact_staff_churn'] / (df_check['fact_staff_value_lag_1'] + 1)\n",
    "df_check['month'] = df_check['calendar_dt'].dt.month\n",
    "df_check['week_of_year'] = df_check['calendar_dt'].dt.isocalendar().week.astype(int)\n",
    "\n",
    "features_check = ['store_id', 'fact_staff_value_lag_1', 'fact_load_factor_lag_1',\n",
    "                  'num_available_couriers_lag_1', 'fact_num_orders_lag_1',\n",
    "                  'fact_percent_lateness_lag_1', 'city_nm', 'store_lifetime_in_days',\n",
    "                  'fact_staff_churn', 'flag_high_load_lag_1', 'marketing_costs_lag_1',\n",
    "                  'fact_couriers_with_shifts_lag_1', 'predicted_staff_value',\n",
    "                  'predicted_num_orders', 'predicted_load_factor', 'month',\n",
    "                  'week_of_year', 'heuristic_diff', 'orders_increase_ratio', 'churn_ratio']\n",
    "\n",
    "# делим на трейн и валидацию\n",
    "train_full = df_check[df_check['is_train'] == 1].copy()\n",
    "last_date = train_full['calendar_dt'].max()\n",
    "\n",
    "X_train_local = train_full[train_full['calendar_dt'] < last_date][features_check]\n",
    "y_train_local = train_full[train_full['calendar_dt'] < last_date]['target']\n",
    "\n",
    "X_val_local = train_full[train_full['calendar_dt'] == last_date][features_check]\n",
    "y_val_local = train_full[train_full['calendar_dt'] == last_date]['target']\n",
    "\n",
    "# обучаем модель параметры V9\n",
    "print(\"обучаем модель для проверки порогов...\")\n",
    "model = CatBoostRegressor(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.03,\n",
    "    depth=4,\n",
    "    cat_features=['store_id', 'city_nm'],\n",
    "    loss_function='MAE',\n",
    "    verbose=0,\n",
    "    random_seed=42\n",
    ")\n",
    "model.fit(X_train_local, y_train_local)\n",
    "\n",
    "# получаем сырые предсказания\n",
    "raw_preds = model.predict(X_val_local)\n",
    "raw_preds = np.maximum(raw_preds, 0)\n",
    "\n",
    "# ЦИКЛ ПОИСКА ПОРОГА\n",
    "thresholds = [0.0, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6]\n",
    "\n",
    "print(f\"\\nрезультаты поиска порога\")\n",
    "print(f\"базовый WAPE: {np.sum(np.abs(y_val_local - raw_preds)) / np.sum(np.abs(y_val_local)):.5f}\")\n",
    "\n",
    "best_t = 0\n",
    "best_score = 1.0\n",
    "\n",
    "for t in thresholds:\n",
    "    # порог: если предсказание < t ставим 0\n",
    "    preds_t = np.array([0 if x < t else x for x in raw_preds])\n",
    "\n",
    "    # считаем WAPE\n",
    "    score = np.sum(np.abs(y_val_local - preds_t)) / np.sum(np.abs(y_val_local))\n",
    "\n",
    "    print(f\"порог {t}: WAPE = {score:.5f}\")\n",
    "\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_t = t\n",
    "\n",
    "print(f\"\\nЛУЧШИЙ ПОРОГ: {best_t}\")\n",
    "print(f\"с ним WAPE: {best_score:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qz9awYcczjgX",
    "outputId": "0fc03008-d652-4aa4-edf3-c3e6faa7d0a7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "обучаем модель для проверки порогов...\n",
      "\n",
      "результаты поиска порога\n",
      "базовый WAPE: 0.17619\n",
      "порог 0.0: WAPE = 0.17619\n",
      "порог 0.1: WAPE = 0.17585\n",
      "порог 0.15: WAPE = 0.17583\n",
      "порог 0.2: WAPE = 0.17577\n",
      "порог 0.25: WAPE = 0.17577\n",
      "порог 0.3: WAPE = 0.17573\n",
      "порог 0.35: WAPE = 0.17573\n",
      "порог 0.4: WAPE = 0.17568\n",
      "порог 0.45: WAPE = 0.17560\n",
      "порог 0.5: WAPE = 0.17560\n",
      "порог 0.6: WAPE = 0.17560\n",
      "\n",
      "ЛУЧШИЙ ПОРОГ: 0.45\n",
      "с ним WAPE: 0.17560\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# V10 с лучшим порогом\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# загружаем лучший сабмит V9\n",
    "sub = pd.read_csv('submission_v9_best_params.csv')\n",
    "\n",
    "print(\"Статистика ДО обработки:\")\n",
    "print(sub['target'].describe())\n",
    "\n",
    "# все, что меньше 0.45 превращаем в 0\n",
    "# все, что больше или равно оставляем как есть\n",
    "threshold = 0.45\n",
    "sub['target'] = sub['target'].apply(lambda x: 0 if x < threshold else x)\n",
    "\n",
    "print(\"\\nСтатистика ПОСЛЕ обработки:\")\n",
    "print(sub['target'].describe())\n",
    "\n",
    "# сохраняем\n",
    "sub.to_csv('submission_v10_threshold.csv', index=False)\n",
    "\n",
    "print(\"\\nФайл готов!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cA0Sh6Tn0fMI",
    "outputId": "0e50acd9-b22c-44f0-9d0d-6df03050d02e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Статистика ДО обработки:\n",
      "count    2438.000000\n",
      "mean        2.398030\n",
      "std         2.475156\n",
      "min         0.000000\n",
      "25%         0.002897\n",
      "50%         2.000266\n",
      "75%         4.009551\n",
      "max        14.606336\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Статистика ПОСЛЕ обработки:\n",
      "count    2438.000000\n",
      "mean        2.397348\n",
      "std         2.475811\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         2.000266\n",
      "75%         4.009551\n",
      "max        14.606336\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Файл готов!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ну допустим это черная пятница V11\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# грузим лучший V10\n",
    "sub = pd.read_csv('submission_v10_threshold.csv')\n",
    "\n",
    "print(\"средний дефицит до буста:\", sub['target'].mean())\n",
    "\n",
    "# добавляем 10% к прогнозу дефицита\n",
    "BOOST_FACTOR = 1.10\n",
    "\n",
    "sub['target'] = sub['target'] * BOOST_FACTOR\n",
    "\n",
    "print(\"средний дефицит после буста:\", sub['target'].mean())\n",
    "\n",
    "# 4. сохраняем\n",
    "sub.to_csv('submission_v11_boost.csv', index=False)\n",
    "\n",
    "print(\"\\nФайл готов!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eSnEUVgE14ro",
    "outputId": "7bb79599-fc2a-4c68-fdb7-411a65fecd03"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "средний дефицит до буста: 2.3973483124430026\n",
      "средний дефицит после буста: 2.6370831436873035\n",
      "\n",
      "Файл готов!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts):\n",
    "\n",
    "    # Собирает единый датасет и генерирует фичи\n",
    "\n",
    "    # Мержим с фактами и прогнозами смен\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # показывает напряженность прошлой недели\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "\n",
    "    # Нагрузка\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "\n",
    "    # Относительная текучка\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    # календарные фичи\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "path = 'data/'\n",
    "\n",
    "print(\"Загрузка данных...\")\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "\n",
    "# добавляем дату в test\n",
    "test_date = pd.to_datetime('2025-11-24')\n",
    "test['calendar_dt'] = test_date.strftime('%Y-%m-%d')\n",
    "\n",
    "# Генерируем фичи\n",
    "X_full = feature_engineering(train, facts, shifts)\n",
    "X_test_final = feature_engineering(test, facts, shifts)\n",
    "\n",
    "# Определяем категориальные фичи для CatBoost\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns:\n",
    "    cat_features = ['store_id']\n",
    "else:\n",
    "    # Заполняем пропуски в категориях строкой missing\n",
    "    X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "    X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "# Берем последнюю доступную дату в трейне как валидацию\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "train_date = val_date - pd.Timedelta(weeks=1) # или просто все, что меньше val_date\n",
    "\n",
    "print(f\"Validation Date: {val_date}\")\n",
    "\n",
    "mask_val = X_full['calendar_dt'] == val_date\n",
    "mask_train = X_full['calendar_dt'] < val_date\n",
    "\n",
    "X_train_fold = X_full[mask_train].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_fold = X_full.loc[mask_train, 'target']\n",
    "\n",
    "X_val_fold = X_full[mask_val].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val_fold = X_full.loc[mask_val, 'target']\n",
    "\n",
    "\n",
    "params_cls = {\n",
    "    'iterations': 600,\n",
    "    'depth': 4,\n",
    "    'loss_function': 'Logloss',\n",
    "    'verbose': 0,\n",
    "    'random_seed': 42,\n",
    "    'cat_features': cat_features\n",
    "}\n",
    "\n",
    "params_reg = {\n",
    "    'iterations': 800,\n",
    "    'depth': 4,\n",
    "    'loss_function': 'MAE', # изменение\n",
    "    'verbose': 0,\n",
    "    'random_seed': 42,\n",
    "    'cat_features': cat_features\n",
    "}\n",
    "\n",
    "print(\"Обучение Stage 1: Классификатор (0 vs >0)...\")\n",
    "# бинарный таргет\n",
    "y_train_class = (y_train_fold > 0).astype(int)\n",
    "clf = CatBoostClassifier(**params_cls)\n",
    "clf.fit(X_train_fold, y_train_class)\n",
    "\n",
    "print(\"Обучение Stage 2: Регрессор (MAE на ненулевых)...\")\n",
    "# Учим только на тех, где есть дефицит\n",
    "mask_positive = y_train_fold > 0\n",
    "reg = CatBoostRegressor(**params_reg)\n",
    "reg.fit(X_train_fold[mask_positive], y_train_fold[mask_positive])\n",
    "\n",
    "\n",
    "# Предсказываем вероятности и значения\n",
    "probs_val = clf.predict_proba(X_val_fold)[:, 1]\n",
    "preds_val_reg = reg.predict(X_val_fold)\n",
    "\n",
    "# Комбинируем с порогом 0.45\n",
    "threshold = 0.45\n",
    "final_preds_val = np.where(probs_val < threshold, 0, preds_val_reg)\n",
    "\n",
    "\n",
    "# Защита от отрицательных\n",
    "final_preds_val = np.clip(final_preds_val, 0, None)\n",
    "\n",
    "score = wape(y_val_fold, final_preds_val)\n",
    "print(f\"\\n>>> LOCAL WAPE SCORE: {score:.5f}\")\n",
    "\n",
    "print(\"\\nОбучение финальных моделей на полном трейне...\")\n",
    "X_full_train = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_full_train = X_full['target']\n",
    "\n",
    "# Stage 1 Full\n",
    "clf_full = CatBoostClassifier(**params_cls)\n",
    "clf_full.fit(X_full_train, (y_full_train > 0).astype(int))\n",
    "\n",
    "# Stage 2 Full\n",
    "mask_pos_full = y_full_train > 0\n",
    "reg_full = CatBoostRegressor(**params_reg)\n",
    "reg_full.fit(X_full_train[mask_pos_full], y_full_train[mask_pos_full])\n",
    "\n",
    "# Predict Test\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "probs_test = clf_full.predict_proba(X_test_ready)[:, 1]\n",
    "preds_test_reg = reg_full.predict(X_test_ready)\n",
    "\n",
    "final_test_preds = np.where(probs_test < threshold, 0, preds_test_reg)\n",
    "final_test_preds = np.clip(final_test_preds, 0, None)\n",
    "\n",
    "# Сохранение\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_test_preds\n",
    "submission.to_csv('submission_v11_2stage_mae.csv', index=False)\n",
    "print(\"Файл submission_v11_2stage_mae.csv успешно сохранен!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sDbd2Lk3kQdd",
    "outputId": "d79a24a5-7862-4134-8f5b-e14d96efe91c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Загрузка данных...\n",
      "Validation Date: 2025-11-17 00:00:00\n",
      "Обучение Stage 1: Классификатор (0 vs >0)...\n",
      "Обучение Stage 2: Регрессор (MAE на ненулевых)...\n",
      "\n",
      ">>> LOCAL WAPE SCORE: 0.17370\n",
      "\n",
      "Обучение финальных моделей на полном трейне...\n",
      "Файл submission_v11_2stage_mae.csv успешно сохранен!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "test_date = pd.to_datetime('2025-11-24')\n",
    "test['calendar_dt'] = test_date.strftime('%Y-%m-%d')\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # V3 Logic\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    # Calendar\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    return df\n",
    "\n",
    "X_full = feature_engineering(train, facts, shifts)\n",
    "X_test_final = feature_engineering(test, facts, shifts)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "mask_val = X_full['calendar_dt'] == val_date\n",
    "mask_train = X_full['calendar_dt'] < val_date\n",
    "\n",
    "X_train_fold = X_full[mask_train].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_fold = X_full.loc[mask_train, 'target']\n",
    "X_val_fold = X_full[mask_val].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val_fold = X_full.loc[mask_val, 'target']\n",
    "\n",
    "# используем одну модель, но с MAE\n",
    "params_mae = {\n",
    "    'iterations': 1000,\n",
    "    'depth': 5,             # чуть больше глубина, тк модель одна\n",
    "    'loss_function': 'MAE', # самое важное!\n",
    "    'eval_metric': 'MAE',   # Чтобы видеть реальную метрику\n",
    "    'verbose': 100,\n",
    "    'random_seed': 42,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 50,\n",
    "    'cat_features': cat_features\n",
    "}\n",
    "\n",
    "print(\"Обучение Single MAE Model...\")\n",
    "model = CatBoostRegressor(**params_mae)\n",
    "model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold))\n",
    "\n",
    "preds_val = model.predict(X_val_fold)\n",
    "# зануляем совсем мелкие значения, но мягче\n",
    "preds_val = np.where(preds_val < 0.3, 0, preds_val)\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "print(f\"\\nLOCAL WAPE (Single MAE): {wape(y_val_fold, preds_val):.5f}\")\n",
    "\n",
    "\n",
    "print(\"\\nОбучение на всем трейне...\")\n",
    "X_full_train = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_full_train = X_full['target']\n",
    "\n",
    "final_model = CatBoostRegressor(**params_mae)\n",
    "final_model.fit(X_full_train, y_full_train)\n",
    "\n",
    "cols_to_drop = ['target', 'calendar_dt']\n",
    "X_test_ready = X_test_final.drop(cols_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "print(\"Финальное предсказание...\")\n",
    "preds_test = final_model.predict(X_test_ready)\n",
    "\n",
    "preds_test = np.where(preds_test < 0.35, 0, preds_test)\n",
    "preds_test = np.clip(preds_test, 0, None)\n",
    "\n",
    "# сохранение\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = preds_test\n",
    "submission.to_csv('submission_v12_single_mae.csv', index=False)\n",
    "print(\"Файл submission_v12_single_mae.csv создан.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oe0HXAulmQXv",
    "outputId": "18f02677-4106-4c31-b3e0-88005174f14c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Обучение Single MAE Model...\n",
      "0:\tlearn: 1.8969996\ttest: 1.9501017\tbest: 1.9501017 (0)\ttotal: 8.72ms\tremaining: 8.71s\n",
      "100:\tlearn: 0.5017981\ttest: 0.5318435\tbest: 0.5318435 (100)\ttotal: 465ms\tremaining: 4.14s\n",
      "200:\tlearn: 0.4409405\ttest: 0.4792969\tbest: 0.4792969 (200)\ttotal: 919ms\tremaining: 3.65s\n",
      "300:\tlearn: 0.4245971\ttest: 0.4680540\tbest: 0.4680540 (300)\ttotal: 1.86s\tremaining: 4.33s\n",
      "400:\tlearn: 0.4090180\ttest: 0.4553914\tbest: 0.4553914 (400)\ttotal: 2.84s\tremaining: 4.25s\n",
      "500:\tlearn: 0.3995320\ttest: 0.4508427\tbest: 0.4508427 (500)\ttotal: 3.3s\tremaining: 3.29s\n",
      "600:\tlearn: 0.3870842\ttest: 0.4467416\tbest: 0.4464892 (598)\ttotal: 3.77s\tremaining: 2.5s\n",
      "Stopped by overfitting detector  (50 iterations wait)\n",
      "\n",
      "bestTest = 0.4464891579\n",
      "bestIteration = 598\n",
      "\n",
      "Shrink model to first 599 iterations.\n",
      "\n",
      ">>> LOCAL WAPE (Single MAE): 0.17422\n",
      "\n",
      "Обучение на всем трейне...\n",
      "0:\tlearn: 1.9192485\ttotal: 8.53ms\tremaining: 8.52s\n",
      "100:\tlearn: 0.4995922\ttotal: 699ms\tremaining: 6.22s\n",
      "200:\tlearn: 0.4452145\ttotal: 1.29s\tremaining: 5.14s\n",
      "300:\tlearn: 0.4342677\ttotal: 1.77s\tremaining: 4.12s\n",
      "400:\tlearn: 0.4218720\ttotal: 2.29s\tremaining: 3.42s\n",
      "500:\tlearn: 0.4155084\ttotal: 2.81s\tremaining: 2.79s\n",
      "600:\tlearn: 0.4058851\ttotal: 3.35s\tremaining: 2.23s\n",
      "700:\tlearn: 0.3997353\ttotal: 3.91s\tremaining: 1.67s\n",
      "800:\tlearn: 0.3934750\ttotal: 4.47s\tremaining: 1.11s\n",
      "900:\tlearn: 0.3928602\ttotal: 4.99s\tremaining: 548ms\n",
      "999:\tlearn: 0.3911161\ttotal: 5.54s\tremaining: 0us\n",
      "Финальное предсказание...\n",
      "Готово! Файл submission_v12_single_mae.csv создан.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "sub_v10 = pd.read_csv('submission_v10_threshold.csv') # текущий топ (RMSE)\n",
    "sub_v12 = pd.read_csv('submission_v12_single_mae.csv') # новый стабильный (MAE)\n",
    "\n",
    "print(f\"V10 stats: {sub_v10['target'].describe()}\")\n",
    "print(f\"V12 stats: {sub_v12['target'].describe()}\")\n",
    "\n",
    "# микс 50/50\n",
    "sub_blend = sub_v10.copy()\n",
    "sub_blend['target'] = (sub_v10['target'] * 0.5) + (sub_v12['target'] * 0.5)\n",
    "\n",
    "# Пока просто чистое среднее\n",
    "\n",
    "print(\"\\nBlend stats:\")\n",
    "print(sub_blend['target'].describe())\n",
    "\n",
    "# сохраняем\n",
    "sub_blend.to_csv('submission_v13_blend_best.csv', index=False)\n",
    "print(\"Файл submission_v13_blend_best.csv готов к отправке!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDviAwTJnzR9",
    "outputId": "51dbc94d-b100-46c9-f194-55d6b335c189"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "V10 stats: count    2438.000000\n",
      "mean        2.397348\n",
      "std         2.475811\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         2.000266\n",
      "75%         4.009551\n",
      "max        14.606336\n",
      "Name: target, dtype: float64\n",
      "V12 stats: count    2438.000000\n",
      "mean        2.380258\n",
      "std         2.439946\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.996676\n",
      "75%         3.994184\n",
      "max        12.690326\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Blend stats:\n",
      "count    2438.000000\n",
      "mean        2.388803\n",
      "std         2.456885\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.998336\n",
      "75%         4.004442\n",
      "max        13.648331\n",
      "Name: target, dtype: float64\n",
      "Файл submission_v13_blend_best.csv готов к отправке!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "corr = sub_v10['target'].corr(sub_v12['target'])\n",
    "print(f\"Корреляция между моделями: {corr:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TMkOOue2oaSE",
    "outputId": "7ee5be0c-5ce9-4365-e467-d8c50a3f410a"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Корреляция между моделями: 0.99838\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "test_date = pd.to_datetime('2025-11-24')\n",
    "test['calendar_dt'] = test_date.strftime('%Y-%m-%d')\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    return df\n",
    "\n",
    "X_full = feature_engineering(train, facts, shifts)\n",
    "X_test_final = feature_engineering(test, facts, shifts)\n",
    "\n",
    "# ПОДГОТОВКА ДЛЯ LIGHTGBM\n",
    "cat_cols = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_cols = ['store_id']\n",
    "\n",
    "# заполняем пропуски\n",
    "X_full[cat_cols] = X_full[cat_cols].fillna('missing')\n",
    "X_test_final[cat_cols] = X_test_final[cat_cols].fillna('missing')\n",
    "\n",
    "# кодируем\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    # объединяем, чтобы выучить все категории\n",
    "    all_cats = pd.concat([X_full[col], X_test_final[col]], axis=0).astype(str)\n",
    "    le.fit(all_cats)\n",
    "    X_full[col] = le.transform(X_full[col].astype(str))\n",
    "    X_test_final[col] = le.transform(X_test_final[col].astype(str))\n",
    "\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "mask_val = X_full['calendar_dt'] == val_date\n",
    "mask_train = X_full['calendar_dt'] < val_date\n",
    "\n",
    "X_train_fold = X_full[mask_train].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_fold = X_full.loc[mask_train, 'target']\n",
    "X_val_fold = X_full[mask_val].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val_fold = X_full.loc[mask_val, 'target']\n",
    "\n",
    "\n",
    "# создаем датасеты для LGBM\n",
    "lgb_train = lgb.Dataset(X_train_fold, y_train_fold, categorical_feature=cat_cols)\n",
    "lgb_eval = lgb.Dataset(X_val_fold, y_val_fold, reference=lgb_train, categorical_feature=cat_cols)\n",
    "\n",
    "params = {\n",
    "    'objective': 'regression_l1', # MAE в терминах LightGBM\n",
    "    'metric': 'mae',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 6,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': -1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"Обучение LightGBM...\")\n",
    "model_lgb = lgb.train(\n",
    "    params,\n",
    "    lgb_train,\n",
    "    num_boost_round=2000,\n",
    "    valid_sets=[lgb_train, lgb_eval],\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "# проверка локально\n",
    "preds_val_lgb = model_lgb.predict(X_val_fold, num_iteration=model_lgb.best_iteration)\n",
    "# мягкий порог для LGBM\n",
    "preds_val_lgb = np.where(preds_val_lgb < 0.35, 0, preds_val_lgb)\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "print(f\"\\nLOCAL WAPE (LightGBM): {wape(y_val_fold, preds_val_lgb):.5f}\")\n",
    "\n",
    "print(\"\\nобучение на всем трейне...\")\n",
    "X_full_train = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_full_train = X_full['target']\n",
    "\n",
    "lgb_full = lgb.Dataset(X_full_train, y_full_train, categorical_feature=cat_cols)\n",
    "\n",
    "model_lgb_final = lgb.train(\n",
    "    params,\n",
    "    lgb_full,\n",
    "    num_boost_round=model_lgb.best_iteration # берем лучшее число итераций\n",
    ")\n",
    "\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "preds_test_lgb = model_lgb_final.predict(X_test_ready)\n",
    "\n",
    "preds_test_lgb = np.where(preds_test_lgb < 0.35, 0, preds_test_lgb)\n",
    "preds_test_lgb = np.clip(preds_test_lgb, 0, None)\n",
    "\n",
    "# чистый LightGBM (для истории)\n",
    "sub_lgb = sample_sub.copy()\n",
    "sub_lgb['target'] = preds_test_lgb\n",
    "sub_lgb.to_csv('submission_v14_lgbm_pure.csv', index=False)\n",
    "print(\"Чистый LightGBM сохранен.\")\n",
    "\n",
    "# лучший результат (V13)\n",
    "sub_best = pd.read_csv('submission_v13_blend_best.csv')\n",
    "\n",
    "# 70% V13 + 30% новая LightGBM\n",
    "sub_super_blend = sub_best.copy()\n",
    "sub_super_blend['target'] = (sub_best['target'] * 0.7) + (sub_lgb['target'] * 0.3)\n",
    "\n",
    "sub_super_blend.to_csv('submission_v15_lgbm_blend.csv', index=False)\n",
    "print(\"Файл submission_v15_lgbm_blend.csv ГОТОВ!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bttIX4-QpIQH",
    "outputId": "f978989f-b138-4111-c35b-0efd8ed13189"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Обучение LightGBM...\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.376764\tvalid_1's l1: 0.457208\n",
      "[200]\ttraining's l1: 0.35555\tvalid_1's l1: 0.45529\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's l1: 0.36395\tvalid_1's l1: 0.453237\n",
      "\n",
      ">>> LOCAL WAPE (LightGBM): 0.17686\n",
      "\n",
      "Обучение на всем трейне...\n",
      "Чистый LightGBM сохранен.\n",
      "Файл submission_v15_lgbm_blend.csv ГОТОВ К ОТПРАВКЕ!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "test_date = pd.to_datetime('2025-11-24')\n",
    "test['calendar_dt'] = test_date.strftime('%Y-%m-%d')\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    return df\n",
    "\n",
    "X_full = feature_engineering(train, facts, shifts)\n",
    "X_test_final = feature_engineering(test, facts, shifts)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "# обучаем 5 моделей с разными random_seed и усредняем предсказания\n",
    "seeds = [42, 2025, 777, 1337, 100]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"начинаем обучение ансамбля из {len(seeds)} моделей...\")\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(f\"\\n--- Model {i+1}/{len(seeds)} (Seed {seed}) ---\")\n",
    "\n",
    "    params = {\n",
    "        'iterations': 1100,      # чуть больше итераций для надежности\n",
    "        'depth': 5,\n",
    "        'loss_function': 'MAE',\n",
    "        'verbose': 200,\n",
    "        'random_seed': seed,\n",
    "        'cat_features': cat_features,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "\n",
    "    preds = model.predict(X_test_ready)\n",
    "\n",
    "    preds = np.where(preds < 0.35, 0, preds)\n",
    "    preds = np.clip(preds, 0, None)\n",
    "\n",
    "    test_preds_accum += preds\n",
    "\n",
    "# усредняем\n",
    "final_preds_bagging = test_preds_accum / len(seeds)\n",
    "\n",
    "# (на всякий случай)\n",
    "sub_bagging = sample_sub.copy()\n",
    "sub_bagging['target'] = final_preds_bagging\n",
    "sub_bagging.to_csv('submission_v16_mae_bagging.csv', index=False)\n",
    "print(\"\\nЧистый ансамбль MAE сохранен (submission_v16_mae_bagging.csv)\")\n",
    "\n",
    "sub_v10 = pd.read_csv('submission_v10_threshold.csv')\n",
    "\n",
    "sub_final = sample_sub.copy()\n",
    "# снова 50/50, но теперь MAE часть гораздо стабильнее\n",
    "sub_final['target'] = (sub_v10['target'] * 0.5) + (final_preds_bagging * 0.5)\n",
    "\n",
    "sub_final.to_csv('submission_v17_bagging_blend.csv', index=False)\n",
    "print(\"файл submission_v17_bagging_blend.csv ГОТОВ\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GIEE908qbYI",
    "outputId": "be712c33-fe91-4868-a8dc-7714b6e31fdf"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Начинаем обучение ансамбля из 5 моделей...\n",
      "\n",
      "--- Model 1/5 (Seed 42) ---\n",
      "0:\tlearn: 1.9192485\ttotal: 8.16ms\tremaining: 8.97s\n",
      "200:\tlearn: 0.4452145\ttotal: 1.35s\tremaining: 6.05s\n",
      "400:\tlearn: 0.4218720\ttotal: 2.33s\tremaining: 4.07s\n",
      "600:\tlearn: 0.4058851\ttotal: 3.44s\tremaining: 2.86s\n",
      "800:\tlearn: 0.3934750\ttotal: 4.59s\tremaining: 1.71s\n",
      "1000:\tlearn: 0.3911158\ttotal: 6.32s\tremaining: 625ms\n",
      "1099:\tlearn: 0.3889195\ttotal: 7.42s\tremaining: 0us\n",
      "\n",
      "--- Model 2/5 (Seed 2025) ---\n",
      "0:\tlearn: 1.9171937\ttotal: 9.53ms\tremaining: 10.5s\n",
      "200:\tlearn: 0.4453994\ttotal: 1.09s\tremaining: 4.88s\n",
      "400:\tlearn: 0.4195142\ttotal: 2.15s\tremaining: 3.75s\n",
      "600:\tlearn: 0.4040468\ttotal: 3.2s\tremaining: 2.66s\n",
      "800:\tlearn: 0.3935297\ttotal: 4.31s\tremaining: 1.61s\n",
      "1000:\tlearn: 0.3885351\ttotal: 5.46s\tremaining: 540ms\n",
      "1099:\tlearn: 0.3860480\ttotal: 6.04s\tremaining: 0us\n",
      "\n",
      "--- Model 3/5 (Seed 777) ---\n",
      "0:\tlearn: 1.9133872\ttotal: 10.3ms\tremaining: 11.3s\n",
      "200:\tlearn: 0.4467938\ttotal: 1.16s\tremaining: 5.19s\n",
      "400:\tlearn: 0.4228891\ttotal: 2.22s\tremaining: 3.87s\n",
      "600:\tlearn: 0.4041361\ttotal: 3.33s\tremaining: 2.76s\n",
      "800:\tlearn: 0.3936741\ttotal: 5.39s\tremaining: 2.01s\n",
      "1000:\tlearn: 0.3895535\ttotal: 6.64s\tremaining: 657ms\n",
      "1099:\tlearn: 0.3873848\ttotal: 7.22s\tremaining: 0us\n",
      "\n",
      "--- Model 4/5 (Seed 1337) ---\n",
      "0:\tlearn: 1.9110806\ttotal: 11.3ms\tremaining: 12.4s\n",
      "200:\tlearn: 0.4456725\ttotal: 1.12s\tremaining: 5.01s\n",
      "400:\tlearn: 0.4214130\ttotal: 2.12s\tremaining: 3.69s\n",
      "600:\tlearn: 0.4017074\ttotal: 3.17s\tremaining: 2.63s\n",
      "800:\tlearn: 0.3919629\ttotal: 4.27s\tremaining: 1.59s\n",
      "1000:\tlearn: 0.3888020\ttotal: 5.39s\tremaining: 533ms\n",
      "1099:\tlearn: 0.3862290\ttotal: 5.95s\tremaining: 0us\n",
      "\n",
      "--- Model 5/5 (Seed 100) ---\n",
      "0:\tlearn: 1.9138726\ttotal: 10.8ms\tremaining: 11.9s\n",
      "200:\tlearn: 0.4459770\ttotal: 1.19s\tremaining: 5.31s\n",
      "400:\tlearn: 0.4214309\ttotal: 2.22s\tremaining: 3.87s\n",
      "600:\tlearn: 0.4033987\ttotal: 4.5s\tremaining: 3.73s\n",
      "800:\tlearn: 0.3940890\ttotal: 5.63s\tremaining: 2.1s\n",
      "1000:\tlearn: 0.3892277\ttotal: 6.75s\tremaining: 668ms\n",
      "1099:\tlearn: 0.3871360\ttotal: 7.32s\tremaining: 0us\n",
      "\n",
      "Чистый ансамбль MAE сохранен (submission_v16_mae_bagging.csv)\n",
      "Файл submission_v17_bagging_blend.csv ГОТОВ! Грузи его.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# загружаем файлы\n",
    "v13_best = pd.read_csv('submission_v13_blend_best.csv') # текущий рекорд\n",
    "v17_new = pd.read_csv('submission_v17_bagging_blend.csv') # новый кандидат\n",
    "\n",
    "# проверка на технические ошибки (NaN, Infinity)\n",
    "if v17_new['target'].isnull().any():\n",
    "    print(\"в новом файле есть пустые значения!\")\n",
    "elif (v17_new['target'] < 0).any():\n",
    "    print(\"в новом файле есть отрицательные числа!\")\n",
    "else:\n",
    "    print(\"Файл чистый (нет NaN и минусов)\")\n",
    "\n",
    "# сравнение статистик\n",
    "print(\"\\n--- Сравнение Статистик ---\")\n",
    "print(f\"Mean (Среднее):   V13={v13_best['target'].mean():.4f} vs V17={v17_new['target'].mean():.4f}\")\n",
    "print(f\"Max (Максимум):   V13={v13_best['target'].max():.4f}  vs V17={v17_new['target'].max():.4f}\")\n",
    "print(f\"Zeros (Сколько 0): V13={(v13_best['target'] == 0).sum()} vs V17={(v17_new['target'] == 0).sum()}\")\n",
    "\n",
    "# корреляция и различия\n",
    "corr = v17_new['target'].corr(v13_best['target'])\n",
    "mae_diff = np.mean(np.abs(v17_new['target'] - v13_best['target']))\n",
    "\n",
    "print(f\"\\n--- Насколько они разные? ---\")\n",
    "print(f\"Корреляция: {corr:.6f}\")\n",
    "print(f\"Средняя разница (MAE) между файлами: {mae_diff:.6f}\")\n",
    "\n",
    "# Вердикт\n",
    "if 0.98 < corr < 0.9999:\n",
    "    print(\"\\nФайл очень похож на лидера, но имеет небольшие отличия (bagging сработал)\")\n",
    "elif corr > 0.9999:\n",
    "    print(\"\\nФайлы почти идентичны. Прирост будет микроскопическим\")\n",
    "else:\n",
    "    print(\"\\nФайлы сильно отличаются. Это риск\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QbNWYchwrNSd",
    "outputId": "01ab3919-3efd-4d4e-840d-f9c406a5f904"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Техническая проверка: Файл чистый (нет NaN и минусов).\n",
      "\n",
      "--- Сравнение Статистик ---\n",
      "Mean (Среднее):   V13=2.3888 vs V17=2.3961\n",
      "Max (Максимум):   V13=13.6483  vs V17=13.7450\n",
      "Zeros (Сколько 0): V13=724 vs V17=724\n",
      "\n",
      "--- Насколько они разные? ---\n",
      "Корреляция: 0.999892\n",
      "Средняя разница (MAE) между файлами: 0.015824\n",
      "\n",
      "🚀 ВЕРДИКТ: Отличный кандидат! Файл очень похож на лидера, но имеет небольшие отличия (bagging сработал). Можно грузить.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "test_date = pd.to_datetime('2025-11-24')\n",
    "test['calendar_dt'] = test_date.strftime('%Y-%m-%d')\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "\n",
    "    # добавим месяц, так как поведение осенью/зимой разное\n",
    "    df['month'] = df['calendar_dt'].dt.month\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "X_full = feature_engineering(train, facts, shifts)\n",
    "X_test_final = feature_engineering(test, facts, shifts)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "# оставляем только данные за последние 6 месяцев (или год)\n",
    "X_full = X_full[X_full['calendar_dt'] >= '2024-06-01'].copy()\n",
    "print(f\"Обучаемся на данных с: {X_full['calendar_dt'].min()}\")\n",
    "\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "mask_val = X_full['calendar_dt'] == val_date\n",
    "mask_train = X_full['calendar_dt'] < val_date\n",
    "\n",
    "X_train_fold = X_full[mask_train].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_fold = X_full.loc[mask_train, 'target']\n",
    "X_val_fold = X_full[mask_val].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val_fold = X_full.loc[mask_val, 'target']\n",
    "\n",
    "params_tweedie = {\n",
    "    'iterations': 1500,\n",
    "    'depth': 5,\n",
    "    'loss_function': 'Tweedie:variance_power=1.5',\n",
    "    'eval_metric': 'MAE', # смотрим на MAE, но оптимизируем Tweedie\n",
    "    'learning_rate': 0.03, # медленно\n",
    "    'verbose': 200,\n",
    "    'random_seed': 42,\n",
    "    'cat_features': cat_features\n",
    "}\n",
    "\n",
    "print(\"Обучение CatBoost Tweedie...\")\n",
    "model = CatBoostRegressor(**params_tweedie)\n",
    "model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold))\n",
    "\n",
    "preds_val = model.predict(X_val_fold)\n",
    "\n",
    "preds_val = np.where(preds_val < 0.45, 0, preds_val)\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "score = wape(y_val_fold, preds_val)\n",
    "print(f\"\\nLOCAL WAPE (Tweedie + Fresh Data): {score:.5f}\")\n",
    "\n",
    "if score < 0.175:\n",
    "    print(\"Новый подход работает локально. Обучаем на всем\")\n",
    "\n",
    "    # Финальное обучение\n",
    "    X_full_train = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "    y_full_train = X_full['target']\n",
    "\n",
    "    final_model = CatBoostRegressor(**params_tweedie)\n",
    "    final_model.fit(X_full_train, y_full_train)\n",
    "\n",
    "    X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "    preds_test = final_model.predict(X_test_ready)\n",
    "\n",
    "    preds_test = np.where(preds_test < 0.45, 0, preds_test)\n",
    "    preds_test = np.clip(preds_test, 0, None)\n",
    "\n",
    "    submission = sample_sub.copy()\n",
    "    submission['target'] = preds_test\n",
    "    submission.to_csv('submission_v19_tweedie.csv', index=False)\n",
    "    print(\"Файл submission_v19_tweedie.csv готов.\")\n",
    "else:\n",
    "    print(\"Не тратим попытку.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y_wYWqPtstLO",
    "outputId": "2f14ce92-db1f-46ef-d0bd-67dcf46d6bfd"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Обучаемся на данных с: 2024-06-03 00:00:00\n",
      "Обучение CatBoost Tweedie...\n",
      "0:\tlearn: 2.2501138\ttest: 2.5565587\tbest: 2.5565587 (0)\ttotal: 5.77ms\tremaining: 8.65s\n",
      "200:\tlearn: 4.2561042\ttest: 4.0244884\tbest: 2.5385926 (14)\ttotal: 944ms\tremaining: 6.1s\n",
      "400:\tlearn: 4.7452164\ttest: 4.4284245\tbest: 2.5385926 (14)\ttotal: 1.82s\tremaining: 5s\n",
      "600:\tlearn: 5.0105711\ttest: 4.6499326\tbest: 2.5385926 (14)\ttotal: 2.71s\tremaining: 4.05s\n",
      "800:\tlearn: 5.1552860\ttest: 4.7716750\tbest: 2.5385926 (14)\ttotal: 3.62s\tremaining: 3.16s\n",
      "1000:\tlearn: 5.2665372\ttest: 4.8643751\tbest: 2.5385926 (14)\ttotal: 4.7s\tremaining: 2.34s\n",
      "1200:\tlearn: 5.3533951\ttest: 4.9357354\tbest: 2.5385926 (14)\ttotal: 6.56s\tremaining: 1.63s\n",
      "1400:\tlearn: 5.4389856\ttest: 5.0044253\tbest: 2.5385926 (14)\ttotal: 7.45s\tremaining: 527ms\n",
      "1499:\tlearn: 5.4702384\ttest: 5.0307936\tbest: 2.5385926 (14)\ttotal: 7.89s\tremaining: 0us\n",
      "\n",
      "bestTest = 2.538592557\n",
      "bestIteration = 14\n",
      "\n",
      "Shrink model to first 15 iterations.\n",
      "\n",
      ">>> LOCAL WAPE (Tweedie + Fresh Data): 0.66689\n",
      "😔 Tweedie не взлетел локально. Не тратим попытку.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sub = pd.read_csv('submission_v13_blend_best.csv')\n",
    "\n",
    "print(\"Статистика ДО обработки:\")\n",
    "print(sub['target'].describe())\n",
    "\n",
    "sub['target_rounded'] = np.round(sub['target'])\n",
    "\n",
    "sub['target_boosted'] = sub['target'] * 1.03\n",
    "sub['target_final'] = np.round(sub['target_boosted'])\n",
    "\n",
    "# сравним\n",
    "diff = (sub['target_final'] != sub['target_rounded']).sum()\n",
    "print(f\"\\nИзменилось предсказаний после Boost: {diff} из {len(sub)}\")\n",
    "\n",
    "# записываем в файл\n",
    "submission = sub[['store_id', 'target_final']].rename(columns={'target_final': 'target'})\n",
    "\n",
    "# финальная защита от отрицательных (на всякий случай)\n",
    "submission['target'] = submission['target'].clip(lower=0)\n",
    "\n",
    "print(\"\\nСтатистика ФИНАЛЬНАЯ:\")\n",
    "print(submission['target'].describe())\n",
    "\n",
    "submission.to_csv('submission_v20_black_friday_int.csv', index=False)\n",
    "print(\"Файл submission_v20_black_friday_int.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q4vK6dPGtInC",
    "outputId": "0b9a18c0-69b0-4166-9598-d806ae2219ed"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Статистика ДО обработки:\n",
      "count    2438.000000\n",
      "mean        2.388803\n",
      "std         2.456885\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         1.998336\n",
      "75%         4.004442\n",
      "max        13.648331\n",
      "Name: target, dtype: float64\n",
      "\n",
      "Изменилось предсказаний после Boost-а: 87 из 2438\n",
      "\n",
      "Статистика ФИНАЛЬНАЯ:\n",
      "count    2438.000000\n",
      "mean        2.406891\n",
      "std         2.518081\n",
      "min         0.000000\n",
      "25%         0.000000\n",
      "50%         2.000000\n",
      "75%         4.000000\n",
      "max        14.000000\n",
      "Name: target, dtype: float64\n",
      "Файл submission_v20_black_friday_int.csv готов.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "# приводим даты к datetime\n",
    "train['calendar_dt'] = pd.to_datetime(train['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "facts['calendar_dt'] = pd.to_datetime(facts['calendar_dt'])\n",
    "shifts['calendar_dt'] = pd.to_datetime(shifts['calendar_dt'])\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # Если данных за прошлую неделю нет, заполняем нулем или медианой\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # старые фичи\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Разница между прогнозом штата и прошлым дефицитом\n",
    "    # Показывает динамику: стало хуже или лучше\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков с авторегрессией...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "# Проверка: есть ли lag_target_1 в тесте\n",
    "print(f\"Lag Target in Test (Not Null): {X_test_final['lag_target_1'].notna().sum()} / {len(X_test_final)}\")\n",
    "\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "mask_val = X_full['calendar_dt'] == val_date\n",
    "mask_train = X_full['calendar_dt'] < val_date\n",
    "\n",
    "X_train_fold = X_full[mask_train].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_fold = X_full.loc[mask_train, 'target']\n",
    "X_val_fold = X_full[mask_val].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val_fold = X_full.loc[mask_val, 'target']\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "params = {\n",
    "    'iterations': 1200,\n",
    "    'depth': 5,\n",
    "    'loss_function': 'MAE',\n",
    "    'verbose': 200,\n",
    "    'random_seed': 42,\n",
    "    'cat_features': cat_features\n",
    "}\n",
    "\n",
    "print(\"Обучение с Lag Target...\")\n",
    "model = CatBoostRegressor(**params)\n",
    "model.fit(X_train_fold, y_train_fold, eval_set=(X_val_fold, y_val_fold))\n",
    "\n",
    "preds_val = model.predict(X_val_fold)\n",
    "# Небольшой порог + округление (так как мы знаем про инты)\n",
    "preds_val = np.where(preds_val < 0.35, 0, preds_val)\n",
    "preds_val = np.round(preds_val) # округление сразу\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "score = wape(y_val_fold, preds_val)\n",
    "print(f\"\\n>>> LOCAL WAPE (Autoregression): {score:.5f}\")\n",
    "\n",
    "print(\"\\nОбучение на всем трейне...\")\n",
    "X_full_train = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_full_train = X_full['target']\n",
    "\n",
    "final_model = CatBoostRegressor(**params)\n",
    "final_model.fit(X_full_train, y_full_train)\n",
    "\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "preds_test = final_model.predict(X_test_ready)\n",
    "\n",
    "# Пост-процессинг\n",
    "preds_test = np.where(preds_test < 0.35, 0, preds_test)\n",
    "preds_test = np.round(preds_test) # Округляем до целых\n",
    "preds_test = np.clip(preds_test, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = preds_test\n",
    "submission.to_csv('submission_v21_autoreg.csv', index=False)\n",
    "print(\"Файл submission_v21_autoreg.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YqS71B92tipd",
    "outputId": "7fd40ca0-d40a-409e-ecf8-2b05434cb77e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков с авторегрессией...\n",
      "Lag Target in Test (Not Null): 2438 / 2438\n",
      "Обучение с Lag Target...\n",
      "0:\tlearn: 1.9017996\ttest: 1.9566082\tbest: 1.9566082 (0)\ttotal: 26.9ms\tremaining: 32.2s\n",
      "200:\tlearn: 0.4370040\ttest: 0.4792758\tbest: 0.4792758 (200)\ttotal: 3.36s\tremaining: 16.7s\n",
      "400:\tlearn: 0.4002425\ttest: 0.4489086\tbest: 0.4489086 (400)\ttotal: 5.63s\tremaining: 11.2s\n",
      "600:\tlearn: 0.3859803\ttest: 0.4439709\tbest: 0.4433992 (540)\ttotal: 6.73s\tremaining: 6.71s\n",
      "800:\tlearn: 0.3811003\ttest: 0.4445533\tbest: 0.4433992 (540)\ttotal: 7.71s\tremaining: 3.84s\n",
      "1000:\tlearn: 0.3733647\ttest: 0.4467533\tbest: 0.4433992 (540)\ttotal: 8.69s\tremaining: 1.73s\n",
      "1199:\tlearn: 0.3668914\ttest: 0.4532504\tbest: 0.4433992 (540)\ttotal: 9.64s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.4433992449\n",
      "bestIteration = 540\n",
      "\n",
      "Shrink model to first 541 iterations.\n",
      "\n",
      ">>> LOCAL WAPE (Autoregression): 0.16517\n",
      "\n",
      "Обучение на всем трейне...\n",
      "0:\tlearn: 1.9121974\ttotal: 7.83ms\tremaining: 9.39s\n",
      "200:\tlearn: 0.4376625\ttotal: 1.11s\tremaining: 5.53s\n",
      "400:\tlearn: 0.4116902\ttotal: 2.1s\tremaining: 4.18s\n",
      "600:\tlearn: 0.3971925\ttotal: 3.2s\tremaining: 3.19s\n",
      "800:\tlearn: 0.3873688\ttotal: 4.36s\tremaining: 2.17s\n",
      "1000:\tlearn: 0.3827518\ttotal: 5.54s\tremaining: 1.1s\n",
      "1199:\tlearn: 0.3782409\ttotal: 7.7s\tremaining: 0us\n",
      "Файл submission_v21_autoreg.csv готов.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "train['calendar_dt'] = pd.to_datetime(train['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "facts['calendar_dt'] = pd.to_datetime(facts['calendar_dt'])\n",
    "shifts['calendar_dt'] = pd.to_datetime(shifts['calendar_dt'])\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Тренд\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "seeds = [42, 2024, 777, 555, 8800]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Начинаем Bagging ({len(seeds)} моделей)...\")\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(f\"\\nTraining Model {i+1} (Seed {seed})...\")\n",
    "\n",
    "    params = {\n",
    "        'iterations': 1200,\n",
    "        'depth': 5,\n",
    "        'loss_function': 'MAE',\n",
    "        'verbose': 200,\n",
    "        'random_seed': seed,\n",
    "        'cat_features': cat_features,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "\n",
    "    # Предсказываем чистые float\n",
    "    preds = model.predict(X_test_ready)\n",
    "\n",
    "    # Накапливаем сумму\n",
    "    test_preds_accum += preds\n",
    "\n",
    "# Усредняем предсказания (получаем более точные float)\n",
    "final_preds_float = test_preds_accum / len(seeds)\n",
    "\n",
    "# Пост-процессинг\n",
    "# Сначала отсекаем явные нули\n",
    "final_preds = np.where(final_preds_float < 0.35, 0, final_preds_float)\n",
    "\n",
    "# Округляем до целых\n",
    "final_preds = np.round(final_preds)\n",
    "\n",
    "# Защита\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v22_autoreg_bagging.csv', index=False)\n",
    "print(\"Файл submission_v22_autoreg_bagging.csv готов\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PpSnE1kCudyP",
    "outputId": "58ad1fb5-2486-4811-e0a7-0559cd196002"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков...\n",
      "Начинаем Bagging (5 моделей)...\n",
      "\n",
      "Training Model 1 (Seed 42)...\n",
      "0:\tlearn: 1.9121974\ttotal: 8.56ms\tremaining: 10.3s\n",
      "200:\tlearn: 0.4376625\ttotal: 1.23s\tremaining: 6.13s\n",
      "400:\tlearn: 0.4116902\ttotal: 2.35s\tremaining: 4.68s\n",
      "600:\tlearn: 0.3971925\ttotal: 3.59s\tremaining: 3.58s\n",
      "800:\tlearn: 0.3873688\ttotal: 5.72s\tremaining: 2.85s\n",
      "1000:\tlearn: 0.3827518\ttotal: 7.84s\tremaining: 1.56s\n",
      "1199:\tlearn: 0.3782409\ttotal: 9.1s\tremaining: 0us\n",
      "\n",
      "Training Model 2 (Seed 2024)...\n",
      "0:\tlearn: 1.9169383\ttotal: 10.2ms\tremaining: 12.2s\n",
      "200:\tlearn: 0.4454273\ttotal: 1.25s\tremaining: 6.19s\n",
      "400:\tlearn: 0.4128820\ttotal: 2.41s\tremaining: 4.81s\n",
      "600:\tlearn: 0.3953210\ttotal: 3.6s\tremaining: 3.59s\n",
      "800:\tlearn: 0.3869909\ttotal: 4.79s\tremaining: 2.39s\n",
      "1000:\tlearn: 0.3825953\ttotal: 6.02s\tremaining: 1.2s\n",
      "1199:\tlearn: 0.3781177\ttotal: 7.26s\tremaining: 0us\n",
      "\n",
      "Training Model 3 (Seed 777)...\n",
      "0:\tlearn: 1.9158981\ttotal: 10.6ms\tremaining: 12.7s\n",
      "200:\tlearn: 0.4357054\ttotal: 1.81s\tremaining: 9.01s\n",
      "400:\tlearn: 0.4082201\ttotal: 4.22s\tremaining: 8.41s\n",
      "600:\tlearn: 0.3962518\ttotal: 5.38s\tremaining: 5.36s\n",
      "800:\tlearn: 0.3874642\ttotal: 6.58s\tremaining: 3.28s\n",
      "1000:\tlearn: 0.3831138\ttotal: 7.8s\tremaining: 1.55s\n",
      "1199:\tlearn: 0.3796333\ttotal: 9.03s\tremaining: 0us\n",
      "\n",
      "Training Model 4 (Seed 555)...\n",
      "0:\tlearn: 1.9192339\ttotal: 9.77ms\tremaining: 11.7s\n",
      "200:\tlearn: 0.4306076\ttotal: 1.23s\tremaining: 6.1s\n",
      "400:\tlearn: 0.4082834\ttotal: 2.36s\tremaining: 4.7s\n",
      "600:\tlearn: 0.3965403\ttotal: 3.51s\tremaining: 3.5s\n",
      "800:\tlearn: 0.3881090\ttotal: 4.72s\tremaining: 2.35s\n",
      "1000:\tlearn: 0.3828412\ttotal: 7.25s\tremaining: 1.44s\n",
      "1199:\tlearn: 0.3783923\ttotal: 9.07s\tremaining: 0us\n",
      "\n",
      "Training Model 5 (Seed 8800)...\n",
      "0:\tlearn: 1.9132886\ttotal: 10.6ms\tremaining: 12.7s\n",
      "200:\tlearn: 0.4340022\ttotal: 1.32s\tremaining: 6.56s\n",
      "400:\tlearn: 0.4112012\ttotal: 2.44s\tremaining: 4.86s\n",
      "600:\tlearn: 0.3979494\ttotal: 3.66s\tremaining: 3.65s\n",
      "800:\tlearn: 0.3888147\ttotal: 4.87s\tremaining: 2.42s\n",
      "1000:\tlearn: 0.3842181\ttotal: 6.14s\tremaining: 1.22s\n",
      "1199:\tlearn: 0.3786344\ttotal: 7.39s\tremaining: 0us\n",
      "Файл submission_v22_autoreg_bagging.csv готов! Это претендент на топ-5.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "v21 = pd.read_csv('submission_v21_autoreg.csv')\n",
    "v22 = pd.read_csv('submission_v22_autoreg_bagging.csv')\n",
    "\n",
    "print(f\"Среднее значение V21: {v21['target'].mean():.4f}\")\n",
    "print(f\"Среднее значение V22: {v22['target'].mean():.4f}\")\n",
    "\n",
    "# Считаем, во скольких магазинах изменился прогноз\n",
    "diff_count = (v21['target'] != v22['target']).sum()\n",
    "total_count = len(v21)\n",
    "percent_diff = (diff_count / total_count) * 100\n",
    "\n",
    "print(f\"\\nРазличия:\")\n",
    "print(f\"Всего строк: {total_count}\")\n",
    "print(f\"Изменилось предсказаний: {diff_count} ({percent_diff:.2f}%)\")\n",
    "\n",
    "# В какую сторону изменения?\n",
    "diffs = v22['target'] - v21['target']\n",
    "print(f\"V22 увеличил прогноз: {(diffs > 0).sum()} раз\")\n",
    "print(f\"V22 уменьшил прогноз: {(diffs < 0).sum()} раз\")\n",
    "\n",
    "# Пример изменений\n",
    "if diff_count > 0:\n",
    "    print(\"\\nПримеры изменений (Store ID | Было - Стало):\")\n",
    "    changed_indices = v21[v21['target'] != v22['target']].index[:5]\n",
    "    for idx in changed_indices:\n",
    "        store = v21.loc[idx, 'store_id']\n",
    "        old_val = v21.loc[idx, 'target']\n",
    "        new_val = v22.loc[idx, 'target']\n",
    "        print(f\"{store} | {old_val} -> {new_val}\")\n",
    "\n",
    "print(\"\\nВЕРДИКТ\")\n",
    "if diff_count == 0:\n",
    "    print(\"Файлы идентичны!\")\n",
    "elif diff_count < 20:\n",
    "    print(\"Изменений очень мало.\")\n",
    "elif 20 <= diff_count <= 300:\n",
    "    print(\"ОТЛИЧНО! бэггинг скорректировал пограничные случаи (3-10% данных)\")\n",
    "else:\n",
    "    print(\"Изменений очень много (>12%)\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aTgh4aRu7Pq",
    "outputId": "90e319be-f1f6-44fd-c97a-3fb64dda9cf2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Среднее значение V21: 2.3897\n",
      "Среднее значение V22: 2.3843\n",
      "\n",
      "Различия:\n",
      "Всего строк: 2438\n",
      "Изменилось предсказаний: 49 (2.01%)\n",
      "V22 увеличил прогноз: 18 раз\n",
      "V22 уменьшил прогноз: 31 раз\n",
      "\n",
      "Примеры изменений (Store ID | Было -> Стало):\n",
      "086f6748-70c4-11ed-885b-08c0eb32014b | 14.0 -> 13.0\n",
      "0bd8083b-009d-11ef-b973-08c0eb32008b | 7.0 -> 6.0\n",
      "0f7a6cef-d7e9-11eb-85ac-1c34dae33151 | 7.0 -> 6.0\n",
      "129695ad-87ae-11ef-b973-08c0eb32008b | 7.0 -> 8.0\n",
      "13231899-594a-11ea-8385-0050560306e1 | 8.0 -> 9.0\n",
      "\n",
      "--- ВЕРДИКТ ---\n",
      "🚀 ОТЛИЧНО! Бэггинг скорректировал пограничные случаи (3-10% данных). Это самый здоровый признак улучшения.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "# Берем историю таргетов\n",
    "targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "\n",
    "# Функция для создания лага\n",
    "def create_lag(df_target, weeks_shift):\n",
    "    df_shifted = df_target.copy()\n",
    "    df_shifted['calendar_dt'] = df_shifted['calendar_dt'] + pd.Timedelta(weeks=weeks_shift)\n",
    "    df_shifted = df_shifted.rename(columns={'target': f'lag_target_{weeks_shift}'})\n",
    "    return df_shifted\n",
    "\n",
    "# Создаем лаги на 1, 2, 3, 4 недели вперед\n",
    "lag1 = create_lag(targets, 1)\n",
    "lag2 = create_lag(targets, 2)\n",
    "lag3 = create_lag(targets, 3)\n",
    "lag4 = create_lag(targets, 4)\n",
    "\n",
    "def feature_engineering_deep(df_main, df_facts, df_shifts):\n",
    "    # Базовые мерджи\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # Мерджим лаги (История)\n",
    "    df = df.merge(lag1, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(lag2, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(lag3, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(lag4, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # Заполняем пропуски (если истории нет, считаем что дефицита не было)\n",
    "    lag_cols = ['lag_target_1', 'lag_target_2', 'lag_target_3', 'lag_target_4']\n",
    "    df[lag_cols] = df[lag_cols].fillna(0)\n",
    "\n",
    "    # Средний дефицит за месяц\n",
    "    df['target_mean_4w'] = df[lag_cols].mean(axis=1)\n",
    "\n",
    "    # Растет дефицит или падает?\n",
    "    df['trend_short_vs_long'] = df['lag_target_1'] - df['target_mean_4w']\n",
    "\n",
    "    # Разница между прошлой и позапрошлой неделей\n",
    "    df['momentum'] = df['lag_target_1'] - df['lag_target_2']\n",
    "\n",
    "    # старые добрые фичи\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация глубоких признаков...\")\n",
    "X_full = feature_engineering_deep(train, facts, shifts)\n",
    "X_test_final = feature_engineering_deep(test, facts, shifts)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "seeds = [42, 2025, 777, 555, 8800, 123, 999]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"\\nНачинаем Deep Bagging ({len(seeds)} моделей)...\")\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(f\"Training Model {i+1}...\")\n",
    "\n",
    "    params = {\n",
    "        'iterations': 1300, # Чуть больше итераций, фич стало больше\n",
    "        'depth': 5,\n",
    "        'loss_function': 'MAE',\n",
    "        'verbose': 0, # Чтобы не спамить в консоль\n",
    "        'random_seed': seed,\n",
    "        'cat_features': cat_features,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "# Усредняем\n",
    "final_preds_float = test_preds_accum / len(seeds)\n",
    "\n",
    "final_preds = np.where(final_preds_float < 0.35, 0, final_preds_float)\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v23_deep_memory.csv', index=False)\n",
    "print(\"\\nФайл submission_v23_deep_memory.csv готов\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tQbx7FIYvvfP",
    "outputId": "710b4efb-3414-4ee8-ba2b-d2688738f026"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация глубоких признаков...\n",
      "\n",
      "Начинаем Deep Bagging (7 моделей)...\n",
      "Training Model 1...\n",
      "Training Model 2...\n",
      "Training Model 3...\n",
      "Training Model 4...\n",
      "Training Model 5...\n",
      "Training Model 6...\n",
      "Training Model 7...\n",
      "\n",
      "Файл submission_v23_deep_memory.csv готов! Идем на рекорд.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "v21 = pd.read_csv('submission_v22_autoreg_bagging.csv')\n",
    "v22 = pd.read_csv('submission_v23_deep_memory.csv')\n",
    "\n",
    "print(f\"Среднее значение V21: {v21['target'].mean():.4f}\")\n",
    "print(f\"Среднее значение V22: {v22['target'].mean():.4f}\")\n",
    "\n",
    "diff_count = (v21['target'] != v22['target']).sum()\n",
    "total_count = len(v21)\n",
    "percent_diff = (diff_count / total_count) * 100\n",
    "\n",
    "print(f\"\\nРазличия:\")\n",
    "print(f\"Всего строк: {total_count}\")\n",
    "print(f\"Изменилось предсказаний: {diff_count} ({percent_diff:.2f}%)\")\n",
    "\n",
    "diffs = v22['target'] - v21['target']\n",
    "print(f\"V22 увеличил прогноз: {(diffs > 0).sum()} раз\")\n",
    "print(f\"V22 уменьшил прогноз: {(diffs < 0).sum()} раз\")\n",
    "\n",
    "if diff_count > 0:\n",
    "    print(\"\\nПримеры изменений (Store ID | Было -> Стало):\")\n",
    "    changed_indices = v21[v21['target'] != v22['target']].index[:5]\n",
    "    for idx in changed_indices:\n",
    "        store = v21.loc[idx, 'store_id']\n",
    "        old_val = v21.loc[idx, 'target']\n",
    "        new_val = v22.loc[idx, 'target']\n",
    "        print(f\"{store} | {old_val} -> {new_val}\")\n",
    "\n",
    "print(\"\\nВЕРДИКТ\")\n",
    "if diff_count == 0:\n",
    "    print(\"Бэггинг не изменил округленные значения\")\n",
    "elif diff_count < 20:\n",
    "    print(\"Изменений очень мало\")\n",
    "elif 20 <= diff_count <= 300:\n",
    "    print(\"Бэггинг скорректировал пограничные случаи (3-10% данных)\")\n",
    "else:\n",
    "    print(\"Изменений очень много (>12%)\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpX9dwdjwFFo",
    "outputId": "01e96d9c-76a0-4f59-cc9a-324ec4f8f50d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Среднее значение V21: 2.3843\n",
      "Среднее значение V22: 2.3962\n",
      "\n",
      "Различия:\n",
      "Всего строк: 2438\n",
      "Изменилось предсказаний: 82 (3.36%)\n",
      "V22 увеличил прогноз: 53 раз\n",
      "V22 уменьшил прогноз: 29 раз\n",
      "\n",
      "Примеры изменений (Store ID | Было -> Стало):\n",
      "031693e6-9d20-11f0-aa3c-be3af2b6059f | 11.0 -> 10.0\n",
      "086f6748-70c4-11ed-885b-08c0eb32014b | 13.0 -> 12.0\n",
      "0c1c5535-0f6e-11ee-ae78-08c0eb320147 | 6.0 -> 7.0\n",
      "129695ad-87ae-11ef-b973-08c0eb32008b | 8.0 -> 7.0\n",
      "17ea18e1-abb7-11ed-b970-08c0eb32008b | 6.0 -> 7.0\n",
      "\n",
      "--- ВЕРДИКТ ---\n",
      "🚀 ОТЛИЧНО! Бэггинг скорректировал пограничные случаи (3-10% данных). Это самый здоровый признак улучшения.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_cols = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_cols = ['store_id']\n",
    "\n",
    "for col in cat_cols:\n",
    "    X_full[col] = X_full[col].fillna('missing').astype(str)\n",
    "    X_test_final[col] = X_test_final[col].fillna('missing').astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    full_cats = pd.concat([X_full[col], X_test_final[col]])\n",
    "    le.fit(full_cats)\n",
    "    X_full[col] = le.transform(X_full[col])\n",
    "    X_test_final[col] = le.transform(X_test_final[col])\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "seeds = [42, 2024, 777, 555, 8800]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Начинаем XGBoost Bagging ({len(seeds)} моделей)...\")\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(f\"Training XGB Model {i+1} (Seed {seed})...\")\n",
    "\n",
    "    model = xgb.XGBRegressor(\n",
    "        n_estimators=1000,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.04,\n",
    "        objective='reg:absoluteerror', # как MAE для XGBoost\n",
    "        n_jobs=-1,\n",
    "        random_state=seed,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method='hist' # Быстрый режим\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_full, y_train_full, verbose=False)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "# среднее XGBoost\n",
    "xgb_preds_float = test_preds_accum / len(seeds)\n",
    "\n",
    "# Округляем и чистим\n",
    "xgb_preds_final = np.where(xgb_preds_float < 0.35, 0, xgb_preds_float)\n",
    "xgb_preds_final = np.round(xgb_preds_final)\n",
    "xgb_preds_final = np.clip(xgb_preds_final, 0, None)\n",
    "\n",
    "# Сохраняем чистый XGBoost (на всякий случай)\n",
    "sub_xgb = sample_sub.copy()\n",
    "sub_xgb['target'] = xgb_preds_final\n",
    "sub_xgb.to_csv('submission_v24_xgboost_pure.csv', index=False)\n",
    "print(\"Чистый XGBoost готов.\")\n",
    "\n",
    "# CatBoost V22 + XGBoost V24\n",
    "print(\"\\nСоздаем Блендинг...\")\n",
    "sub_cat = pd.read_csv('submission_v22_autoreg_bagging.csv')\n",
    "\n",
    "# сделаем 50/50\n",
    "blend_preds = (sub_cat['target'] * 0.5) + (sub_xgb['target'] * 0.5)\n",
    "\n",
    "# Финальное округление бленда\n",
    "blend_preds = np.round(blend_preds)\n",
    "\n",
    "sub_final = sample_sub.copy()\n",
    "sub_final['target'] = blend_preds\n",
    "sub_final.to_csv('submission_v25_CAT_XGB_BLEND.csv', index=False)\n",
    "print(\"Файл submission_v25_CAT_XGB_BLEND.csv ГОТОВ!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7IKQTNvuw4js",
    "outputId": "6becc6ce-66ba-4dec-917e-9b3ddda59e50"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков...\n",
      "Начинаем XGBoost Bagging (5 моделей)...\n",
      "Training XGB Model 1 (Seed 42)...\n",
      "Training XGB Model 2 (Seed 2024)...\n",
      "Training XGB Model 3 (Seed 777)...\n",
      "Training XGB Model 4 (Seed 555)...\n",
      "Training XGB Model 5 (Seed 8800)...\n",
      "Чистый XGBoost готов.\n",
      "\n",
      "Создаем Блендинг...\n",
      "Файл submission_v25_CAT_XGB_BLEND.csv ГОТОВ! Это мощь.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "corr = sub_cat['target'].corr(sub_xgb['target'])\n",
    "print(f\"Корреляция CatBoost vs XGBoost: {corr:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0QeQ3zmQw_VQ",
    "outputId": "cf66a853-b59d-4a0c-e91d-aaf02a90a067"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Корреляция CatBoost vs XGBoost: 0.99340\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering_physics(df_main, df_facts, df_shifts, df_lags):\n",
    "    # Мерджим всё\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    # НОВЫЕ ФИЧИ\n",
    "    # Рост спроса: Прогноз заказов - Факт заказов прошлой недели\n",
    "    # Если прогнозируем всплеск заказов, а штат старый - дефицит\n",
    "    df['orders_growth_num'] = df['predicted_num_orders'] - df['fact_num_orders_lag_1']\n",
    "\n",
    "    # Сколько заказов по прогнозу придется на одного курьера (по факту прошлой недели)\n",
    "    # Если это число выше нормы (например > 4), курьеры не вывезут\n",
    "    df['potential_load_per_courier'] = df['predicted_num_orders'] / (df['fact_couriers_with_shifts_lag_1'] + 1e-5)\n",
    "\n",
    "    # Прогноз заказов - (Курьеры * Их привычная нагрузка)\n",
    "    # Сколько заказов мы физически НЕ сможем развести текущим штатом\n",
    "    possible_orders = df['fact_couriers_with_shifts_lag_1'] * df['fact_load_factor_lag_1']\n",
    "    df['orders_overflow'] = df['predicted_num_orders'] - possible_orders\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация физических признаков...\")\n",
    "X_full = feature_engineering_physics(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering_physics(test, facts, shifts, past_targets)\n",
    "\n",
    "# Категории\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "mask_val = X_full['calendar_dt'] == val_date\n",
    "mask_train = X_full['calendar_dt'] < val_date\n",
    "\n",
    "X_train_fold = X_full[mask_train].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_fold = X_full.loc[mask_train, 'target']\n",
    "X_val_fold = X_full[mask_val].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val_fold = X_full.loc[mask_val, 'target']\n",
    "\n",
    "print(\"\\nПРОВЕРКА V26 ЛОКАЛЬНО\")\n",
    "# Обучаем 1 быструю модель для проверки гипотезы\n",
    "model_check = CatBoostRegressor(\n",
    "    iterations=800, depth=5, loss_function='MAE',\n",
    "    verbose=0, random_seed=42, cat_features=cat_features\n",
    ")\n",
    "model_check.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "preds_val = model_check.predict(X_val_fold)\n",
    "preds_val = np.round(np.where(preds_val < 0.35, 0, preds_val))\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "score_v26 = wape(y_val_fold, preds_val)\n",
    "print(f\"LOCAL WAPE V26 (с новыми фичами): {score_v26:.5f}\")\n",
    "\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "seeds = [42, 2024, 777, 555, 8800] # Те же 5 сидов\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"\\nЗапускаем Bagging V26 ({len(seeds)} seeds)...\")\n",
    "for seed in seeds:\n",
    "    print(f\".\", end=\"\")\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1200, depth=5, loss_function='MAE',\n",
    "        verbose=0, random_seed=seed, cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(seeds)\n",
    "\n",
    "# Пост-процессинг\n",
    "final_preds = np.where(final_preds_float < 0.35, 0, final_preds_float)\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v26_physics.csv', index=False)\n",
    "print(\"\\nФайл submission_v26_physics.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgwgPClLyIXV",
    "outputId": "306486ad-7595-41d8-f7d6-43be225405b2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация физических признаков...\n",
      "\n",
      "--- ПРОВЕРКА V26 (Physics) ЛОКАЛЬНО ---\n",
      ">>> LOCAL WAPE V26 (с новыми фичами): 0.16886\n",
      "\n",
      "Запускаем Bagging V26 (5 seeds)...\n",
      ".....\n",
      "Файл submission_v26_physics.csv готов.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Стандартные фичи V22\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "mask_val = X_full['calendar_dt'] == val_date\n",
    "mask_train = X_full['calendar_dt'] < val_date\n",
    "\n",
    "X_train_fold = X_full[mask_train].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_fold = X_full.loc[mask_train, 'target']\n",
    "X_val_fold = X_full[mask_val].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val_fold = X_full.loc[mask_val, 'target']\n",
    "\n",
    "seeds = [42, 2024, 777] # 3 сида для скорости поиска порога\n",
    "val_preds_accum = np.zeros(len(X_val_fold))\n",
    "\n",
    "for seed in seeds:\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1000, depth=5, loss_function='MAE',\n",
    "        verbose=0, random_seed=seed, cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    val_preds_accum += model.predict(X_val_fold)\n",
    "\n",
    "val_preds_avg = val_preds_accum / len(seeds)\n",
    "\n",
    "# Перебор порогов\n",
    "best_threshold = 0.5\n",
    "best_score = 1.0\n",
    "\n",
    "# Пробуем пороги от 0.35 до 0.65 с шагом 0.01\n",
    "thresholds = np.arange(0.35, 0.65, 0.01)\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "for t in thresholds:\n",
    "    current_preds = np.floor(val_preds_avg + (1 - t))\n",
    "    # защита от отрицательных и мелкого шума\n",
    "    current_preds = np.where(val_preds_avg < 0.35, 0, current_preds)\n",
    "\n",
    "    score = wape(y_val_fold, current_preds)\n",
    "\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"\\nЛучший порог найден: {best_threshold:.2f}\")\n",
    "print(f\"Лучший Local WAPE с этим порогом: {best_score:.5f}\")\n",
    "\n",
    "print(\"\\nФинальный Bagging (5 Seeds)\")\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "final_seeds = [42, 2024, 777, 555, 8800]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "for i, seed in enumerate(final_seeds):\n",
    "    print(f\"Training Model {i+1}...\")\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1200, depth=5, loss_function='MAE',\n",
    "        verbose=0, random_seed=seed, cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(final_seeds)\n",
    "\n",
    "# зануляем явный шум\n",
    "final_preds = np.where(final_preds_float < 0.35, 0, final_preds_float)\n",
    "\n",
    "# умное округление\n",
    "final_preds = np.floor(final_preds + (1 - best_threshold))\n",
    "\n",
    "# защита\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_final_calibrated.csv', index=False)\n",
    "print(f\"\\nФайл submission_final_calibrated.csv готов!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzizvGEkyxpE",
    "outputId": "5a834511-b0e2-4b73-da1e-81246ffe06f4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков...\n",
      "\n",
      "--- Этап 1: Поиск магического порога (Calibration) ---\n",
      "\n",
      "🏆 Лучший порог найден: 0.63\n",
      "🏆 Лучший Local WAPE с этим порогом: 0.16581\n",
      "(Для сравнения, стандартный round давал ~0.165)\n",
      "\n",
      "--- Этап 2: Финальный Bagging (5 Seeds) ---\n",
      "Training Model 1...\n",
      "Training Model 2...\n",
      "Training Model 3...\n",
      "Training Model 4...\n",
      "Training Model 5...\n",
      "\n",
      "Файл submission_final_calibrated.csv готов!\n",
      "Использован порог: 0.63\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "mask_val = X_full['calendar_dt'] == val_date\n",
    "mask_train = X_full['calendar_dt'] < val_date\n",
    "\n",
    "X_train_fold = X_full[mask_train].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_fold = X_full.loc[mask_train, 'target']\n",
    "X_val_fold = X_full[mask_val].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val_fold = X_full.loc[mask_val, 'target']\n",
    "\n",
    "# Быстрый прогон на 3 сидах для поиска параметра\n",
    "check_seeds = [42, 777, 2024]\n",
    "val_preds_accum = np.zeros(len(X_val_fold))\n",
    "\n",
    "print(\"\\nКалибровка отсечения нуля (Zero Threshold)...\")\n",
    "for seed in check_seeds:\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1000, depth=5, loss_function='MAE',\n",
    "        verbose=0, random_seed=seed, cat_features=cat_features\n",
    "    )\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    val_preds_accum += model.predict(X_val_fold)\n",
    "\n",
    "val_preds_avg = val_preds_accum / len(check_seeds)\n",
    "\n",
    "# Перебираем пороги зануления\n",
    "zero_thresholds = [0.25, 0.30, 0.35, 0.40, 0.45, 0.50]\n",
    "best_zero_th = 0.35\n",
    "best_score = 1.0\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "for zt in zero_thresholds:\n",
    "    # Зануляем мелочь\n",
    "    preds = np.where(val_preds_avg < zt, 0, val_preds_avg)\n",
    "    # Стандартное округление (оно работает лучше всего)\n",
    "    preds = np.round(preds)\n",
    "\n",
    "    score = wape(y_val_fold, preds)\n",
    "    print(f\"Zero Threshold {zt}: WAPE = {score:.5f}\")\n",
    "\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        best_zero_th = zt\n",
    "\n",
    "print(f\"\\nПобедил порог зануления: {best_zero_th} (WAPE: {best_score:.5f})\")\n",
    "\n",
    "print(f\"\\nЗапускаем Тяжелый Бэггинг (15 моделей) с порогом {best_zero_th}...\")\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "# 15 разных сидов для максимальной стабильности\n",
    "final_seeds = [\n",
    "    42, 2024, 777, 555, 8800,\n",
    "    100, 200, 300, 1234, 5678,\n",
    "    999, 111, 222, 333, 444\n",
    "]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "for i, seed in enumerate(final_seeds):\n",
    "    # Выводим точку каждые 3 модели, чтобы видеть прогресс\n",
    "    if i % 3 == 0: print(f\"Training models batch {i+1}-{i+3}...\")\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1200, depth=5, loss_function='MAE',\n",
    "        verbose=0, random_seed=seed, cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(final_seeds)\n",
    "\n",
    "final_preds = np.where(final_preds_float < best_zero_th, 0, final_preds_float)\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v28_heavy_bagging.csv', index=False)\n",
    "print(\"\\nФайл submission_v28_heavy_bagging.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32IH3CwFzhDG",
    "outputId": "7ff3dabc-7ee8-4c3f-8197-3437f23983b4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков...\n",
      "\n",
      "Калибровка отсечения нуля (Zero Threshold)...\n",
      "Zero Threshold 0.25: WAPE = 0.16741\n",
      "Zero Threshold 0.3: WAPE = 0.16741\n",
      "Zero Threshold 0.35: WAPE = 0.16741\n",
      "Zero Threshold 0.4: WAPE = 0.16741\n",
      "Zero Threshold 0.45: WAPE = 0.16741\n",
      "Zero Threshold 0.5: WAPE = 0.16741\n",
      "\n",
      "✅ Победил порог зануления: 0.25 (WAPE: 0.16741)\n",
      "\n",
      "Запускаем Тяжелый Бэггинг (15 моделей) с порогом 0.25...\n",
      "Training models batch 1-3...\n",
      "Training models batch 4-6...\n",
      "Training models batch 7-9...\n",
      "Training models batch 10-12...\n",
      "Training models batch 13-15...\n",
      "\n",
      "Файл submission_v28_heavy_bagging.csv готов.\n",
      "Это самая стабильная и мощная версия твоего решения.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "print(f\"\\nЗапускаем Median Bagging (15 моделей)...\")\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "final_seeds = [\n",
    "    42, 2024, 777, 555, 8800,\n",
    "    100, 200, 300, 1234, 5678,\n",
    "    999, 111, 222, 333, 444\n",
    "]\n",
    "\n",
    "# Создаем список, куда будем складывать ВСЕ предсказания\n",
    "all_predictions = []\n",
    "\n",
    "for i, seed in enumerate(final_seeds):\n",
    "    if i % 3 == 0: print(f\"Training models batch {i+1}-{i+3}...\")\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1200, depth=5, loss_function='MAE',\n",
    "        verbose=0, random_seed=seed, cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    preds = model.predict(X_test_ready)\n",
    "    all_predictions.append(preds)\n",
    "\n",
    "# Берем МЕДИАНУ по всем предсказаниям\n",
    "print(\"\\nСчитаем медиану ансамбля...\")\n",
    "all_predictions_np = np.array(all_predictions)\n",
    "final_preds_median = np.median(all_predictions_np, axis=0)\n",
    "\n",
    "# Стандартный порог и округление\n",
    "final_preds = np.where(final_preds_median < 0.35, 0, final_preds_median)\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v29_median_bagging.csv', index=False)\n",
    "print(\"\\nФайл submission_v29_median_bagging.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k84jrptw01KS",
    "outputId": "308314c6-8b5f-43ed-fb9e-5a937cf52690"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков...\n",
      "\n",
      "Запускаем Median Bagging (15 моделей)...\n",
      "Training models batch 1-3...\n",
      "Training models batch 4-6...\n",
      "Training models batch 7-9...\n",
      "Training models batch 10-12...\n",
      "Training models batch 13-15...\n",
      "\n",
      "Считаем медиану ансамбля...\n",
      "\n",
      "Файл submission_v29_median_bagging.csv готов.\n",
      "Это математически самое точное решение для метрики WAPE.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "v22_best = pd.read_csv('submission_v22_autoreg_bagging.csv')\n",
    "v29_new = pd.read_csv('submission_v29_median_bagging.csv')\n",
    "\n",
    "# Статистика\n",
    "print(f\"Среднее значение V22 (Best): {v22_best['target'].mean():.4f}\")\n",
    "print(f\"Среднее значение V29 (New):  {v29_new['target'].mean():.4f}\")\n",
    "\n",
    "# Количество изменений\n",
    "diff_mask = v22_best['target'] != v29_new['target']\n",
    "diff_count = diff_mask.sum()\n",
    "total_count = len(v22_best)\n",
    "percent_diff = (diff_count / total_count) * 100\n",
    "\n",
    "print(f\"\\nРазличия:\")\n",
    "print(f\"Всего строк: {total_count}\")\n",
    "print(f\"Изменилось предсказаний: {diff_count} ({percent_diff:.2f}%)\")\n",
    "\n",
    "# Анализ изменений\n",
    "if diff_count > 0:\n",
    "    diffs = v29_new.loc[diff_mask, 'target'] - v22_best.loc[diff_mask, 'target']\n",
    "    print(f\"V29 увеличил прогноз: {(diffs > 0).sum()} раз\")\n",
    "    print(f\"V29 уменьшил прогноз: {(diffs < 0).sum()} раз\")\n",
    "\n",
    "    print(\"\\nПримеры изменений\")\n",
    "    # Берем 5 случайных изменений\n",
    "    sample_idxs = v29_new[diff_mask].sample(min(5, diff_count), random_state=42).index\n",
    "    for idx in sample_idxs:\n",
    "        store = v29_new.loc[idx, 'store_id']\n",
    "        old_val = v22_best.loc[idx, 'target']\n",
    "        new_val = v29_new.loc[idx, 'target']\n",
    "        print(f\"{store} | {old_val} -> {new_val}\")\n",
    "\n",
    "if diff_count == 0:\n",
    "    print(\"Файлы идентичны!\")\n",
    "elif diff_count < 10:\n",
    "    print(\"Изменений очень мало (<10)\")\n",
    "elif 10 <= diff_count <= 150:\n",
    "    print(\"Изменилось от 0.5% до 6% прогнозов\")\n",
    "else:\n",
    "    print(\"Изменений много (>150)\")"
   ],
   "metadata": {
    "id": "KdvQx24B1v2e",
    "outputId": "81c9030e-3f91-4809-a33f-48cac312dade",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Среднее значение V22 (Best): 2.3843\n",
      "Среднее значение V29 (New):  2.3835\n",
      "\n",
      "Различия:\n",
      "Всего строк: 2438\n",
      "Изменилось предсказаний: 20 (0.82%)\n",
      "V29 увеличил прогноз: 9 раз\n",
      "V29 уменьшил прогноз: 11 раз\n",
      "\n",
      "Примеры изменений (Store ID | V22 -> V29):\n",
      "129695ad-87ae-11ef-b973-08c0eb32008b | 8.0 -> 7.0\n",
      "c1de499b-47bc-11ec-85ad-1c34dae33151 | 8.0 -> 9.0\n",
      "742729aa-ec79-11ec-8859-08c0eb32014b | 6.0 -> 7.0\n",
      "15fe19b9-8ac4-11ea-aff3-0050560306e1 | 8.0 -> 7.0\n",
      "3ceb9456-4ccc-11ee-885f-08c0eb32014b | 8.0 -> 7.0\n",
      "\n",
      "--- ВЕРДИКТ ---\n",
      "✅ ИДЕАЛЬНО! Изменилось от 0.5% до 6% прогнозов. Это именно та 'тонкая настройка' спорных моментов.\n",
      "Рекомендую отправлять.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "# Даты\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "target_history = train[['store_id', 'calendar_dt', 'target']].sort_values(['store_id', 'calendar_dt'])\n",
    "\n",
    "# Создаем функцию для генерации лагов и окон\n",
    "def create_lag_features(df, target_col='target'):\n",
    "    for i in [1, 2, 3, 4]:\n",
    "        df[f'lag_{i}'] = df.groupby('store_id')[target_col].shift(i)\n",
    "\n",
    "    # Среднее за 4 недели\n",
    "    df['rolling_mean_4w'] = df[[f'lag_{i}' for i in range(1, 5)]].mean(axis=1)\n",
    "    # Максимум за 4 недели\n",
    "    df['rolling_max_4w'] = df[[f'lag_{i}' for i in range(1, 5)]].max(axis=1)\n",
    "    # Стандартное отклонение\n",
    "    df['rolling_std_4w'] = df[[f'lag_{i}' for i in range(1, 5)]].std(axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "test_stub = test[['store_id', 'calendar_dt']].copy()\n",
    "test_stub['target'] = np.nan # Мы этого не знаем\n",
    "\n",
    "full_history = pd.concat([target_history, test_stub], ignore_index=True)\n",
    "full_history = full_history.sort_values(['store_id', 'calendar_dt'])\n",
    "\n",
    "# Генерируем лаги на всей истории\n",
    "full_history = create_lag_features(full_history)\n",
    "\n",
    "# Отделяем обратно\n",
    "features_from_history = full_history.drop(columns=['target']) # target убираем, он есть в train\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_hist_feats):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # Приклеиваем исторические фичи\n",
    "    df = df.merge(df_hist_feats, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # Заполняем пропуски в лагах нулями\n",
    "    lag_cols = [c for c in df.columns if 'lag_' in c or 'rolling_' in c]\n",
    "    df[lag_cols] = df[lag_cols].fillna(0)\n",
    "\n",
    "    # Старые добрые фичи из V22\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_vs_month'] = df['predicted_staff_value'] - df['rolling_mean_4w']\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация Rolling признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, features_from_history)\n",
    "X_test_final = feature_engineering(test, facts, shifts, features_from_history)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "# Добавим пару сидов для надежности (7 моделей)\n",
    "seeds = [42, 2024, 777, 555, 8800, 100, 999]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Начинаем Rolling Bagging ({len(seeds)} моделей)...\")\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(f\"Training Model {i+1} (Seed {seed})...\")\n",
    "\n",
    "    # Чуть увеличим итерации, так как фич стало больше\n",
    "    params = {\n",
    "        'iterations': 1400,\n",
    "        'depth': 5, # Оставляем 5, чтобы не переобучиться на истории\n",
    "        'loss_function': 'MAE',\n",
    "        'verbose': 0,\n",
    "        'random_seed': seed,\n",
    "        'cat_features': cat_features,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "# Усредняем (Mean работает лучше Median для WAPE, мы это проверили)\n",
    "final_preds_float = test_preds_accum / len(seeds)\n",
    "\n",
    "# Если предсказание < 0.3, считаем что дефицита нет.\n",
    "final_preds = np.where(final_preds_float < 0.3, 0, final_preds_float)\n",
    "\n",
    "# Округление\n",
    "final_preds = np.round(final_preds)\n",
    "\n",
    "# Clip\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v30_rolling_stats.csv', index=False)\n",
    "print(\"Файл submission_v30_rolling_stats.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P94hyuWOoiiR",
    "outputId": "f3794e2f-aa40-4f62-ea6e-faafb1a45bae"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация Rolling признаков...\n",
      "Начинаем Rolling Bagging (7 моделей)...\n",
      "Training Model 1 (Seed 42)...\n",
      "Training Model 2 (Seed 2024)...\n",
      "Training Model 3 (Seed 777)...\n",
      "Training Model 4 (Seed 555)...\n",
      "Training Model 5 (Seed 8800)...\n",
      "Training Model 6 (Seed 100)...\n",
      "Training Model 7 (Seed 999)...\n",
      "Файл submission_v30_rolling_stats.csv готов.\n",
      "Фичи: Lags 1-4, Rolling Mean/Max/Std 4w, Trend vs Month.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "v22 = pd.read_csv('submission_v22_autoreg_bagging.csv')\n",
    "v30 = pd.read_csv('submission_v30_rolling_stats.csv')\n",
    "\n",
    "# Сравнение файлов\n",
    "diff_mask = v22['target'] != v30['target']\n",
    "diff_count = diff_mask.sum()\n",
    "mae_diff = np.mean(np.abs(v22['target'] - v30['target']))\n",
    "\n",
    "print(f\"Всего магазинов: {len(v22)}\")\n",
    "print(f\"Изменилось предсказаний: {diff_count} ({diff_count/len(v22):.2%})\")\n",
    "print(f\"Среднее изменение (MAE между файлами): {mae_diff:.4f}\")\n",
    "\n",
    "if diff_count > 0:\n",
    "    diffs = v30.loc[diff_mask, 'target'] - v22.loc[diff_mask, 'target']\n",
    "    print(f\"V30 повысил прогноз: {(diffs > 0).sum()} раз\")\n",
    "    print(f\"V30 понизил прогноз: {(diffs < 0).sum()} раз\")\n",
    "\n",
    "    print(\"\\nПримеры изменений:\")\n",
    "    # 5 случайных изменений\n",
    "    idxs = v30[diff_mask].sample(min(5, diff_count), random_state=42).index\n",
    "    for idx in idxs:\n",
    "        print(f\"{v30.loc[idx, 'store_id']} | {v22.loc[idx, 'target']} -> {v30.loc[idx, 'target']}\")\n",
    "else:\n",
    "    print(\"Файлы идентичны!\")\n",
    "\n",
    "try:\n",
    "    check_model = CatBoostRegressor(\n",
    "        iterations=500, depth=5, loss_function='MAE', verbose=0, random_seed=42, cat_features=cat_features\n",
    "    )\n",
    "    check_model.fit(X_train_full, y_train_full)\n",
    "\n",
    "    fi = check_model.get_feature_importance(prettified=True)\n",
    "    print(\"\\nТоп-10 важных признаков:\")\n",
    "    print(fi.head(10))\n",
    "\n",
    "    # проверка, вошли ли новые фичи в топ\n",
    "    new_features = ['rolling_mean_4w', 'rolling_max_4w', 'rolling_std_4w', 'trend_vs_month']\n",
    "    print(\"\\nПозиции новых фич:\")\n",
    "    for feat in new_features:\n",
    "        if feat in fi['Feature Id'].values:\n",
    "            rank = fi[fi['Feature Id'] == feat].index[0] + 1\n",
    "            score = fi[fi['Feature Id'] == feat]['Importances'].values[0]\n",
    "            print(f\"{feat}: Место #{rank}, Важность {score:.2f}\")\n",
    "        else:\n",
    "            print(f\"{feat}: Не используется!\")\n",
    "except NameError:\n",
    "    print(\"Ошибка: переменные обучения не найдены в памяти\")\n",
    "\n",
    "val_date = X_full['calendar_dt'].max()\n",
    "\n",
    "# Сплит\n",
    "X_local_train = X_full[X_full['calendar_dt'] < val_date].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_local_train = X_full.loc[X_full['calendar_dt'] < val_date, 'target']\n",
    "\n",
    "X_local_val = X_full[X_full['calendar_dt'] == val_date].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_local_val = X_full.loc[X_full['calendar_dt'] == val_date, 'target']\n",
    "\n",
    "# Обучаем модель V30\n",
    "model_v30_local = CatBoostRegressor(\n",
    "    iterations=1000, depth=5, loss_function='MAE', verbose=0, random_seed=42, cat_features=cat_features\n",
    ")\n",
    "model_v30_local.fit(X_local_train, y_local_train)\n",
    "preds_v30 = model_v30_local.predict(X_local_val)\n",
    "\n",
    "# Пост-процессинг V30\n",
    "preds_v30 = np.round(np.where(preds_v30 < 0.3, 0, preds_v30))\n",
    "wape_v30 = np.sum(np.abs(y_local_val - preds_v30)) / np.sum(np.abs(y_local_val))\n",
    "\n",
    "print(f\"Локальный WAPE модели V30: {wape_v30:.5f}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYWJ8LxdrB_R",
    "outputId": "4352fd6d-c171-4f34-ad5b-4d2ff75ff94c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "=== 1. СРАВНЕНИЕ С ЧЕМПИОНОМ (V22 vs V30) ===\n",
      "Всего магазинов: 2438\n",
      "Изменилось предсказаний: 90 (3.69%)\n",
      "Среднее изменение (MAE между файлами): 0.0386\n",
      "V30 повысил прогноз: 50 раз\n",
      "V30 понизил прогноз: 40 раз\n",
      "\n",
      "Примеры изменений (Store ID | V22 -> V30):\n",
      "8e19d76f-7115-11f0-9bb2-be3af2b6059f | 6.0 -> 7.0\n",
      "35c4255b-2444-11ed-b96c-08c0eb32008b | 7.0 -> 6.0\n",
      "b43dc4d5-d612-11ee-b973-08c0eb32008b | 5.0 -> 4.0\n",
      "ce6c1cbd-77f4-11ee-ae79-08c0eb320147 | 7.0 -> 6.0\n",
      "086f6748-70c4-11ed-885b-08c0eb32014b | 13.0 -> 12.0\n",
      "\n",
      "=== 2. ВАЖНОСТЬ ПРИЗНАКОВ (Feature Importance) ===\n",
      "\n",
      "Топ-10 важных признаков:\n",
      "              Feature Id  Importances\n",
      "0       fact_staff_churn    62.937480\n",
      "1   flag_high_load_lag_1    10.597402\n",
      "2                  lag_1     3.841923\n",
      "3        rolling_mean_4w     2.635879\n",
      "4         rolling_max_4w     2.434137\n",
      "5            churn_ratio     2.128600\n",
      "6  diff_plan_vs_fact_lag     2.051598\n",
      "7  predicted_staff_value     1.492995\n",
      "8                  lag_2     1.470356\n",
      "9                  lag_3     1.282158\n",
      "\n",
      "Позиции новых фич:\n",
      "rolling_mean_4w: Место #4, Важность 2.64\n",
      "rolling_max_4w: Место #5, Важность 2.43\n",
      "rolling_std_4w: Место #20, Важность 0.61\n",
      "trend_vs_month: Место #14, Важность 0.76\n",
      "\n",
      "=== 3. ЛОКАЛЬНЫЙ БЭКТЕСТ (На дате 2025-11-17) ===\n",
      "Локальный WAPE модели V30: 0.16597\n",
      "(Для ориентира: V22 давал ~0.165 на локальной валидации. Если здесь меньше — это ПОБЕДА).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_best = 'submission_v22_autoreg_bagging.csv'\n",
    "file_new = 'submission_v30_rolling_stats.csv'\n",
    "\n",
    "v22 = pd.read_csv(file_best)\n",
    "v30 = pd.read_csv(file_new)\n",
    "\n",
    "print(\"--- Статистика ---\")\n",
    "print(f\"V22 Mean: {v22['target'].mean():.4f}\")\n",
    "print(f\"V30 Mean: {v30['target'].mean():.4f}\")\n",
    "\n",
    "# Взвешенное смешивание\n",
    "# Даём 75% веса лучшей модели (V22) и 25% новой (V30)\n",
    "w_best = 0.75\n",
    "w_new = 0.25\n",
    "\n",
    "blend_val = (v22['target'] * w_best) + (v30['target'] * w_new)\n",
    "\n",
    "# Округление\n",
    "# Это критический момент. Результат смешивания будет дробным (например, 2.25).\n",
    "# Нам нужно округлить его до целого\n",
    "blend_final = np.floor(blend_val + 0.5)\n",
    "\n",
    "# Анализ изменений\n",
    "diff_mask = blend_final != v22['target']\n",
    "changes = diff_mask.sum()\n",
    "\n",
    "print(f\"\\nРезультат Блендинга\")\n",
    "print(f\"Веса: {w_best} (V22) / {w_new} (V30)\")\n",
    "print(f\"Изменилось предсказаний относительно V22: {changes} (из {len(v22)})\")\n",
    "print(f\"Процент изменений: {changes / len(v22) * 100:.2f}%\")\n",
    "\n",
    "if changes > 0:\n",
    "    print(\"\\nПримеры изменений:\")\n",
    "    sample = v22[diff_mask].sample(min(5, changes), random_state=42).index\n",
    "    for idx in sample:\n",
    "        sid = v22.loc[idx, 'store_id']\n",
    "        old = v22.loc[idx, 'target']\n",
    "        new = blend_final[idx]\n",
    "        # покажем, что предлагала V30\n",
    "        alt = v30.loc[idx, 'target']\n",
    "        print(f\"{sid} | V22={old} (V30={alt}) -> NEW={new}\")\n",
    "\n",
    "sub = v22.copy()\n",
    "sub['target'] = blend_final\n",
    "sub.to_csv('submission_v31_weighted_blend.csv', index=False)\n",
    "print(\"\\nФайл submission_v31_weighted_blend.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7agKf3xTsGBZ",
    "outputId": "cd5be611-ce5c-4274-a3f1-920c455bef2c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Статистика ---\n",
      "V22 Mean: 2.3843\n",
      "V30 Mean: 2.3901\n",
      "\n",
      "--- Результат Блендинга ---\n",
      "Веса: 0.75 (V22) / 0.25 (V30)\n",
      "Изменилось предсказаний относительно V22: 4 (из 2438)\n",
      "Процент изменений: 0.16%\n",
      "\n",
      "Примеры изменений (Store ID | V22 -> Blend):\n",
      "64e754eb-37fe-11ec-85ad-1c34dae33151 | V22=8.0 (V30=10.0) -> NEW=9.0\n",
      "c1de499b-47bc-11ec-85ad-1c34dae33151 | V22=8.0 (V30=10.0) -> NEW=9.0\n",
      "31f29954-9d79-11ee-ae7a-08c0eb320147 | V22=6.0 (V30=8.0) -> NEW=7.0\n",
      "6a53a2f1-f3e6-11ed-ae78-08c0eb320147 | V22=11.0 (V30=13.0) -> NEW=12.0\n",
      "\n",
      "Файл submission_v31_weighted_blend.csv готов.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Стандартный проверенный набор фич\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    # Динамический порог для будущей фильтрации\n",
    "    # Если заказы растут > 10% к прошлой неделе\n",
    "    df['orders_growth_heavy'] = (df['predicted_num_orders'] / (df['fact_num_orders_lag_1'] + 1)) > 1.10\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "# 9 моделей: 3 простых, 3 средних, 3 сложных\n",
    "models_config = [\n",
    "    {'depth': 4, 'iter': 1500, 'lr': 0.04, 'seed': 42},\n",
    "    {'depth': 4, 'iter': 1500, 'lr': 0.04, 'seed': 2024},\n",
    "    {'depth': 4, 'iter': 1500, 'lr': 0.04, 'seed': 777},\n",
    "\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 42},\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 2024},\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 777},\n",
    "\n",
    "    {'depth': 8, 'iter': 1000, 'lr': 0.02, 'seed': 42},\n",
    "    {'depth': 8, 'iter': 1000, 'lr': 0.02, 'seed': 2024},\n",
    "    {'depth': 8, 'iter': 1000, 'lr': 0.02, 'seed': 777},\n",
    "]\n",
    "\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Начинаем Multi-Depth Bagging ({len(models_config)} моделей)...\")\n",
    "\n",
    "for i, conf in enumerate(models_config):\n",
    "    print(f\"Training Model {i+1} (Depth {conf['depth']})...\")\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=conf['iter'],\n",
    "        depth=conf['depth'],\n",
    "        learning_rate=conf['lr'],\n",
    "        loss_function='MAE',\n",
    "        verbose=0,\n",
    "        random_seed=conf['seed'],\n",
    "        cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "# Усредняем\n",
    "final_preds_float = test_preds_accum / len(models_config)\n",
    "\n",
    "\n",
    "# Достаем вспомогательные колонки для теста\n",
    "lag_target_test = X_test_final['lag_target_1'].values\n",
    "is_high_growth = X_test_final['orders_growth_heavy'].values\n",
    "\n",
    "# Базовая логика: 0.35 порог (как в V22)\n",
    "final_preds = np.where(final_preds_float < 0.35, 0, final_preds_float)\n",
    "\n",
    "safe_condition = (lag_target_test == 0) & (~is_high_growth)\n",
    "final_preds[safe_condition] = np.where(final_preds[safe_condition] < 0.5, 0, final_preds[safe_condition])\n",
    "\n",
    "# Округляем\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v32_multi_depth.csv', index=False)\n",
    "print(\"Файл submission_v32_multi_depth.csv готов.\")\n",
    "print(\"Изменения: Разные глубины деревьев + Умное подавление шума для стабильных магазинов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEXRXCfptJSL",
    "outputId": "c12da7e0-e1b9-496d-9e26-cb6495f0db05"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков...\n",
      "Начинаем Multi-Depth Bagging (9 моделей)...\n",
      "Training Model 1 (Depth 4)...\n",
      "Training Model 2 (Depth 4)...\n",
      "Training Model 3 (Depth 4)...\n",
      "Training Model 4 (Depth 6)...\n",
      "Training Model 5 (Depth 6)...\n",
      "Training Model 6 (Depth 6)...\n",
      "Training Model 7 (Depth 8)...\n",
      "Training Model 8 (Depth 8)...\n",
      "Training Model 9 (Depth 8)...\n",
      "Файл submission_v32_multi_depth.csv готов.\n",
      "Изменения: Разные глубины деревьев + Умное подавление шума для стабильных магазинов.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "# Нам нужен только МАКСИМУМ за 4 недели. Это маркер проблемности магазина.\n",
    "target_history = train[['store_id', 'calendar_dt', 'target']].sort_values(['store_id', 'calendar_dt'])\n",
    "\n",
    "# Фейк для теста, чтобы сдвиг сработал\n",
    "test_stub = test[['store_id', 'calendar_dt']].copy()\n",
    "test_stub['target'] = np.nan\n",
    "full_history = pd.concat([target_history, test_stub], ignore_index=True).sort_values(['store_id', 'calendar_dt'])\n",
    "\n",
    "# Считаем\n",
    "full_history['lag_1'] = full_history.groupby('store_id')['target'].shift(1)\n",
    "full_history['lag_2'] = full_history.groupby('store_id')['target'].shift(2)\n",
    "full_history['lag_3'] = full_history.groupby('store_id')['target'].shift(3)\n",
    "full_history['lag_4'] = full_history.groupby('store_id')['target'].shift(4)\n",
    "\n",
    "full_history['rolling_max_4w'] = full_history[['lag_1', 'lag_2', 'lag_3', 'lag_4']].max(axis=1).fillna(0)\n",
    "\n",
    "# Оставляем только нужную фичу и lag_1 (он у нас основной)\n",
    "hist_feats = full_history[['store_id', 'calendar_dt', 'lag_1', 'rolling_max_4w']]\n",
    "hist_feats = hist_feats.rename(columns={'lag_1': 'lag_target_1'}) # переименуем для совместимости\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_hist):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_hist, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # Заполнение\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "    df['rolling_max_4w'] = df['rolling_max_4w'].fillna(0)\n",
    "\n",
    "    # Стандартный пакет\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Тренд к прошлой неделе\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    # Маркер роста заказов\n",
    "    df['orders_growth_heavy'] = (df['predicted_num_orders'] / (df['fact_num_orders_lag_1'] + 1)) > 1.10\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация V33...\")\n",
    "X_full = feature_engineering(train, facts, shifts, hist_feats)\n",
    "X_test_final = feature_engineering(test, facts, shifts, hist_feats)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "# Добавляем Depth 10\n",
    "models_config = [\n",
    "    # Легкие (видят тренды)\n",
    "    {'depth': 4, 'iter': 1500, 'lr': 0.04, 'seed': 42},\n",
    "    {'depth': 4, 'iter': 1500, 'lr': 0.04, 'seed': 2024},\n",
    "    {'depth': 4, 'iter': 1500, 'lr': 0.04, 'seed': 777},\n",
    "\n",
    "    # Средние (баланс)\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 42},\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 2024},\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 777},\n",
    "\n",
    "    # Глубокие (видят детали)\n",
    "    {'depth': 8, 'iter': 1000, 'lr': 0.02, 'seed': 42},\n",
    "    {'depth': 8, 'iter': 1000, 'lr': 0.02, 'seed': 2024},\n",
    "\n",
    "    # ОЧЕНЬ Глубокие (видят сложные связи, например rolling_max + день недели)\n",
    "    {'depth': 10, 'iter': 900, 'lr': 0.02, 'seed': 42},\n",
    "    {'depth': 10, 'iter': 900, 'lr': 0.02, 'seed': 100},\n",
    "    {'depth': 10, 'iter': 900, 'lr': 0.02, 'seed': 999},\n",
    "]\n",
    "\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Запускаем Heavy Bagging ({len(models_config)} моделей)...\")\n",
    "\n",
    "for i, conf in enumerate(models_config):\n",
    "    print(f\"Training Model {i+1}/{len(models_config)} (Depth {conf['depth']})...\")\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=conf['iter'],\n",
    "        depth=conf['depth'],\n",
    "        learning_rate=conf['lr'],\n",
    "        loss_function='MAE',\n",
    "        verbose=0,\n",
    "        random_seed=conf['seed'],\n",
    "        cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(models_config)\n",
    "\n",
    "# Обновленная логика:\n",
    "# Если за месяц проблем НЕ БЫЛО (rolling_max_4w == 0), доверяем магазину, ставим 0, если нет дикого роста.\n",
    "\n",
    "lag_max_test = X_test_final['rolling_max_4w'].values # Максимум за 4 недели\n",
    "is_high_growth = X_test_final['orders_growth_heavy'].values\n",
    "\n",
    "# Сначала отсекаем явный мусор (<0.35)\n",
    "final_preds = np.where(final_preds_float < 0.35, 0, final_preds_float)\n",
    "\n",
    "# Если за месяц ни одной проблемы И нет роста заказов, режем всё, что меньше 0.6\n",
    "perfect_store_mask = (lag_max_test == 0) & (~is_high_growth)\n",
    "final_preds[perfect_store_mask] = np.where(final_preds[perfect_store_mask] < 0.6, 0, final_preds[perfect_store_mask])\n",
    "\n",
    "# Округление и Clip\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v33_heavy_depth.csv', index=False)\n",
    "print(\"Файл submission_v33_heavy_depth.csv готов.\")\n",
    "print(\"Фичи: +Rolling Max 4w. Модели: Depth 4/6/8/10. Logic: Perfect Store Filter.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xzMYt7bwu9vg",
    "outputId": "27980cc7-265b-4f98-aae1-e5b0cc54b32f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация V33...\n",
      "Запускаем Heavy Bagging (11 моделей)...\n",
      "Training Model 1/11 (Depth 4)...\n",
      "Training Model 2/11 (Depth 4)...\n",
      "Training Model 3/11 (Depth 4)...\n",
      "Training Model 4/11 (Depth 6)...\n",
      "Training Model 5/11 (Depth 6)...\n",
      "Training Model 6/11 (Depth 6)...\n",
      "Training Model 7/11 (Depth 8)...\n",
      "Training Model 8/11 (Depth 8)...\n",
      "Training Model 9/11 (Depth 10)...\n",
      "Training Model 10/11 (Depth 10)...\n",
      "Training Model 11/11 (Depth 10)...\n",
      "Файл submission_v33_heavy_depth.csv готов.\n",
      "Фичи: +Rolling Max 4w. Модели: Depth 4/6/8/10. Logic: Perfect Store Filter.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "v32 = pd.read_csv('submission_v32_multi_depth.csv')\n",
    "v33 = pd.read_csv('submission_v33_heavy_depth.csv')\n",
    "\n",
    "print(\"--- Сравнение V32 (Good) vs V33 (Bad) ---\")\n",
    "print(f\"Mean V32: {v32['target'].mean():.4f}\")\n",
    "print(f\"Mean V33: {v33['target'].mean():.4f}\")\n",
    "print(f\"Sum  V32: {v32['target'].sum()}\")\n",
    "print(f\"Sum  V33: {v33['target'].sum()}\")\n",
    "\n",
    "# Если Sum V33 < Sum V32, значит V33 слишком сильно занизила прогноз\n",
    "if v33['target'].sum() < v32['target'].sum():\n",
    "    print(\"ДИАГНОЗ: V33 занизила прогнозы (переборщили с фильтрацией 'Perfect Store').\")\n",
    "    print(\"В высокий сезон (ноябрь) нельзя слепо доверять спокойной истории октября.\")\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "# Золотая фича\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Фичи из V32\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "    # Рост заказов\n",
    "    df['orders_growth_heavy'] = (df['predicted_num_orders'] / (df['fact_num_orders_lag_1'] + 1)) > 1.10\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"\\nГенерация признаков (V32 Architecture)...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "seeds = [42, 2024, 777, 555, 8800, 100, 999]\n",
    "depths = [4, 6, 8]\n",
    "\n",
    "# Конфигурация моделей\n",
    "models_config = []\n",
    "for d in depths:\n",
    "    # Подстраиваем итерации и LR под глубину\n",
    "    if d == 4: iter_n, lr = 1600, 0.04\n",
    "    if d == 6: iter_n, lr = 1300, 0.03\n",
    "    if d == 8: iter_n, lr = 1100, 0.02\n",
    "\n",
    "    for s in seeds:\n",
    "        models_config.append({'depth': d, 'iter': iter_n, 'lr': lr, 'seed': s})\n",
    "\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Запускаем Massive Bagging ({len(models_config)} моделей)...\")\n",
    "\n",
    "for i, conf in enumerate(models_config):\n",
    "    # Вывод прогресса пачками\n",
    "    if i % 3 == 0:\n",
    "        print(f\"Training Batch {i//3 + 1}/7 (Depth {conf['depth']})...\")\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=conf['iter'],\n",
    "        depth=conf['depth'],\n",
    "        learning_rate=conf['lr'],\n",
    "        loss_function='MAE',\n",
    "        verbose=0,\n",
    "        random_seed=conf['seed'],\n",
    "        cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(models_config)\n",
    "\n",
    "lag_target_test = X_test_final['lag_target_1'].values\n",
    "is_high_growth = X_test_final['orders_growth_heavy'].values\n",
    "\n",
    "# Базовый порог\n",
    "final_preds = np.where(final_preds_float < 0.35, 0, final_preds_float)\n",
    "\n",
    "# Если на прошлой неделе было 0 и нет резкого роста, повышаем порог уверенности до 0.5\n",
    "safe_condition = (lag_target_test == 0) & (~is_high_growth)\n",
    "final_preds[safe_condition] = np.where(final_preds[safe_condition] < 0.5, 0, final_preds[safe_condition])\n",
    "\n",
    "# Округление\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v34_massive_bagging.csv', index=False)\n",
    "print(\"\\nФайл submission_v34_massive_bagging.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N95QmPlzwwcf",
    "outputId": "42a196f0-1857-4920-cc44-38ed591e6c68"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Сравнение V32 (Good) vs V33 (Bad) ---\n",
      "Mean V32: 2.3897\n",
      "Mean V33: 2.4028\n",
      "Sum  V32: 5826.0\n",
      "Sum  V33: 5858.0\n",
      "\n",
      "Генерация признаков (V32 Architecture)...\n",
      "Запускаем Massive Bagging (21 моделей)...\n",
      "Training Batch 1/7 (Depth 4)...\n",
      "Training Batch 2/7 (Depth 4)...\n",
      "Training Batch 3/7 (Depth 4)...\n",
      "Training Batch 4/7 (Depth 6)...\n",
      "Training Batch 5/7 (Depth 6)...\n",
      "Training Batch 6/7 (Depth 8)...\n",
      "Training Batch 7/7 (Depth 8)...\n",
      "\n",
      "Файл submission_v34_massive_bagging.csv готов.\n",
      "Это усиленная версия V32 (больше моделей, та же логика). Должна быть стабильнее.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "\n",
    "# Даты\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "\n",
    "# Делаем Лаг таргета на 1 неделю назад\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # FillNA\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Если факт > прогноза, значит нагрузка была выше ожидаемой, риск дефицита растет\n",
    "    df['orders_error_lag1'] = df['fact_num_orders_lag_1'] - (df['predicted_num_orders'] / 1.05) # условно считаем, что прогноз на текущую ~ прогнозу на прошлую\n",
    "\n",
    "    # Насколько мы просели по курьерам?\n",
    "    # (Сколько хотели - сколько вышло)\n",
    "    df['staff_shortage_lag1'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "\n",
    "    # Эффективность (Заказов на 1 курьера)\n",
    "    df['efficiency_fact'] = df['fact_num_orders_lag_1'] / (df['fact_couriers_with_shifts_lag_1'] + 1)\n",
    "\n",
    "    # Стандартные фичи\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "# Собираем полный датасет\n",
    "full_df = feature_engineering(train, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in full_df.columns: cat_features = ['store_id']\n",
    "full_df[cat_features] = full_df[cat_features].fillna('missing')\n",
    "\n",
    "VAL_DATE = pd.to_datetime('2025-11-17')\n",
    "\n",
    "# Все что строго до валидационной даты\n",
    "train_df = full_df[full_df['calendar_dt'] < VAL_DATE].copy()\n",
    "# Ровно одна дата (как в тесте)\n",
    "valid_df = full_df[full_df['calendar_dt'] == VAL_DATE].copy()\n",
    "\n",
    "X_train = train_df.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train = train_df['target']\n",
    "\n",
    "X_val = valid_df.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_val = valid_df['target']\n",
    "\n",
    "print(f\"Train size: {len(X_train)}, Valid size: {len(X_val)}\")\n",
    "\n",
    "params = {\n",
    "    'iterations': 1500,\n",
    "    'depth': 5,\n",
    "    'learning_rate': 0.03,\n",
    "    'loss_function': 'MAE', # Для WAPE лучше MAE\n",
    "    'cat_features': cat_features,\n",
    "    'random_seed': 42,\n",
    "    'verbose': 200,\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "\n",
    "model = CatBoostRegressor(**params)\n",
    "model.fit(X_train, y_train, eval_set=(X_val, y_val), early_stopping_rounds=200)\n",
    "\n",
    "preds_raw = model.predict(X_val)\n",
    "\n",
    "# ПОИСК ИДЕАЛЬНОГО ПОРОГА\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
    "\n",
    "best_wape = 1.0\n",
    "best_th = 0.0\n",
    "best_preds = []\n",
    "\n",
    "# Перебираем пороги от 0.20 до 0.65\n",
    "print(\"\\n--- Tuning Threshold ---\")\n",
    "thresholds = np.arange(0.20, 0.66, 0.01)\n",
    "\n",
    "for th in thresholds:\n",
    "    # Базовая логика: все что < th ставим в 0\n",
    "    p = np.where(preds_raw < th, 0, preds_raw)\n",
    "\n",
    "    # Округляем остальное\n",
    "    p = np.round(p)\n",
    "\n",
    "    current_wape = wape(y_val, p)\n",
    "    if current_wape < best_wape:\n",
    "        best_wape = current_wape\n",
    "        best_th = th\n",
    "        best_preds = p\n",
    "\n",
    "print(f\"\\nWINNER THRESHOLD: {best_th:.2f}\")\n",
    "print(f\"Best Validation WAPE: {best_wape:.5f}\")\n",
    "\n",
    "valid_df['pred'] = best_preds\n",
    "valid_df['raw'] = preds_raw\n",
    "valid_df['diff'] = valid_df['target'] - valid_df['pred']\n",
    "\n",
    "print(\"\\nТОП Ошибок:\")\n",
    "print(valid_df[valid_df['diff'] != 0][['store_id', 'target', 'pred', 'raw', 'lag_target_1']].head(10))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uXN8mX7zTT7A",
    "outputId": "6de4f652-2988-4aee-8f8c-8b0bff863406"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train size: 5781, Valid size: 2439\n",
      "0:\tlearn: 1.9017996\ttest: 1.9566082\tbest: 1.9566082 (0)\ttotal: 24.8ms\tremaining: 37.2s\n",
      "200:\tlearn: 0.4314041\ttest: 0.4758849\tbest: 0.4758849 (200)\ttotal: 2.57s\tremaining: 16.6s\n",
      "400:\tlearn: 0.4003133\ttest: 0.4516380\tbest: 0.4516380 (400)\ttotal: 5.71s\tremaining: 15.6s\n",
      "600:\tlearn: 0.3815908\ttest: 0.4460912\tbest: 0.4454547 (536)\ttotal: 9.69s\tremaining: 14.5s\n",
      "800:\tlearn: 0.3767554\ttest: 0.4460864\tbest: 0.4451999 (749)\ttotal: 13.2s\tremaining: 11.6s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.4451998992\n",
      "bestIteration = 749\n",
      "\n",
      "Shrink model to first 750 iterations.\n",
      "\n",
      "--- Tuning Threshold ---\n",
      "\n",
      "WINNER THRESHOLD: 0.20\n",
      "Best Validation WAPE: 0.16709\n",
      "\n",
      "ТОП Ошибок (Где мы облажались?):\n",
      "                                store_id  target  pred       raw  lag_target_1\n",
      "11  00442959-9671-11ec-ae6d-08c0eb320147     7.0   6.0  6.261909           5.0\n",
      "17  00872c4d-b7c8-11eb-85ab-1c34dae33151     2.0   1.0  1.358516           6.0\n",
      "26  00f43499-3c96-11f0-9bb2-be3af2b6059f     2.0   1.0  1.210141           3.0\n",
      "29  012f4970-7b40-11ef-ae7a-08c0eb320147     5.0   4.0  4.030298           3.0\n",
      "35  018c0434-f787-11ec-8859-08c0eb32014b     4.0   5.0  4.618146           7.0\n",
      "38  01b61453-a759-11ef-8861-08c0eb32014b     7.0   6.0  5.746894           3.0\n",
      "41  01bb6fcc-259c-11f0-9bb2-be3af2b6059f     2.0   1.0  1.030217           2.0\n",
      "44  01ca88ce-d4a2-11ee-b973-08c0eb32008b     3.0   2.0  2.002182           1.0\n",
      "47  01eca359-58f5-11ec-a0ee-ec0d9a21b021     6.0   4.0  4.467035           4.0\n",
      "50  02074606-902a-11ee-ae7a-08c0eb320147     5.0   3.0  3.186426           7.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "# Приводим даты\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Ошибка прогноза заказов на прошлой неделе\n",
    "    # Если факт > прогноза, значит магазину тяжело, дефицит вероятен\n",
    "    df['orders_error_lag1'] = df['fact_num_orders_lag_1'] - (df['predicted_num_orders'] / 1.05)\n",
    "\n",
    "    # 2. Дефицит штата (хотели - вышло)\n",
    "    df['staff_shortage_lag1'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "\n",
    "    # Реальная эффективность (заказов на курьера)\n",
    "    df['efficiency_fact'] = df['fact_num_orders_lag_1'] / (df['fact_couriers_with_shifts_lag_1'] + 1)\n",
    "\n",
    "    # Тренды\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Generating Features based on Best Validation...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "seeds = [42, 2024, 777, 555, 100]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Training 5 Models...\")\n",
    "\n",
    "for seed in seeds:\n",
    "    params = {\n",
    "        'iterations': 1600,\n",
    "        'depth': 5,            # Глубина 5 показала себя лучше всего\n",
    "        'learning_rate': 0.035,\n",
    "        'loss_function': 'MAE',\n",
    "        'verbose': 0,\n",
    "        'random_seed': seed,\n",
    "        'cat_features': cat_features,\n",
    "        'allow_writing_files': False\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(seeds)\n",
    "\n",
    "print(\"Applying Aggressive Shift Strategy...\")\n",
    "\n",
    "# Валидация сказала 0.20, берем 0.22 для безопасности.\n",
    "# (Раньше мы резали < 0.35, и зря!)\n",
    "mask_low = final_preds_float < 0.22\n",
    "final_preds_float[mask_low] = 0\n",
    "\n",
    "# Мы видели, что модель предсказывает 3.18, когда надо 5.\n",
    "# Умножаем на 1.05, чтобы подтянуть неуверенные прогнозы вверх\n",
    "final_preds_boosted = final_preds_float * 1.05\n",
    "\n",
    "# Округление\n",
    "final_preds = np.round(final_preds_boosted)\n",
    "\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "# Статистика изменений\n",
    "n_boosted = np.sum(np.round(final_preds_float) != final_preds)\n",
    "print(f\"Boost logic changed {n_boosted} predictions (pushed them up).\")\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v35_aggressive_boost.csv', index=False)\n",
    "print(\"Файл submission_v35_aggressive_boost.csv готов.\")\n",
    "print(\"Изменения: Threshold 0.22 + Multiplier 1.05 + New Error Features.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kNgNvvLTvC9",
    "outputId": "05cf3ebc-6834-4fd4-ba0e-1667fdffb380"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating Features based on Best Validation...\n",
      "Training 5 Models...\n",
      "Applying Aggressive Shift Strategy...\n",
      "Boost logic changed 169 predictions (pushed them up).\n",
      "Файл submission_v35_aggressive_boost.csv готов.\n",
      "Изменения: Threshold 0.22 + Multiplier 1.05 + New Error Features.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "# Лаг таргета\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Фичи, которые доказали эффективность в V32\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Тренд\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    # Рост заказов (для фильтрации)\n",
    "    df['orders_growth_heavy'] = (df['predicted_num_orders'] / (df['fact_num_orders_lag_1'] + 1)) > 1.10\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Generating Features (V32 Set)...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "# Мы используем ту же схему Multi-Depth, что в V32, но меняем loss_function\n",
    "# Poisson лучше подходит для счетных данных (0, 1, 2...), чем MAE.\n",
    "models_config = [\n",
    "    # Depth 4\n",
    "    {'depth': 4, 'iter': 1600, 'lr': 0.04, 'seed': 42},\n",
    "    {'depth': 4, 'iter': 1600, 'lr': 0.04, 'seed': 2024},\n",
    "    # Depth 5 (Золотая середина)\n",
    "    {'depth': 5, 'iter': 1400, 'lr': 0.035, 'seed': 42},\n",
    "    {'depth': 5, 'iter': 1400, 'lr': 0.035, 'seed': 777},\n",
    "    # Depth 6\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 42},\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 555},\n",
    "]\n",
    "\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Training Poisson Models ({len(models_config)})...\")\n",
    "\n",
    "for i, conf in enumerate(models_config):\n",
    "    print(f\"Model {i+1} (Depth {conf['depth']})...\")\n",
    "\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=conf['iter'],\n",
    "        depth=conf['depth'],\n",
    "        learning_rate=conf['lr'],\n",
    "        loss_function='Poisson',\n",
    "        verbose=0,\n",
    "        random_seed=conf['seed'],\n",
    "        cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "\n",
    "    # Poisson в CatBoost предсказывает exponent(log_lambda), то есть сразу значение.\n",
    "    # Дополнительных преобразований не нужно.\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(models_config)\n",
    "\n",
    "# Мы убираем агрессию V35 и возвращаемся к логике, которая дала 0.178.\n",
    "# Но так как Poisson лучше работает около нуля, мы можем довериться стандартному округлению больше.\n",
    "\n",
    "lag_target_test = X_test_final['lag_target_1'].values\n",
    "is_high_growth = X_test_final['orders_growth_heavy'].values\n",
    "\n",
    "# Базовое правило\n",
    "final_preds = final_preds_float.copy()\n",
    "\n",
    "# Smart Zeroing (как в V32)\n",
    "# Если на прошлой неделе было 0 И нет роста, требуем уверенности > 0.5\n",
    "safe_condition = (lag_target_test == 0) & (~is_high_growth)\n",
    "mask_uncertain = (final_preds < 0.5) & safe_condition\n",
    "final_preds[mask_uncertain] = 0\n",
    "\n",
    "# Для остальных - стандартный порог шума.\n",
    "# Так как V35 (0.22) провалилась, вернемся к 0.35 (V32)\n",
    "final_preds[final_preds < 0.35] = 0\n",
    "\n",
    "# Округление\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v36_poisson.csv', index=False)\n",
    "print(\"Файл submission_v36_poisson.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0vOl4WNOVCj7",
    "outputId": "d8543350-b4a9-41c9-dd81-ecd37c18cd63"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating Features (V32 Set)...\n",
      "Training Poisson Models (6)...\n",
      "Model 1 (Depth 4)...\n",
      "Model 2 (Depth 4)...\n",
      "Model 3 (Depth 5)...\n",
      "Model 4 (Depth 5)...\n",
      "Model 5 (Depth 6)...\n",
      "Model 6 (Depth 6)...\n",
      "Файл submission_v36_poisson.csv готов.\n",
      "Strategy: Back to V32 logic + Poisson Loss function.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Фичи из V32\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Generating Features...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "# Данные\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_reg = X_full['target']\n",
    "# Создаем бинарный таргет для классификатора (0 - нет дефицита, 1 - есть)\n",
    "y_train_clf = (X_full['target'] > 0).astype(int)\n",
    "\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "print(\"\\n--- Stage 1: Classifier Training ---\")\n",
    "clf_model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    depth=5,\n",
    "    learning_rate=0.03,\n",
    "    loss_function='Logloss', # Оптимизируем вероятность\n",
    "    verbose=200,\n",
    "    random_seed=42,\n",
    "    cat_features=cat_features,\n",
    "    auto_class_weights='Balanced', # Классы могут быть несбалансированы\n",
    "    allow_writing_files=False\n",
    ")\n",
    "clf_model.fit(X_train_full, y_train_clf)\n",
    "\n",
    "# Предсказываем вероятность дефицита\n",
    "probs_test = clf_model.predict_proba(X_test_ready)[:, 1]\n",
    "\n",
    "print(\"\\n--- Stage 2: Regressor Training (V32 Config) ---\")\n",
    "# Используем усреднение 3-х лучших конфигураций из V32\n",
    "reg_configs = [\n",
    "    {'depth': 4, 'iter': 1500, 'lr': 0.04, 'seed': 42},\n",
    "    {'depth': 6, 'iter': 1200, 'lr': 0.03, 'seed': 2024},\n",
    "    {'depth': 8, 'iter': 1000, 'lr': 0.02, 'seed': 777},\n",
    "]\n",
    "\n",
    "reg_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "for i, conf in enumerate(reg_configs):\n",
    "    print(f\"Regressor {i+1}...\")\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=conf['iter'],\n",
    "        depth=conf['depth'],\n",
    "        learning_rate=conf['lr'],\n",
    "        loss_function='MAE',\n",
    "        verbose=0,\n",
    "        random_seed=conf['seed'],\n",
    "        cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_reg)\n",
    "    reg_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "reg_preds_raw = reg_preds_accum / len(reg_configs)\n",
    "\n",
    "print(\"\\nApplying Hybrid Logic...\")\n",
    "\n",
    "final_preds = reg_preds_raw.copy()\n",
    "\n",
    "# Логика V37:\n",
    "# 1. Если Классификатор уверен, что дефицита НЕТ (вероятность < 0.45), ставим 0.\n",
    "# 2. Иначе оставляем прогноз Регрессора.\n",
    "\n",
    "threshold_prob = 0.45 # Если вероятность дефицита меньше 45%, считаем что его нет.\n",
    "\n",
    "# Фильтруем\n",
    "mask_zeros = probs_test < threshold_prob\n",
    "final_preds[mask_zeros] = 0\n",
    "\n",
    "# Стандартная очистка шума для оставшихся\n",
    "final_preds[final_preds < 0.35] = 0\n",
    "\n",
    "# Округление\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "# Аналитика\n",
    "n_zeros_clf = np.sum(mask_zeros)\n",
    "print(f\"Classifier forced {n_zeros_clf} stores to Zero (out of {len(final_preds)}).\")\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v37_two_stage.csv', index=False)\n",
    "print(\"Файл submission_v37_two_stage.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d53U9kIfWHuw",
    "outputId": "44f56037-4b54-4fa7-8b7e-e1e7b4423a76"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating Features...\n",
      "\n",
      "--- Stage 1: Classifier Training ---\n",
      "0:\tlearn: 0.5866030\ttotal: 24.5ms\tremaining: 24.5s\n",
      "200:\tlearn: 0.0002650\ttotal: 3.31s\tremaining: 13.1s\n",
      "400:\tlearn: 0.0002646\ttotal: 6.05s\tremaining: 9.04s\n",
      "600:\tlearn: 0.0002643\ttotal: 8.7s\tremaining: 5.78s\n",
      "800:\tlearn: 0.0002643\ttotal: 12.1s\tremaining: 3s\n",
      "999:\tlearn: 0.0002643\ttotal: 14.1s\tremaining: 0us\n",
      "\n",
      "--- Stage 2: Regressor Training (V32 Config) ---\n",
      "Regressor 1...\n",
      "Regressor 2...\n",
      "Regressor 3...\n",
      "\n",
      "Applying Hybrid Logic...\n",
      "Classifier forced 724 stores to Zero (out of 2438).\n",
      "Файл submission_v37_two_stage.csv готов.\n",
      "Logic: Classifier (Prob < 0.45 -> 0) + V32 Regressor.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    # Плановая нагрузка на будущую неделю\n",
    "    plan_eff = df['predicted_num_orders'] / (df['predicted_staff_value'] + 0.1)\n",
    "    fact_eff = df['fact_num_orders_lag_1'] / (df['fact_couriers_with_shifts_lag_1'] + 0.1)\n",
    "\n",
    "    # Если Plan > Fact, значит курьерам придется бегать быстрее, риск дефицита выше\n",
    "    df['efficiency_gap'] = plan_eff - fact_eff\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Generating Features (V32 + Efficiency Gap)...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "models_config = [\n",
    "    # Small Depth\n",
    "    {'depth': 4, 'iter': 1600, 'lr': 0.035, 'seed': 42},\n",
    "    {'depth': 4, 'iter': 1600, 'lr': 0.035, 'seed': 2024},\n",
    "    # Medium Depth\n",
    "    {'depth': 6, 'iter': 1300, 'lr': 0.03, 'seed': 42},\n",
    "    {'depth': 6, 'iter': 1300, 'lr': 0.03, 'seed': 777},\n",
    "    # Large Depth\n",
    "    {'depth': 8, 'iter': 1100, 'lr': 0.02, 'seed': 42},\n",
    "    {'depth': 8, 'iter': 1100, 'lr': 0.02, 'seed': 555},\n",
    "]\n",
    "\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Training Refined V32 Models ({len(models_config)} models)...\")\n",
    "\n",
    "for i, conf in enumerate(models_config):\n",
    "    # print(f\"Model {i+1}...\")\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=conf['iter'],\n",
    "        depth=conf['depth'],\n",
    "        learning_rate=conf['lr'],\n",
    "        loss_function='MAE',\n",
    "        verbose=0,\n",
    "        random_seed=conf['seed'],\n",
    "        cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(models_config)\n",
    "\n",
    "lag_target_test = X_test_final['lag_target_1'].values\n",
    "# Убираем orders_growth_heavy, так как он был в неудачных версиях. Опираемся только на лаг.\n",
    "\n",
    "final_preds = final_preds_float.copy()\n",
    "\n",
    "# Safe Zone\n",
    "# (Было 0.5, повышаем до 0.55 - сложнее получить 1)\n",
    "mask_safe = (lag_target_test == 0)\n",
    "final_preds[mask_safe] = np.where(final_preds[mask_safe] < 0.55, 0, final_preds[mask_safe])\n",
    "\n",
    "# General Zone\n",
    "# (Было 0.35, повышаем до 0.38)\n",
    "final_preds[~mask_safe] = np.where(final_preds[~mask_safe] < 0.38, 0, final_preds[~mask_safe])\n",
    "\n",
    "# Округление\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v38_efficiency_tuned.csv', index=False)\n",
    "print(\"Файл submission_v38_efficiency_tuned.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPgHsw4BZYKP",
    "outputId": "4da3b76e-d8f4-4e7b-8e24-36cb357abd6e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating Features (V32 + Efficiency Gap)...\n",
      "Training Refined V32 Models (6 models)...\n",
      "Файл submission_v38_efficiency_tuned.csv готов.\n",
      "Changes: Added 'efficiency_gap'. Tighter thresholds (0.35->0.38, 0.5->0.55).\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "# Лаг\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # V32 Base\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    # Возвращаем эту фичу, она нужна для пост-процессинга!\n",
    "    df['orders_growth_heavy'] = (df['predicted_num_orders'] / (df['fact_num_orders_lag_1'] + 1)) > 1.10\n",
    "\n",
    "    # Отношение: Сколько нам НАДО курьеров (прогноз) / Сколько у нас ВСЕГО трудоустроено (факт лаг)\n",
    "    df['capacity_pressure'] = df['predicted_staff_value'] / (df['fact_staff_value_lag_1'] + 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Generating Features (Fixed)...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "max_date = X_full['calendar_dt'].max()\n",
    "X_full['days_from_end'] = (max_date - X_full['calendar_dt']).dt.days\n",
    "\n",
    "# Веса: свежие данные важнее\n",
    "decay_rate = 0.003\n",
    "X_full['sample_weight'] = np.exp(-decay_rate * X_full['days_from_end'])\n",
    "\n",
    "print(f\"Weights stats: Min={X_full['sample_weight'].min():.3f}, Max={X_full['sample_weight'].max():.3f}\")\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt', 'days_from_end', 'sample_weight'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "train_weights = X_full['sample_weight']\n",
    "\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt', 'days_from_end', 'sample_weight'], axis=1, errors='ignore')\n",
    "\n",
    "models_config = [\n",
    "    {'depth': 4, 'iter': 1600, 'lr': 0.035, 'seed': 42},\n",
    "    {'depth': 4, 'iter': 1600, 'lr': 0.035, 'seed': 2024},\n",
    "\n",
    "    {'depth': 6, 'iter': 1300, 'lr': 0.03, 'seed': 42},\n",
    "    {'depth': 6, 'iter': 1300, 'lr': 0.03, 'seed': 777},\n",
    "\n",
    "    {'depth': 8, 'iter': 1100, 'lr': 0.02, 'seed': 42},\n",
    "    {'depth': 8, 'iter': 1100, 'lr': 0.02, 'seed': 555},\n",
    "]\n",
    "\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "print(f\"Training Weighted Models ({len(models_config)})...\")\n",
    "\n",
    "for i, conf in enumerate(models_config):\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=conf['iter'],\n",
    "        depth=conf['depth'],\n",
    "        learning_rate=conf['lr'],\n",
    "        loss_function='MAE',\n",
    "        verbose=0,\n",
    "        random_seed=conf['seed'],\n",
    "        cat_features=cat_features,\n",
    "        allow_writing_files=False\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_full, y_train_full, sample_weight=train_weights)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(models_config)\n",
    "\n",
    "lag_target_test = X_test_final['lag_target_1'].values\n",
    "is_high_growth = X_test_final['orders_growth_heavy'].values\n",
    "\n",
    "final_preds = final_preds_float.copy()\n",
    "\n",
    "# Smart Zeroing (V32)\n",
    "safe_condition = (lag_target_test == 0) & (~is_high_growth)\n",
    "final_preds[safe_condition] = np.where(final_preds[safe_condition] < 0.5, 0, final_preds[safe_condition])\n",
    "\n",
    "# Default Threshold\n",
    "final_preds[~safe_condition] = np.where(final_preds[~safe_condition] < 0.35, 0, final_preds[~safe_condition])\n",
    "\n",
    "# Round & Clip\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v39_temporal_weights.csv', index=False)\n",
    "print(\"Файл submission_v39_temporal_weights.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sk8kYBO-apNF",
    "outputId": "735179e2-9de6-4c96-95fe-e2907dce4941"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generating Features (Fixed)...\n",
      "Weights stats: Min=0.128, Max=1.000\n",
      "Training Weighted Models (6)...\n",
      "Файл submission_v39_temporal_weights.csv готов.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"--- Загрузка данных ---\")\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "# Приведение дат\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    # Заполнение пропусков в лагах\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Базовые метрики\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "\n",
    "    # Защита от деления на 0\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "\n",
    "    # Календарь\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Тренд\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    df['orders_growth_heavy'] = (df['predicted_num_orders'] / (df['fact_num_orders_lag_1'] + 1)) > 1.10\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "# Обработка категорий\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "# Подготовка матриц\n",
    "X_train = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_raw = X_full['target']\n",
    "X_test = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "print(\"\\n--- Синхронизация признаков (Train vs Test) ---\")\n",
    "train_cols = set(X_train.columns)\n",
    "test_cols = set(X_test.columns)\n",
    "\n",
    "# Оставляем только те колонки, которые есть в обоих датасетах\n",
    "common_cols = list(train_cols.intersection(test_cols))\n",
    "print(f\"Колонок до фикса: Train = {len(train_cols)}, Test={len(test_cols)}\")\n",
    "print(f\"Потерянные колонки (были в train, нет в test): {train_cols - test_cols}\")\n",
    "\n",
    "X_train = X_train[common_cols]\n",
    "X_test = X_test[common_cols]\n",
    "\n",
    "# Обновляем список cat_features\n",
    "actual_cat_features = [c for c in cat_features if c in X_train.columns]\n",
    "print(f\"Итого колонок для обучения: {len(X_train.columns)}\")\n",
    "\n",
    "y_train_class = (y_train_raw > 0).astype(int)\n",
    "\n",
    "print(\"\\nTraining Stage 1: Classifier\")\n",
    "class_seeds = [42, 2024, 777]\n",
    "class_preds_accum = np.zeros(len(X_test))\n",
    "\n",
    "class_params = {\n",
    "    'iterations': 900,         # Чуть больше итераций\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.05,\n",
    "    'loss_function': 'Logloss',\n",
    "    'eval_metric': 'AUC',\n",
    "    'cat_features': actual_cat_features,\n",
    "    'verbose': 0,              # Тихий режим\n",
    "    'allow_writing_files': False,\n",
    "    'auto_class_weights': 'Balanced' # Компенсируем дисбаланс нулей\n",
    "}\n",
    "\n",
    "for i, seed in enumerate(class_seeds):\n",
    "    print(f\"Clf Seed {seed}...\")\n",
    "    model_clf = CatBoostClassifier(**class_params, random_seed=seed)\n",
    "    model_clf.fit(X_train, y_train_class)\n",
    "    class_preds_accum += model_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "final_prob = class_preds_accum / len(class_seeds)\n",
    "print(\"Classification done.\")\n",
    "\n",
    "print(\"\\n--- Training Stage 2: Weighted Regressor ---\")\n",
    "\n",
    "sample_weights = 1 + np.log1p(y_train_raw)\n",
    "\n",
    "reg_seeds = [42, 2024, 777, 555, 8800] # 5 надежных сидов\n",
    "reg_preds_accum = np.zeros(len(X_test))\n",
    "\n",
    "reg_params = {\n",
    "    'iterations': 1500,\n",
    "    'depth': 6,\n",
    "    'learning_rate': 0.03,\n",
    "    'loss_function': 'MAE',\n",
    "    'cat_features': actual_cat_features,\n",
    "    'verbose': 0,\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "\n",
    "# Используем Pool для передачи весов\n",
    "train_pool = Pool(X_train, y_train_raw, cat_features=actual_cat_features, weight=sample_weights)\n",
    "\n",
    "for i, seed in enumerate(reg_seeds):\n",
    "    print(f\"Reg Seed {seed}...\")\n",
    "    model_reg = CatBoostRegressor(**reg_params, random_seed=seed)\n",
    "    model_reg.fit(train_pool)\n",
    "    reg_preds_accum += model_reg.predict(X_test)\n",
    "\n",
    "final_reg_raw = reg_preds_accum / len(reg_seeds)\n",
    "print(\"Regression done.\")\n",
    "\n",
    "print(\"\\n--- Сборка финального решения ---\")\n",
    "\n",
    "# Пороги уверенности классификатора\n",
    "PROB_HIGH = 0.65  # Если вероятность > 65%, верим, что дефицит есть\n",
    "PROB_LOW = 0.25   # Если вероятность < 25%, рубим в ноль\n",
    "\n",
    "final_preds = np.zeros(len(X_test))\n",
    "counters = {'pure_zero': 0, 'smart_zero': 0, 'regressor': 0}\n",
    "\n",
    "# Достаем вспомогательные данные для Smart Zeroing (из V32)\n",
    "lag_target_test = X_test_final['lag_target_1'].values\n",
    "is_growth_test = X_test_final['orders_growth_heavy'].values\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    prob = final_prob[i]\n",
    "    reg_val = final_reg_raw[i]\n",
    "    lag_val = lag_target_test[i]\n",
    "    is_growth = is_growth_test[i]\n",
    "\n",
    "    # 1. Если классификатор уверен, что дефицита нет\n",
    "    if prob < PROB_LOW:\n",
    "        final_preds[i] = 0\n",
    "        counters['pure_zero'] += 1\n",
    "\n",
    "    # 2. Если классификатор уверен, что дефицит есть\n",
    "    elif prob > PROB_HIGH:\n",
    "        # Берем регрессор. Но если он вдруг дал совсем мало (<0.2),\n",
    "        # то округление все равно сделает 0.\n",
    "        final_preds[i] = reg_val\n",
    "        counters['regressor'] += 1\n",
    "\n",
    "    # 3. 25% - 65% - тут включаем логику V32\n",
    "    else:\n",
    "        # Базовое отсечение шума\n",
    "        if reg_val < 0.35:\n",
    "            final_preds[i] = 0\n",
    "            counters['pure_zero'] += 1\n",
    "        # Умное зануление\n",
    "        # Если раньше было 0 и нет роста, давим шум сильнее\n",
    "        elif (lag_val == 0) and (not is_growth):\n",
    "            if reg_val < 0.5:\n",
    "                final_preds[i] = 0\n",
    "                counters['smart_zero'] += 1\n",
    "            else:\n",
    "                final_preds[i] = reg_val\n",
    "                counters['regressor'] += 1\n",
    "        else:\n",
    "            final_preds[i] = reg_val\n",
    "            counters['regressor'] += 1\n",
    "\n",
    "# Финальная обработка\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "print(f\"Статистика решений: {counters}\")\n",
    "print(f\"Среднее предсказание: {final_preds.mean():.4f}\")\n",
    "print(f\"Сумма дефицита: {final_preds.sum()}\")\n",
    "\n",
    "# Сохранение\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v40_two_stage.csv', index=False)\n",
    "print(\"Файл submission_v40_two_stage.csv успешно сохранен!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qu2RBU_AeKBo",
    "outputId": "835d946b-8c31-445b-82bc-684896dad5ca"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--- Загрузка данных ---\n",
      "Генерация признаков...\n",
      "\n",
      "--- Синхронизация признаков (Train vs Test) ---\n",
      "Колонок до фикса: Train=23, Test=23\n",
      "Потерянные колонки (были в train, нет в test): set()\n",
      "Итого колонок для обучения: 23\n",
      "\n",
      "--- Training Stage 1: Classifier ---\n",
      "Clf Seed 42...\n",
      "Clf Seed 2024...\n",
      "Clf Seed 777...\n",
      "Classification done.\n",
      "\n",
      "--- Training Stage 2: Weighted Regressor ---\n",
      "Reg Seed 42...\n",
      "Reg Seed 2024...\n",
      "Reg Seed 777...\n",
      "Reg Seed 555...\n",
      "Reg Seed 8800...\n",
      "Regression done.\n",
      "\n",
      "--- Сборка финального решения ---\n",
      "Статистика решений: {'pure_zero': 724, 'smart_zero': 0, 'regressor': 1714}\n",
      "Среднее предсказание: 2.4176\n",
      "Сумма дефицита: 5894.0\n",
      "Файл submission_v40_two_stage.csv успешно сохранен!\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "# Даты\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "# Lag-1 Target\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # V32 Features\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    # Рост заказов (оставляем, пригодится)\n",
    "    df['orders_growth_heavy'] = (df['predicted_num_orders'] / (df['fact_num_orders_lag_1'] + 1)) > 1.10\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "cat_features = ['store_id', 'city_nm']\n",
    "if 'city_nm' not in X_full.columns: cat_features = ['store_id']\n",
    "X_full[cat_features] = X_full[cat_features].fillna('missing')\n",
    "X_test_final[cat_features] = X_test_final[cat_features].fillna('missing')\n",
    "\n",
    "print(\"\\n--- Calibration Stage: Searching for Optimal Thresholds ---\")\n",
    "\n",
    "# Отщепляем последние 3 доступные даты из train для валидации порогов\n",
    "dates = sorted(X_full['calendar_dt'].unique())\n",
    "val_dates = dates[-3:] # Последние 3 недели\n",
    "train_dates = dates[:-3] # Всё остальное\n",
    "\n",
    "print(f\"Train dates: {len(train_dates)} weeks. Val dates: {val_dates}\")\n",
    "\n",
    "# Сплит\n",
    "X_calib_train = X_full[X_full['calendar_dt'].isin(train_dates)].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_calib_train = X_full[X_full['calendar_dt'].isin(train_dates)]['target']\n",
    "\n",
    "X_calib_val = X_full[X_full['calendar_dt'].isin(val_dates)].drop(['target', 'calendar_dt'], axis=1)\n",
    "y_calib_val = X_full[X_full['calendar_dt'].isin(val_dates)]['target']\n",
    "\n",
    "# Обучаем быструю модель для калибровки\n",
    "# Используем параметры V32\n",
    "calib_model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    depth=6,\n",
    "    learning_rate=0.04,\n",
    "    loss_function='MAE',\n",
    "    random_seed=42,\n",
    "    cat_features=[c for c in cat_features if c in X_calib_train.columns],\n",
    "    verbose=0,\n",
    "    allow_writing_files=False\n",
    ")\n",
    "calib_model.fit(X_calib_train, y_calib_train)\n",
    "val_preds_raw = calib_model.predict(X_calib_val)\n",
    "\n",
    "# ФУНКЦИЯ ДЛЯ ПОДБОРА ПОРОГОВ\n",
    "def wape(y_true, y_pred):\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(y_true)\n",
    "\n",
    "best_wape = 1.0\n",
    "best_th_low = 0.5  # Граница 0 - 1\n",
    "best_th_high = 1.5 # Граница 1 - 2+\n",
    "\n",
    "thresholds = np.arange(0.25, 0.65, 0.01)\n",
    "\n",
    "print(\"Starting Grid Search...\")\n",
    "for th in thresholds:\n",
    "    current_preds = val_preds_raw.copy()\n",
    "    current_preds = np.where(current_preds < th, 0, current_preds)\n",
    "    current_preds = np.round(current_preds) # Округляем оставшееся\n",
    "\n",
    "    score = wape(y_calib_val, current_preds)\n",
    "\n",
    "    if score < best_wape:\n",
    "        best_wape = score\n",
    "        best_th_low = th\n",
    "\n",
    "print(f\"Optimal Zero Threshold found: {best_th_low:.3f} (Val WAPE: {best_wape:.5f})\")\n",
    "# Если порог получился около 0.35, значит V32 была права. Если 0.45 — значит мы нашли резерв\n",
    "print(\"\\n--- Final Training (Full Data) ---\")\n",
    "\n",
    "X_train_full = X_full.drop(['target', 'calendar_dt'], axis=1)\n",
    "y_train_full = X_full['target']\n",
    "X_test_ready = X_test_final.drop(['target', 'calendar_dt'], axis=1, errors='ignore')\n",
    "\n",
    "# Синхронизация колонок (на всякий случай, как в V40)\n",
    "common = list(set(X_train_full.columns).intersection(set(X_test_ready.columns)))\n",
    "X_train_full = X_train_full[common]\n",
    "X_test_ready = X_test_ready[common]\n",
    "actual_cats = [c for c in cat_features if c in common]\n",
    "\n",
    "# Bagging (Как в V32/34, но с найденным порогом)\n",
    "seeds = [42, 2024, 777, 555, 8800]\n",
    "test_preds_accum = np.zeros(len(X_test_ready))\n",
    "\n",
    "params = {\n",
    "    'iterations': 1400,\n",
    "    'depth': 6, # Золотая середина\n",
    "    'learning_rate': 0.035,\n",
    "    'loss_function': 'MAE',\n",
    "    'cat_features': actual_cats,\n",
    "    'verbose': 0,\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"Training Seed {seed}...\")\n",
    "    model = CatBoostRegressor(**params, random_seed=seed)\n",
    "    model.fit(X_train_full, y_train_full)\n",
    "    test_preds_accum += model.predict(X_test_ready)\n",
    "\n",
    "final_preds_float = test_preds_accum / len(seeds)\n",
    "\n",
    "print(f\"Applying Threshold: < {best_th_low} -> 0\")\n",
    "\n",
    "final_preds = final_preds_float.copy()\n",
    "\n",
    "final_preds = np.where(final_preds < best_th_low, 0, final_preds)\n",
    "\n",
    "lag_target_test = X_test_final['lag_target_1'].values\n",
    "is_growth = X_test_final['orders_growth_heavy'].values\n",
    "safe_condition = (lag_target_test == 0) & (~is_growth)\n",
    "\n",
    "enhanced_th = best_th_low + 0.15\n",
    "final_preds[safe_condition] = np.where(final_preds[safe_condition] < enhanced_th, 0, final_preds[safe_condition])\n",
    "\n",
    "# Финальное округление\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "# Проверка\n",
    "print(f\"Mean Prediction: {final_preds.mean():.4f}\")\n",
    "print(f\"Zeros count: {np.sum(final_preds == 0)} / {len(final_preds)}\")\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v41_calibrated_threshold.csv', index=False)\n",
    "print(\"Файл submission_v41_calibrated_threshold.csv готов.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76ZdSVaFgSpM",
    "outputId": "b49ccca9-15d5-40bf-cad6-6c4effb9d95c"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков...\n",
      "\n",
      "--- Calibration Stage: Searching for Optimal Thresholds ---\n",
      "Train dates: 95 weeks. Val dates: [Timestamp('2025-11-03 00:00:00'), Timestamp('2025-11-10 00:00:00'), Timestamp('2025-11-17 00:00:00')]\n",
      "Starting Grid Search...\n",
      "Optimal Zero Threshold found: 0.630 (Val WAPE: 0.21024)\n",
      "\n",
      "--- Final Training (Full Data) ---\n",
      "Training Seed 42...\n",
      "Training Seed 2024...\n",
      "Training Seed 777...\n",
      "Training Seed 555...\n",
      "Training Seed 8800...\n",
      "Applying Threshold: < 0.6300000000000003 -> 0\n",
      "Mean Prediction: 2.3950\n",
      "Zeros count: 724 / 2438\n",
      "Файл submission_v41_calibrated_threshold.csv готов.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv')\n",
    "test = pd.read_csv(path + 'test.csv')\n",
    "facts = pd.read_csv(path + 'facts.csv')\n",
    "shifts = pd.read_csv(path + 'shifts_prediction.csv')\n",
    "sample_sub = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "for df in [train, facts, shifts]:\n",
    "    df['calendar_dt'] = pd.to_datetime(df['calendar_dt'])\n",
    "test['calendar_dt'] = pd.to_datetime('2025-11-24')\n",
    "\n",
    "past_targets = train[['store_id', 'calendar_dt', 'target']].copy()\n",
    "past_targets['calendar_dt'] = past_targets['calendar_dt'] + pd.Timedelta(weeks=1)\n",
    "past_targets = past_targets.rename(columns={'target': 'lag_target_1'})\n",
    "\n",
    "def feature_engineering(df_main, df_facts, df_shifts, df_lags):\n",
    "    df = df_main.merge(df_facts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_shifts, on=['store_id', 'calendar_dt'], how='left')\n",
    "    df = df.merge(df_lags, on=['store_id', 'calendar_dt'], how='left')\n",
    "\n",
    "    df['lag_target_1'] = df['lag_target_1'].fillna(0)\n",
    "\n",
    "    # Основные метрики (как в V32)\n",
    "    df['diff_plan_vs_fact_lag'] = df['predicted_staff_value'] - df['fact_couriers_with_shifts_lag_1']\n",
    "    df['load_diff'] = df['predicted_load_factor'] - df['fact_load_factor_lag_1']\n",
    "    df['churn_ratio'] = df['fact_staff_churn'] / (df['fact_staff_value_lag_1'] + 1e-5)\n",
    "    df['day_of_week'] = df['calendar_dt'].dt.dayofweek\n",
    "    df['is_weekend'] = df['day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "    # Тренды\n",
    "    df['trend_staff'] = df['predicted_staff_value'] - df['lag_target_1']\n",
    "\n",
    "    # Отношение плана к факту\n",
    "    df['growth_ratio_orders'] = df['predicted_num_orders'] / (df['fact_num_orders_lag_1'] + 1)\n",
    "    df['growth_ratio_staff'] = df['predicted_staff_value'] / (df['fact_couriers_with_shifts_lag_1'] + 1)\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Генерация признаков...\")\n",
    "X_full = feature_engineering(train, facts, shifts, past_targets)\n",
    "X_test_final = feature_engineering(test, facts, shifts, past_targets)\n",
    "\n",
    "print(\"Кодирование категорий для XGBoost...\")\n",
    "\n",
    "# Объединяем, чтобы LabelEncoder видел все ID\n",
    "all_stores = pd.concat([X_full['store_id'], X_test_final['store_id']]).unique()\n",
    "le_store = LabelEncoder()\n",
    "le_store.fit(all_stores)\n",
    "X_full['store_id_enc'] = le_store.transform(X_full['store_id'])\n",
    "X_test_final['store_id_enc'] = le_store.transform(X_test_final['store_id'])\n",
    "\n",
    "# Если есть city_nm\n",
    "if 'city_nm' in X_full.columns:\n",
    "    X_full['city_nm'] = X_full['city_nm'].fillna('missing')\n",
    "    X_test_final['city_nm'] = X_test_final['city_nm'].fillna('missing')\n",
    "    all_cities = pd.concat([X_full['city_nm'], X_test_final['city_nm']]).unique()\n",
    "    le_city = LabelEncoder()\n",
    "    le_city.fit(all_cities)\n",
    "    X_full['city_nm_enc'] = le_city.transform(X_full['city_nm'])\n",
    "    X_test_final['city_nm_enc'] = le_city.transform(X_test_final['city_nm'])\n",
    "else:\n",
    "    X_full['city_nm_enc'] = 0\n",
    "    X_test_final['city_nm_enc'] = 0\n",
    "\n",
    "# Готовим данные\n",
    "drop_cols = ['target', 'calendar_dt', 'store_id', 'city_nm'] # Убираем сырые строки\n",
    "X_train = X_full.drop(drop_cols, axis=1)\n",
    "y_train = X_full['target']\n",
    "X_test = X_test_final.drop(drop_cols, axis=1, errors='ignore')\n",
    "\n",
    "# Синхронизация колонок\n",
    "cols = list(set(X_train.columns).intersection(set(X_test.columns)))\n",
    "X_train = X_train[cols]\n",
    "X_test = X_test[cols]\n",
    "\n",
    "print(f\"Фичей в работе: {len(cols)}\")\n",
    "\n",
    "print(\"\\n--- Training CatBoost (Quantile 0.54) ---\")\n",
    "# alpha 0.54 чуть-чуть сдвигает прогноз вверх, чтобы ловить дефициты\n",
    "cb_params = {\n",
    "    'iterations': 1400,\n",
    "    'depth': 5,\n",
    "    'learning_rate': 0.035,\n",
    "    'loss_function': 'Quantile:alpha=0.54',\n",
    "    'verbose': 0,\n",
    "    'random_seed': 42,\n",
    "    'allow_writing_files': False\n",
    "}\n",
    "model_cb = CatBoostRegressor(**cb_params)\n",
    "model_cb.fit(X_train, y_train)\n",
    "preds_cb = model_cb.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Training XGBoost (MAE) ---\")\n",
    "xgb_params = {\n",
    "    'n_estimators': 1200,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.04,\n",
    "    'objective': 'reg:absoluteerror', # Аналог MAE\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 2024,\n",
    "    'enable_categorical': True\n",
    "}\n",
    "model_xgb = XGBRegressor(**xgb_params)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "preds_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "print(\"\\nBlending\")\n",
    "w_cb = 0.6\n",
    "w_xgb = 0.4\n",
    "\n",
    "blend_preds = (preds_cb * w_cb) + (preds_xgb * w_xgb)\n",
    "\n",
    "print(f\"Mean CB: {preds_cb.mean():.4f}\")\n",
    "print(f\"Mean XGB: {preds_xgb.mean():.4f}\")\n",
    "print(f\"Mean Blend: {blend_preds.mean():.4f}\")\n",
    "\n",
    "final_preds = blend_preds.copy()\n",
    "\n",
    "final_preds = np.where(final_preds < 0.32, 0, final_preds)\n",
    "\n",
    "final_preds = np.round(final_preds)\n",
    "final_preds = np.clip(final_preds, 0, None)\n",
    "\n",
    "submission = sample_sub.copy()\n",
    "submission['target'] = final_preds\n",
    "submission.to_csv('submission_v42_quantile_hybrid.csv', index=False)\n",
    "print(\"Файл submission_v42_quantile_hybrid.csv готов.\")\n",
    "print(\"Изменения: CatBoost (Quantile 0.54) + XGBoost Blend + Отказ от фильтрации 'Perfect Store'.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xqg56ygLhUiA",
    "outputId": "0ebee25d-9176-4481-899a-f612706ec51b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Генерация признаков...\n",
      "Кодирование категорий для XGBoost...\n",
      "Фичей в работе: 24\n",
      "\n",
      "--- Training CatBoost (Quantile 0.54) ---\n",
      "\n",
      "--- Training XGBoost (MAE) ---\n",
      "\n",
      "--- Blending ---\n",
      "Mean CB: 2.4803\n",
      "Mean XGB: 2.4076\n",
      "Mean Blend: 2.4513\n",
      "Файл submission_v42_quantile_hybrid.csv готов.\n",
      "Изменения: CatBoost (Quantile 0.54) + XGBoost Blend + Отказ от фильтрации 'Perfect Store'.\n"
     ]
    }
   ]
  }
 ]
}
